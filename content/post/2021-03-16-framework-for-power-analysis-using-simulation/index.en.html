---
title: Framework for power analysis using simulation
author: 
date: '2021-03-16'
slug: []
categories: []
tags:
  - R
type: ''
subtitle: ''
image: ''
output:
  blogdown::html_page:
    anchor_sections: no
draft: TRUE
---

<script src="{{< blogdown/postref >}}index.en_files/header-attrs/header-attrs.js"></script>


<p>The <a href="https://kgoldfeld.github.io/simstudy/index.html" target="_blank">simstudy</a> package started as a collection of functions I developed as I found myself repeating many of the same types of simulations for different projects. It was a way of organizing my work that I decided to share with others in case they wanted a routine way to generate data as well. <code>simstudy</code> has expanded a bit from that, but replicability is still a key motivation.</p>
<p>What I have here is another attempt to document and organize a process that I find myself doing quite often - repeated data generation and model fitting. Whether I am conducting a power analysis using simulation or exploring operating characteristics of different models, I take a pretty similar approach. I refer to this structure when I am starting a new project, so I thought it would be nice to have it easily accessible online - and that way others might be able to refer to it as well.</p>
<div id="the-framework" class="section level3">
<h3>The framework</h3>
<p>I will provide a simple application below, but first I am just showing the general structure. The basic idea is that we want to generate data under a variety of assumptions - for example, a power analysis will assume different sample sizes, effects, and/or levels of variation - and for <em>each set of assumptions</em>, we want to generate a large number of replications to mimic repeated sampling from a population. The key elements of the process include (1) <em>defining</em> the data, (2) <em>generating</em> a data set, (3) <em>fitting a model</em> to the data, and (4) <em>providing summary statistics</em>.</p>
<p>If you have familiarity with <code>simstudy</code>, I’d say the code is pretty self-explanatory. In the function <code>s_generate</code>, there is a call to base R function <code>list2env</code>, which makes all elements of a list available as variables in the function’s environment. The replication process is managed by the <code>mclapply</code> function from the <code>parallel</code> package. (Alternative approaches include using function <code>lapply</code> in base R or using a <em>for</em> loop.)</p>
<pre class="r"><code>s_define &lt;- function() {
  
  #--- add data definition code ---#
  
  return(list_of_defs) # list_of_defs is a list of simstudy data definitions
}

s_generate &lt;- function(list_of_defs, argsvec) {
  
  list2env(list_of_defs, envir = environment())
  list2env(as.list(argsvec), envir = environment())
  
  #--- add data generation code ---#
  
  return(generated_data) #  generated_data is a data.table
}

s_model &lt;- function(generated_data) {
  
  #--- add model code ---#
  
  return(model_results) # model_results is a data.table
}

s_single_rep &lt;- function(list_of_defs, argsvec) {
  
  generated_data &lt;- s_generate(list_of_defs, argsvec)
  model_results &lt;- s_model(generated_data)
  
  return(model_results)
}

s_replicate &lt;- function(argsvec, nsim) {
  
  list_of_defs &lt;- s_define()

  model_results &lt;- rbindlist(
    parallel::mclapply(
      X = 1 : nsim, 
      FUN = function(x) s_single_rep(list_of_defs, argsvec), 
      mc.cores = 4)
  )
  
  #--- add summary statistics code ---#
  
  return(summary_stats) # summary_stats is a data.table
}</code></pre>
<div id="specifying-scenarios" class="section level4">
<h4>Specifying scenarios</h4>
<p>The possible values of each data generating parameter are specified as a vector. Different data generating parameters are specified in different vectors. The function <code>scenario_list</code> creates all possible combinations of the values of the various parameters, so that there will be <span class="math inline">\(n_1 \times n_2 \times n_3 \times ...\)</span> scenarios, where <span class="math inline">\(n_i\)</span> is the number of possible values for parameter <span class="math inline">\(i\)</span>. Examples of parameters might be sample size, effect size, variance, etc. - or any value that can be used in the data generation process.</p>
<p>The process of data generation and model fitting is executed for each combination of <span class="math inline">\(n_1 \times n_2 \times n_3 \times ...\)</span> scenarios. This can be done locally using function <code>lapply</code> or using a high performance computing environment using something like <code>Slurm_lapply</code> in the <code>slurmR</code> package. (I won’t provide an example of that here - let me know if you’d like to see that.)</p>
<pre class="r"><code>#---- specify varying power-related parameters ---#

scenario_list &lt;- function(...) {
  argmat &lt;- expand.grid(...)
  return(asplit(argmat, MARGIN = 1))
}

param_1 &lt;- c(...)
param_2 &lt;- c(...)
param_3 &lt;- c(...)
.
.
.

scenarios &lt;- scenario_list(param1 = param_1, param_2 = param_2, param_3 = param_3, ...)

#--- run locally ---#

summary_stats &lt;- rbindlist(lapply(scenarios, function(a) s_replicate(a, nsim = 1000)))</code></pre>
</div>
</div>
<div id="example-power-analysis-of-a-crt" class="section level2">
<h2>Example: power analysis of a CRT</h2>
<p>To carry out a power analysis of a cluster randomized trial, I’ll fill in the skeletal framework. In this case I am interested in understanding how estimates of power vary based on changes in effect size, between cluster/site variation, and the number of patients per site. The data definitions use <a href="https://kgoldfeld.github.io/simstudy/articles/double_dot_extension.html" target="_blank">double dot</a> notation to allow the definitions to change dynamically as we switch from one scenario to the next. We estimate a mixed effect model for each data set and keep track of the proportion of p-value estimates less than 0.05 for each scenario.</p>
<pre class="r"><code>s_define &lt;- function() {
  
  #--- data definition code ---#
  
  def1 &lt;- defData(varname = &quot;site_eff&quot;, 
    formula = 0, variance = &quot;..svar&quot;, dist = &quot;normal&quot;, id = &quot;site&quot;)
  def1 &lt;- defData(def1, &quot;npat&quot;, formula = &quot;..npat&quot;, dist = &quot;poisson&quot;)
  
  def2 &lt;- defDataAdd(varname = &quot;Y&quot;, formula = &quot;5 + site_eff + ..delta * rx&quot;, 
    variance = 3, dist = &quot;normal&quot;)
  
  return(list(def1 = def1, def2 = def2)) 
}

s_generate &lt;- function(list_of_defs, argsvec) {
  
  list2env(list_of_defs, envir = environment())
  list2env(as.list(argsvec), envir = environment())
  
  #--- data generation code ---#
  
  ds &lt;- genData(40, def1)
  ds &lt;- trtAssign(ds, grpName = &quot;rx&quot;)
  dd &lt;- genCluster(ds, &quot;site&quot;, &quot;npat&quot;, &quot;id&quot;)
  dd &lt;- addColumns(def2, dd)
  
  return(dd)
}

s_model &lt;- function(generated_data) {
  
  #--- model code ---#
  
  require(lme4)
  require(lmerTest)
  
  lmefit &lt;- lmer(Y ~ rx + (1|site), data = generated_data)
  est &lt;- summary(lmefit)$coef[2, &quot;Estimate&quot;]
  pval &lt;- summary(lmefit)$coef[2, &quot;Pr(&gt;|t|)&quot;]
  
  return(data.table(est, pval)) # model_results is a data.table
}

s_single_rep &lt;- function(list_of_defs, argsvec) {
  
  generated_data &lt;- s_generate(list_of_defs, argsvec)
  model_results &lt;- s_model(generated_data)
  
  return(model_results)
}

s_replicate &lt;- function(argsvec, nsim) {
  
  list_of_defs &lt;- s_define()

  model_results &lt;- rbindlist(
    parallel::mclapply(
      X = 1 : nsim, 
      FUN = function(x) s_single_rep(list_of_defs, argsvec), 
      mc.cores = 4)
  )
  
  #--- summary statistics ---#
  
  power &lt;- model_results[, mean(pval &lt;= 0.05)]
  summary_stats &lt;- data.table(t(argsvec), power)
  
  return(summary_stats) # summary_stats is a data.table
}</code></pre>
<pre class="r"><code>scenario_list &lt;- function(...) {
  argmat &lt;- expand.grid(...)
  return(asplit(argmat, MARGIN = 1))
}

delta &lt;- c(0.50, 0.75, 1.00)
svar &lt;- c(0.25, 0.50)
npat &lt;- c(8, 16)

scenarios &lt;- scenario_list(delta = delta, svar = svar, npat = npat)

#--- run locally ---#

summary_stats &lt;- rbindlist(lapply(scenarios, function(a) s_replicate(a, nsim = 250)))</code></pre>
<p>The overall results (in this case, the power estimate) can be reported for each scenario.</p>
<pre class="r"><code>summary_stats</code></pre>
<pre><code>##     delta svar npat power
##  1:  0.50 0.25    8 0.536
##  2:  0.75 0.25    8 0.724
##  3:  1.00 0.25    8 0.972
##  4:  0.50 0.50    8 0.348
##  5:  0.75 0.50    8 0.696
##  6:  1.00 0.50    8 0.900
##  7:  0.50 0.25   16 0.628
##  8:  0.75 0.25   16 0.940
##  9:  1.00 0.25   16 1.000
## 10:  0.50 0.50   16 0.420
## 11:  0.75 0.50   16 0.772
## 12:  1.00 0.50   16 0.964</code></pre>
<p>We can also plot the results easily to get a clearer picture. Higher between-site variation clearly reduces power, as do smaller effect sizes and smaller sizes. None of this is surprising, but is always nice to see things working out as expected:</p>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/powerplot-1.png" width="768" /></p>
</div>
