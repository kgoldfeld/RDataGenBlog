---
title: It can be easy to explore data generating mechanisms with the simstudy package
author: []
date: '2017-05-16'
slug: intro-to-simstudy
categories: []
tags: []
subtitle: ''
---



<STYLE TYPE="text/css">
<!--
  td{
    font-family: Arial; 
    font-size: 9pt;
    height: 2px;
    padding:0px;
    cellpadding="0";
    cellspacing="0";
    text-align: center;
  }
  th {
    font-family: Arial; 
    font-size: 9pt;
    height: 20px;
    font-weight: bold;
    text-align: center;
  }
  table { 
    border-spacing: 0px;
    border-collapse: collapse;
  }
--->
</STYLE>
<p>I learned statistics and probability by simulating data. Sure, I did the occasional proof, but I never believed the results until I saw it in a simulation. I guess I have it backwards, but I that’s just the way I am. And now that I am a so-called professional, I continue to use simulation to understand models, to do sample size estimates and power calculations, and of course to teach. Sure - I’ll use the occasional formula when one exists, but I always feel the need to check it with simulation. It’s just the way I am.</p>
<p>Since I found myself constantly setting up simulations, over time I developed ways to make the process a bit easier. Those processes turned into a package, which I called <a href = https://cran.r-project.org/web/packages/simstudy/index.html>simstudy</a>, which obviously means <em>simulating study data</em>. The purpose here in this blog entyr is to introduce the basic idea behind simstudy, and provide a relatively brief example that actually comes from a question a user posed about generating correlated longitudinal data.</p>
<div id="the-basic-idea" class="section level2">
<h2>The basic idea</h2>
<p>Simulation using simstudy has two primary steps. First, the user defines the data elements of a data set either in an external csv file or internally through a set of repeated definition statements. Second, the user generates the data, using these definitions. Data generation can be as simple as a cross-sectional design or prospective cohort design, or it can be more involved, extending to allow simulators to generate observed or randomized <em>treatment assignment/exposures</em>, <em>survival</em> data, <em>longitudinal/panel</em> data, <em>multi-level/hierarchical</em> data, datasets with <em>correlated variables</em> based on a specified covariance structure, and to data sets with <em>missing</em> data based on a variety of missingness patterns.</p>
<p>The key to simulating data in simstudy is the creation of series of data defintion tables that look like this:</p>
<table>
<thead>
<tr class="header">
<th align="left">varname</th>
<th align="left">formula</th>
<th align="right">variance</th>
<th align="left">dist</th>
<th align="left">link</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">nr</td>
<td align="left">7</td>
<td align="right">0</td>
<td align="left">nonrandom</td>
<td align="left">identity</td>
</tr>
<tr class="even">
<td align="left">x1</td>
<td align="left">10;20</td>
<td align="right">0</td>
<td align="left">uniform</td>
<td align="left">identity</td>
</tr>
<tr class="odd">
<td align="left">y1</td>
<td align="left">nr + x1 * 2</td>
<td align="right">8</td>
<td align="left">normal</td>
<td align="left">identity</td>
</tr>
<tr class="even">
<td align="left">y2</td>
<td align="left">nr - 0.2 * x1</td>
<td align="right">0</td>
<td align="left">poisson</td>
<td align="left">log</td>
</tr>
<tr class="odd">
<td align="left">xCat</td>
<td align="left">0.3;0.2;0.5</td>
<td align="right">0</td>
<td align="left">categorical</td>
<td align="left">identity</td>
</tr>
<tr class="even">
<td align="left">g1</td>
<td align="left">5+xCat</td>
<td align="right">1</td>
<td align="left">gamma</td>
<td align="left">log</td>
</tr>
<tr class="odd">
<td align="left">a1</td>
<td align="left">-3 + xCat</td>
<td align="right">0</td>
<td align="left">binary</td>
<td align="left">logit</td>
</tr>
</tbody>
</table>
<p>Here’s the code that is used to generate this definition, which is stored as a <a href = https://github.com/Rdatatable/data.table/wiki>data.table </a>:</p>
<pre class="r"><code>def &lt;- defData(varname = &quot;nr&quot;, dist = &quot;nonrandom&quot;, formula = 7, id = &quot;idnum&quot;)
def &lt;- defData(def, varname = &quot;x1&quot;, dist = &quot;uniform&quot;, formula = &quot;10;20&quot;)
def &lt;- defData(def, varname = &quot;y1&quot;, formula = &quot;nr + x1 * 2&quot;, variance = 8)
def &lt;- defData(def, varname = &quot;y2&quot;, dist = &quot;poisson&quot;, formula = &quot;nr - 0.2 * x1&quot;, 
    link = &quot;log&quot;)
def &lt;- defData(def, varname = &quot;xCat&quot;, formula = &quot;0.3;0.2;0.5&quot;, dist = &quot;categorical&quot;)
def &lt;- defData(def, varname = &quot;g1&quot;, dist = &quot;gamma&quot;, formula = &quot;5+xCat&quot;, variance = 1, 
    link = &quot;log&quot;)
def &lt;- defData(def, varname = &quot;a1&quot;, dist = &quot;binary&quot;, formula = &quot;-3 + xCat&quot;, 
    link = &quot;logit&quot;)</code></pre>
<p>To create a simple data set based on these definitions, all one needs to do is execute a single <code>genData</code> command. In this example, we generate 500 records that are based on the definition in the <code>def</code>table:</p>
<pre class="r"><code>dt &lt;- genData(500, def)

dt</code></pre>
<pre><code>##      idnum nr       x1       y1  y2 xCat         g1 a1
##   1:     1  7 11.78709 30.24305 109    1  297.03396  0
##   2:     2  7 13.02129 30.58814  87    3  929.80474  0
##   3:     3  7 15.37784 37.31205  44    2 3738.52996  1
##   4:     4  7 18.66916 42.51506  24    2   78.17338  0
##   5:     5  7 10.55980 26.39898 131    2  147.42608  0
##  ---                                                  
## 496:   496  7 19.74327 46.62290  24    1   15.49462  0
## 497:   497  7 18.41837 43.35002  24    1  201.66739  0
## 498:   498  7 18.64485 47.62767  26    1  215.74763  0
## 499:   499  7 12.07687 28.65423 105    3  864.30964  1
## 500:   500  7 11.37337 29.71361 132    2  149.21883  0</code></pre>
<p>There’s a lot more functionality in the package, and I’ll be writing about that in the future. But here, I just want give a little more introduction by way of an example that came in from around the world a couple of days ago. (I’d say the best thing about building a package is hearing from folks literally all over the world and getting to talk to them about statistics and R. It is really incredible to be able to do that.)</p>
</div>
<div id="going-a-bit-further-simulating-a-prosepctive-cohort-study-with-repeated-measures" class="section level2">
<h2>Going a bit further: simulating a prosepctive cohort study with repeated measures</h2>
<p>The question was, can we simulate a study with two arms, say a control and treatment, with repeated measures at three time points: baseline, after 1 month, and after 2 months? Of course.</p>
<p>This was what I sent back to my correspondent:</p>
<pre class="r"><code># Define the outcome

ydef &lt;- defDataAdd(varname = &quot;Y&quot;, dist = &quot;normal&quot;, formula = &quot;5 + 2.5*period + 1.5*T + 3.5*period*T&quot;, 
    variance = 3)

# Generate a &#39;blank&#39; data.table with 24 observations and assign them to
# groups

set.seed(1234)

indData &lt;- genData(24)
indData &lt;- trtAssign(indData, nTrt = 2, balanced = TRUE, grpName = &quot;T&quot;)

# Create a longitudinal data set of 3 records for each id

longData &lt;- addPeriods(indData, nPeriods = 3, idvars = &quot;id&quot;)
longData &lt;- addColumns(dtDefs = ydef, longData)

longData[, `:=`(T, factor(T, labels = c(&quot;No&quot;, &quot;Yes&quot;)))]

# Let&#39;s look at the data

ggplot(data = longData, aes(x = factor(period), y = Y)) + geom_line(aes(color = T, 
    group = id)) + scale_color_manual(values = c(&quot;#e38e17&quot;, &quot;#8e17e3&quot;)) + xlab(&quot;Time&quot;)</code></pre>
<p><img src="/post/2017-05-16-intro-to-simstudy_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>If we generate a data set based on 1,000 indviduals and estimate a linear regression model we see that the parameter estimates are quite good. However, my correspondent wrote back saying she wanted correlated data, which makes sense. We can see from the alpha estimate of approximately 0.02 (at the bottom of the output), we don’t have much correlation:</p>
<pre class="r"><code># Fit a GEE model to the data

fit &lt;- geeglm(Y ~ factor(T) + period + factor(T) * period, family = gaussian(link = &quot;identity&quot;), 
    data = longData, id = id, corstr = &quot;exchangeable&quot;)
summary(fit)</code></pre>
<pre><code>## 
## Call:
## geeglm(formula = Y ~ factor(T) + period + factor(T) * period, 
##     family = gaussian(link = &quot;identity&quot;), data = longData, id = id, 
##     corstr = &quot;exchangeable&quot;)
## 
##  Coefficients:
##                     Estimate Std.err   Wald Pr(&gt;|W|)    
## (Intercept)          4.98268 0.07227 4753.4   &lt;2e-16 ***
## factor(T)Yes         1.48555 0.10059  218.1   &lt;2e-16 ***
## period               2.53946 0.05257 2333.7   &lt;2e-16 ***
## factor(T)Yes:period  3.51294 0.07673 2096.2   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Estimated Scale Parameters:
##             Estimate Std.err
## (Intercept)    2.952 0.07325
## 
## Correlation: Structure = exchangeable  Link = identity 
## 
## Estimated Correlation Parameters:
##       Estimate Std.err
## alpha  0.01737 0.01862
## Number of clusters:   1000   Maximum cluster size: 3</code></pre>
</div>
<div id="one-way-to-generate-correlated-data" class="section level2">
<h2>One way to generate correlated data</h2>
<p>The first way to approach this is to use the simstudy function <code>genCorData</code> to generate correlated errors that are normally distributed with mean 0, variance of 3, and and common correlation coeffcient of 0.7. This approach is a bit mysterious, because we are acknowledging that we don’t know what is driving the relationship between the three outcomes, just that they have a common cause.</p>
<pre class="r"><code># define the outcome
ydef &lt;- defDataAdd(varname = &quot;Y&quot;, dist = &quot;normal&quot;, formula = &quot;5 + 2.5*period + 1.5*T + 3.5*period*T + e&quot;)

# define the correlated errors

mu &lt;- c(0, 0, 0)
sigma &lt;- rep(sqrt(3), 3)

# generate correlated data for each id and assign treatment

dtCor &lt;- genCorData(24, mu = mu, sigma = sigma, rho = 0.7, corstr = &quot;cs&quot;)
dtCor &lt;- trtAssign(dtCor, nTrt = 2, balanced = TRUE, grpName = &quot;T&quot;)

# create longitudinal data set and generate outcome based on definition

longData &lt;- addPeriods(dtCor, nPeriods = 3, idvars = &quot;id&quot;, timevars = c(&quot;V1&quot;, 
    &quot;V2&quot;, &quot;V3&quot;), timevarName = &quot;e&quot;)
longData &lt;- addColumns(ydef, longData)

longData[, `:=`(T, factor(T, labels = c(&quot;No&quot;, &quot;Yes&quot;)))]

# look at the data, outcomes should appear more correlated, lines a bit
# straighter

ggplot(data = longData, aes(x = factor(period), y = Y)) + geom_line(aes(color = T, 
    group = id)) + scale_color_manual(values = c(&quot;#e38e17&quot;, &quot;#8e17e3&quot;)) + xlab(&quot;Time&quot;)</code></pre>
<p><img src="/post/2017-05-16-intro-to-simstudy_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Again, we recover the true parameters. And this time, if we look at the estimated correlation, we see that indeed the outcomes are correlated within each indivdual. The estimate is 0.77, close to the our specified value of 0.7.</p>
<pre class="r"><code>fit &lt;- geeglm(Y ~ factor(T) + period + factor(T) * period, family = gaussian(link = &quot;identity&quot;), 
    data = longData, id = id, corstr = &quot;exchangeable&quot;)

summary(fit)</code></pre>
<pre><code>## 
## Call:
## geeglm(formula = Y ~ factor(T) + period + factor(T) * period, 
##     family = gaussian(link = &quot;identity&quot;), data = longData, id = id, 
##     corstr = &quot;exchangeable&quot;)
## 
##  Coefficients:
##                     Estimate Std.err Wald Pr(&gt;|W|)    
## (Intercept)           5.0636  0.0762 4411   &lt;2e-16 ***
## factor(T)Yes          1.4945  0.1077  192   &lt;2e-16 ***
## period                2.4972  0.0303 6798   &lt;2e-16 ***
## factor(T)Yes:period   3.5204  0.0426 6831   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Estimated Scale Parameters:
##             Estimate Std.err
## (Intercept)     3.07   0.117
## 
## Correlation: Structure = exchangeable  Link = identity 
## 
## Estimated Correlation Parameters:
##       Estimate Std.err
## alpha    0.711  0.0134
## Number of clusters:   1000   Maximum cluster size: 3</code></pre>
</div>
<div id="another-way-to-generate-correlated-data" class="section level2">
<h2>Another way to generate correlated data</h2>
<p>A second way to generate correlatd data is through an individual level random-effect or random intercept. This could be considered some unmeasured characteristic of the individuals (which happens to have a convenient normal distribution with mean zero). This random effect contributes equally to all instances of an individuals outcomes, but the outcomes for a particular individual deviate slightly from the hypothetical straight line as a result of unmeasured noise.</p>
<pre class="r"><code>ydef1 &lt;- defData(varname = &quot;randomEffect&quot;, dist = &quot;normal&quot;, formula = 0, variance = sqrt(3))
ydef2 &lt;- defDataAdd(varname = &quot;Y&quot;, dist = &quot;normal&quot;, formula = &quot;5 + 2.5*period + 1.5*T + 3.5*period*T + randomEffect&quot;, 
    variance = 1)

indData &lt;- genData(24, ydef1)
indData &lt;- trtAssign(indData, nTrt = 2, balanced = TRUE, grpName = &quot;T&quot;)

indData[1:6]</code></pre>
<pre><code>##    id T randomEffect
## 1:  1 0      -1.3101
## 2:  2 1       0.3423
## 3:  3 0       0.5716
## 4:  4 1       2.6723
## 5:  5 0      -0.9996
## 6:  6 1      -0.0722</code></pre>
<pre class="r"><code>longData &lt;- addPeriods(indData, nPeriods = 3, idvars = &quot;id&quot;)
longData &lt;- addColumns(dtDefs = ydef2, longData)

longData[, `:=`(T, factor(T, labels = c(&quot;No&quot;, &quot;Yes&quot;)))]

ggplot(data = longData, aes(x = factor(period), y = Y)) + geom_line(aes(color = T, 
    group = id)) + scale_color_manual(values = c(&quot;#e38e17&quot;, &quot;#8e17e3&quot;)) + xlab(&quot;Time&quot;)</code></pre>
<p><img src="/post/2017-05-16-intro-to-simstudy_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<pre class="r"><code>fit &lt;- geeglm(Y ~ factor(T) + period + factor(T) * period, family = gaussian(link = &quot;identity&quot;), 
    data = longData, id = id, corstr = &quot;exchangeable&quot;)
summary(fit)</code></pre>
<pre><code>## 
## Call:
## geeglm(formula = Y ~ factor(T) + period + factor(T) * period, 
##     family = gaussian(link = &quot;identity&quot;), data = longData, id = id, 
##     corstr = &quot;exchangeable&quot;)
## 
##  Coefficients:
##                     Estimate Std.err Wald Pr(&gt;|W|)    
## (Intercept)           4.9230  0.0694 5028   &lt;2e-16 ***
## factor(T)Yes          1.4848  0.1003  219   &lt;2e-16 ***
## period                2.5310  0.0307 6793   &lt;2e-16 ***
## factor(T)Yes:period   3.5076  0.0449 6104   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Estimated Scale Parameters:
##             Estimate Std.err
## (Intercept)     2.63  0.0848
## 
## Correlation: Structure = exchangeable  Link = identity 
## 
## Estimated Correlation Parameters:
##       Estimate Std.err
## alpha    0.619  0.0146
## Number of clusters:   1000   Maximum cluster size: 3</code></pre>
<p>I sent all this back to my correspondent, but I haven’t heard yet if it is what she wanted. I certainly hope so. If there are specific topics you’d like me to discuss related to simstudy, definitely get in touch, and I will try to write something up.</p>
</div>
