---
title: 'A demo on power estimation by simulation for a cluster randomized trial with a time-to-event outcome'
author: Package Build
date: '2023-05-23'
slug: []
categories: []
tags:
  - R
  - Cluster randomized trials
  - survival analysis
type: ''
subtitle: ''
image: ''
draft: TRUE
---

```{r, echo=FALSE}
options(digits = 2)
```

A colleague reached out for some help designing a cluster randomized trial to evaluate a clinical decision support tool for primary care physicians (PCPs), which aims to improve care for high-risk patients. The outcome will be a time-to-event measure, collected at the patient level. The unit of randomization will be the PCP, and one of the key design issues is settling on the number to randomize. > At this stage in my career, I was pretty shocked to realize that I'd never been involved with a study that would require a clustered survival analysis. So, this particular sample size calculation is new for me, and that means that I've had some new simulations to conduct. (There are some analytic solutions to this problem, but there doesn't seem to a consensus about the best approach to use.) I'm getting it all down here, because that's what I do.

### Overview

In tackling this problem, there were four key elements that I needed to work out before actually conducting the power simulations: (1) determine the hypothetical survival curve in the context of a single (control) arm and simulate data to confirm the parameters are correct, (2) generate cluster-level variation and assess the implications of variance of assumptions (still in a single-arm context), (3) generate two intervention arms (without any clustering) and assess effect size assumptions, and (4) generate a full data set that includes clustering and intervention arms to ensure that model fitting is appropriate. Once this was all done, I was confident that I could move on to generating estimates of power under a range of sample size and variability assumptions.

### Defining shape of survival curve

Defining the shape of the survival curve is made relatively easy using the function `survGetParams` in the `simstudy` package. All we need to do is specify a number of  coordinates along the curve and the function will return the parameters for the mean and shape of a Weibull function that best fit the points. In this case, the study's investigators provided me with a couple of points, indicating that approximately 10\% of the sample would have an event by day 30, and half would have an event at day 365. Since the study is following patients at most for 365 days, we will consider anything beyond that to be censored (more on censoring later). To get things started, here are the libraries needed for all the code that follows:

```{r, message=FALSE}
library(simstudy)
library(data.table)
library(survival)
library(survminer)
library(GGally)
library(coxme)
library(parallel)
```

Now, we get the parameters that define the survival curve:

```{r}
points <- list(c(30, 0.90), c(365, .50))
r <- survGetParams(points)
r
```

With the paramters in hand, we are ready for the first simulation. The time-to-event variable *tte* is defined using the parameters generating by `survGetParams`. The observed time is the minimum of one year and the time-to-event.

```{r}
defs <- defSurv(varname = "tte", formula = r[1], shape = r[2])

defa <- defDataAdd(varname = "time", formula = "min(365, tte)", dist = "nonrandom")
defa <- defDataAdd(defa, "event", "1*(tte <= 365)", dist = "nonrandom")
```

Generating the data is quite simple in this case:

```{r}
set.seed(589823)

dd <- genData(1000)
dd <- genSurv(dd, defs, digits = 0)
dd <- addColumns(defa, dd)

dd
```

The plots below show the source function determined by the parameters on the left and the actual data generated on the right. The generated data matches the data generation process:

```{r survplots, fig.height=3.5, fig.width = 10}
splot <- survParamPlot(r[1], r[2], points = points, n = 1000, limits = c(0, 365) )

fit <- survfit(Surv(time, event) ~ 1, data = dd)

j <- ggsurv(fit, CI = FALSE, surv.col = "red", size.est = 0.8) + 
  theme(panel.grid = element_blank(),
        axis.text = element_text(size = 7.5),
        axis.title = element_text(size = 8, face = "bold"),
        plot.title = element_blank()) +
  ylim(0, 1) +
  xlab("time") + ylab("probability of survival")

ggarrange(splot, j, ncol = 2, nrow = 1)
```

### Evaluating cluster variation

Cluster variation in the context of survival curves implies that there is a cluster-specific survival curve. This variation is induced with a random effect in in the data generation process. In this case, I am assuming a normally distributed random effect with mean 0 and some variance (other distributions can be used). The variance assumption is a key one (which will ultimately impact the estimates of power), and I explore that a bit more in the second part of this section.

#### Visualizing cluster variation

The data generation process is a tad more involved than above, though not much more. We need to generate clusters and their random effect first, before adding the individuals. *tte* is now a function of the distribution parameters as well as the cluster random effect *b*. We are still using a single arm and assuming that everyone is followed for one year.

```{r}
defc <- defData(varname = "b", formula = 0, variance = 0.1)

defs <- defSurv(varname = "tte", formula = "r[1] + b", shape = r[2])

defa <- defDataAdd(varname = "time", formula = "min(365, tte)", dist = "nonrandom")
defa <- defDataAdd(defa, "event", "1*(tte <= 365)", dist = "nonrandom")
```

```{r}
dc <- genData(20, defc, id = "pcp")
dd <- genCluster(dc, "pcp", numIndsVar = 200, "id")
dd <- genSurv(dd, defs, digits = 0)
dd <- addColumns(defa, dd)
dd
```

```{r, fig.height=3.5, fig.width = 5.5}
fit <- survfit(Surv(time, event) ~ pcp, data = dd)

j1 <- ggsurvplot(fit, data = dd, title = "Cluster variance = 0.100")
j1$plot <- j1$plot +
  theme(legend.position = "none",
        plot.title = element_text(size = 11, face = "bold"))
```


```{r variation, echo = FALSE, fig.height=4, fig.width = 10}
library(ggpubr)

defc <- defData(varname = "b", formula = 0, variance = 0.005)

dc <- genData(20, defc, id = "pcp")
dd <- genCluster(dc, "pcp", numIndsVar = 200, "id")
dd <- genSurv(dd, defs, digits = 0)
dd <- addColumns(defa, dd)

fit <- survfit(Surv(time, event) ~ pcp, data = dd)

j2 <- ggsurvplot(fit, data = dd, title = "Cluster variance = 0.005")

j2$plot <- j2$plot + 
  theme(legend.position = "none",
        plot.title = element_text(size = 11, face = "bold"))

ggarrange(j1$plot, j2$plot, ncol = 2, nrow = 1)
```

#### Variation of the probability of an event across clusters

```{r histprob, warning=FALSE, fig.width=4, fig.height=3}
defc <- defData(varname = "b", formula = 0, variance = 0.1)

defa <- defDataAdd(varname = "start_day", formula = "1;182", dist = "uniformInt")
defa <- defDataAdd(defa, varname = "censor", 
  formula = "365 - start_day ", dist = "nonrandom")

defs <- defSurv(varname = "tte", formula = "r[1] + b", shape = r[2])

dc <- genData(1000, defc, id = "pcp")
dd <- genCluster(dc, "pcp", numIndsVar = 500, "id")
dd <- addColumns(defa, dd)
dd <- genSurv(dd, defs, digits = 0)

dd[, event := 1 * (tte <= 365)]

ds <- dd[, .(p = mean(event)), keyby = pcp]

ggplot(data = ds, aes(x = p)) +
  geom_histogram(binwidth = .05) +
  scale_x_continuous(limits = c(0, 1)) +
  scale_y_continuous(limits = c(0, 200)) +
  ggtitle("Cluster variance = 0.100") +
  xlab("observed proportion of events") +
  theme(panel.grid = element_blank(),
        plot.title = element_text(size = 11, face = "bold")) 
```


```{r varprob, echo=FALSE, warning=FALSE, message=FALSE, fig.width=6, fig.height=4}
s_generate <- function(nsite, ninds, s2) {
  
  defc <- defData(varname = "b", formula = 0, variance = s2)

  dc <- genData(nsite, defc, id = "site")
  dd <- genCluster(dc, "site", numIndsVar = ninds, "id")
  dd <- addColumns(defa, dd)
  dd <- genSurv(dd, defs, digits = 0)

  dd[, event := 1 * (tte <= 365)]

  dd[, .(p = mean(event)), keyby = site]
}

replicate <- function(s2) {
  ds <- s_generate(1000, 500, s2)
  data.table(s2 = s2, min_p = quantile(ds$p, prob = 0.025), 
             med_p = quantile(ds$p, prob = 0.5),
             max_p = quantile(ds$p, prob = 0.975))
}

res <- parallel::mclapply(seq(0.005, 0.1, by = .005), function(a) replicate(a))
dp <- rbindlist(res)

ggplot(data = dp, aes(x = s2, y = med_p)) +
  geom_point(size = .8) +
  geom_errorbar(aes(ymin = min_p, ymax = max_p), width = .0, color = "grey65") +
  theme(panel.grid = element_blank()) +
  scale_x_continuous(
    name = "\nvariance of random effect in survival data generation",
    breaks = seq(0, .1, by = .01)
  ) +
  scale_y_continuous(
    name = "probability of event",
    limits = c(0.25, 0.75)
  )
```

### Evaluating the effect size

```{r}
defa <- defData(varname = "rx", formula = "1;1", dist = "trtAssign")
defa <- defData(defa, varname = "start_day", formula = "1;182", dist = "uniformInt")
defa <- defDataAdd(defa, varname = "censor", 
  formula = "365 - start_day ", dist = "nonrandom")

defs <- defSurv(varname = "tte", formula = "r[1] + 0.4 * rx", shape = r[2])

dd <- genData(600, defa)
dd <- genSurv(dd, defs, digits = 0)
dd <- addCompRisk(dd, events = c("tte", "censor"), 
  timeName = "time", censorName = "censor", keepEvents = TRUE)
```


```{r effect, fig.height=3.5, fig.width=5.5}
fit <- survfit(Surv(time, event) ~ rx, data = dd)

ggsurvplot(
  fit, 
  data = dd, 
  legend.title = "", 
  legend = c(.25, 0.25),
  palette = "jco"
)
```


```{r}
dd[, event := 1 * (tte <= 365)]
dd[, .(p = mean(event)), keyby = rx]
```

This is an odds ratio of 1.80, risk ratio of 1.26, and risk difference of 14 percentage points.

### Complete data generation and model estimation

```{r}
defc <- defData(varname = "b", formula = 0, variance = 0.05)
defc <- defData(defc, varname = "rx", formula = "1;1", dist = "trtAssign")

defa <- defDataAdd(varname = "start_day", formula = "1;182", dist = "uniformInt")
defa <- defDataAdd(defa, varname = "censor", 
  formula = "365 - start_day ", dist = "nonrandom")

defs <- defSurv(varname = "tte", formula = "r[1] + 0.4 * rx + b", shape = r[2])
```

```{r, eval=FALSE}
dc <- genData(1000, defc, id = "site")
dd <- genCluster(dc, "site", numIndsVar = 500, "id")
dd <- addColumns(defa, dd)
dd <- genSurv(dd, defs, digits = 0)
dd <- addCompRisk(dd, events = c("tte", "censor"), 
  timeName = "time", censorName = "censor", keepEvents = TRUE)

fit_coxme <-coxme(Surv(time, event) ~ rx + (1 | site), data = dd)

summary(fit_coxme)
```

```{r, echo=FALSE}
load("data/coxfit.rda")
fit_coxme
```

### Power estimation

Check out the <a href="#addendum">addendum</a> for code details.

```{r, echo = FALSE}
extract_coxme_table <- function (mod) {
  beta <- mod$coefficients 
  nvar <- length(beta)
  nfrail <- nrow(mod$var) - nvar
  se <- sqrt(diag(mod$var)[nfrail + 1:nvar])
  z <- round(beta/se, 2)
  p <- signif(1 - pchisq((beta/se)^2, 1), 2)
  table=data.table(beta = beta, se = se, z = z, p = p)
  return(table)
}

s_def <- function() {
  
  defc <- defData(varname = "b", formula = 0, variance = "..s2")
  defc <- defData(defc, varname = "rx", formula = "1;1", dist = "trtAssign")
  
  defa <- defDataAdd(varname = "start_day", formula = "1;182", dist = "uniformInt")
  defa <- defDataAdd(defa, varname = "censor", 
                     formula = "365 - start_day ", dist = "nonrandom")
  
  defs <- defSurv(varname = "tte", formula = "-4.815 + 0.4 * rx + b", shape = 1.326)
  
  defa2 <- defDataAdd(varname = "event6", 
                      formula = "1*(tte <= 182)", dist = "nonrandom")
  
  return(list(defc = defc, defa = defa, defs = defs, defa2 = defa2))
  
}

s_generate <- function(argsvec, list_of_defs) {
  
  list2env(list_of_defs, envir = environment())
  list2env(as.list(argsvec), envir = environment())
  
  dc <- genData(nsites, defc, id = "site")
  dd <- genCluster(dc, "site", ninds, "id")
  dd <- addColumns(defa, dd)
  dd <- genSurv(dd, defs, digits = 0)
  dx <- addCompRisk(dd, events = c("tte", "censor"), 
                    timeName = "time", censorName = "censor", keepEvents = TRUE)
  dx <- addColumns(defa2, dx)
  
  dx[]
  
}

s_replicate <- function(argsvec, list_of_defs) {
  
  dx <- s_generate(argsvec, list_of_defs)
  
  coxfitm <-coxme(Surv(time, event) ~ rx + (1 | site), data = dx)
  
  list2env(as.list(argsvec), envir = environment())
  
  return(data.table(
    nsites = nsites,
    ninds = ninds,
    s2 = s2,
    est_s = fixef(coxfitm), 
    re.var_s = VarCorr(coxfitm)$site,
    p_s = extract_coxme_table(coxfitm)$p
  ))
  
}

s_scenarios <- function(argsvec, nreps) {
  
  list_of_defs <- s_def()
  
  rbindlist(
    parallel::mclapply(
      X = 1 : nreps, 
      FUN = function(x) s_replicate(argsvec, list_of_defs), 
      mc.cores = 4)
  )
  
}
```

```{r}
scenario_list <- function(...) {
  argmat <- expand.grid(...)
  return(asplit(argmat, MARGIN = 1))
}

nsites <- c(20, 30)
ninds <- c(15)
s2 <- c(0.03, 0.04)

scenarios <- scenario_list(nsites = nsites, ninds = ninds, s2 = s2)
model.ests <- mclapply(scenarios, function(a) s_scenarios(a, nrep = 3))

model.ests
```

```{r power, echo = FALSE, fig.height = 2.75, fig.width = 8}
load("data/ss.rda")

resum[, `number of sites` := nsites]

ggplot(data = resum, mapping = aes(x = s2, y = p_m)) +
  geom_hline(yintercept = 0.8, color = "white", linewidth = 1.2) +
  geom_line(aes(color = factor(ninds), group = ninds), linewidth = 0.9) +
  facet_grid(. ~ `number of sites`, labeller = label_both) +
  theme(
    panel.grid = element_blank(),
    axis.text = element_text(size = 8),
    panel.spacing = unit(0.65, "lines")
  ) +
  scale_color_brewer(
    name = "size", 
    guide = guide_legend(reverse = TRUE), 
    type = "div", 
    palette = "Dark2"
  ) +
  ylab("estimated power") +
  xlab("\nvariance of random effect")

```

<a name="addendum"></a>  

\ 

## Addendum

```{r, eval = FALSE}
extract_coxme_table <- function (mod) {
  beta <- mod$coefficients 
  nvar <- length(beta)
  nfrail <- nrow(mod$var) - nvar
  se <- sqrt(diag(mod$var)[nfrail + 1:nvar])
  z <- round(beta/se, 2)
  p <- signif(1 - pchisq((beta/se)^2, 1), 2)
  table=data.table(beta = beta, se = se, z = z, p = p)
  return(table)
}

s_def <- function() {
  
  defc <- defData(varname = "b", formula = 0, variance = "..s2")
  defc <- defData(defc, varname = "rx", formula = "1;1", dist = "trtAssign")
  
  defa <- defDataAdd(varname = "start_day", formula = "1;182", dist = "uniformInt")
  defa <- defDataAdd(defa, varname = "censor", 
                     formula = "365 - start_day ", dist = "nonrandom")
  
  defs <- defSurv(varname = "tte", formula = "-4.815 + 0.4 * rx + b", shape = 1.326)
  
  defa2 <- defDataAdd(varname = "event6", 
                      formula = "1*(tte <= 182)", dist = "nonrandom")
  
  return(list(defc = defc, defa = defa, defs = defs, defa2 = defa2))
  
}

s_generate <- function(argsvec, list_of_defs) {
  
  list2env(list_of_defs, envir = environment())
  list2env(as.list(argsvec), envir = environment())
  
  dc <- genData(nsites, defc, id = "site")
  dd <- genCluster(dc, "site", ninds, "id")
  dd <- addColumns(defa, dd)
  dd <- genSurv(dd, defs, digits = 0)
  dx <- addCompRisk(dd, events = c("tte", "censor"), 
                    timeName = "time", censorName = "censor", keepEvents = TRUE)
  dx <- addColumns(defa2, dx)
  
  dx[]
  
}

s_replicate <- function(argsvec, list_of_defs) {
  
  dx <- s_generate(argsvec, list_of_defs)
  
  coxfitm <-coxme(Surv(time, event) ~ rx + (1 | site), data = dx)
  
  list2env(as.list(argsvec), envir = environment())
  
  return(data.table(
    nsites = nsites,
    ninds = ninds,
    s2 = s2,
    est_s = fixef(coxfitm), 
    re.var_s = VarCorr(coxfitm)$site,
    p_s = extract_coxme_table(coxfitm)$p
  ))
  
}

s_scenarios <- function(argsvec, nreps) {
  
  list_of_defs <- s_def()
  
  rbindlist(
    parallel::mclapply(
      X = 1 : nreps, 
      FUN = function(x) s_replicate(argsvec, list_of_defs), 
      mc.cores = 4)
  )
  
}
```

