---
title: Should we be concerned about incidence - prevalence bias?
author: ''
date: '2017-08-09'
slug: simulating-incidence-prevalence-bias
categories: []
tags: [R]
subtitle: ''
---

Recently, we were planning a study to evaluate the effect of an intervention on outcomes for very sick patients who show up in the emergency department. My collaborator had concerns about a phenomenon that she had observed in other studies that might affect the results - patients measured earlier in the study tend to be sicker than those measured later in the study. This might not be a problem, but in the context of a stepped-wedge study design (see [this](https://www.rdatagen.net/post/using-simulation-for-power-analysis-an-example/) for a discussion that touches this type of study design), this could definitely generate biased estimates: when the intervention occurs later in the study (as it does in a stepped-wedge design), the "exposed" and "unexposed" populations could differ, and in turn so could the outcomes. We might confuse an artificial effect as an intervention effect.

What could explain this phenomenon? The title of this post provides a hint: cases earlier in a study are more likely to be prevalent ones (i.e. they have been sick for a while), whereas later in the study cases tend to be incident (i.e. they only recently become sick). Even though both prevalent and incident cases are sick, the former may be sicker on average than the latter, simply because their condition has had more time develop.

We didn't have any data to test out this hypothesis (if our grant proposal is funded, we will be able to do that), so I decided to see if I could simulate this phenomenon. In my continuing series exploring simulation using `Rcpp`, `simstudy`, and `data.table`, I am presenting some code that I used to do this.

## Generating a population of patients

The first task is to generate a population of individuals, each of whom starts out healthy and potentially becomes sicker over time. Time starts in month 1 and ends at some fixed point - in the first example, I end at 400 months. Each individual has a starting health status and a start month. In the examples that follow, health status is 1 through 4, with 1 being healthy, 3 is quite sick, and 4 is death. And, you can think of the start month as the point where the individual ages into the study. (For example, if the study includes only people 65 and over, the start month is the month the individual turns 65.) If an individual starts in month 300, she will have no measurements in periods 1 through 299 (i.e. health status will be 0). 

The first part of the simulation generates a start month and starting health status for each individual, and then generates a health status for each individual until the end of time. Some individuals may die, while others may go all the way to the end of the simulation in a healthy state.

#### Rcpp function to generate health status for each period

While it is generally preferable to avoid loops in R, sometimes it cannot be [avoided](https://www.rdatagen.net/post/first-blog-entry/). I believe generating a health status that depends on the previous health status (a Markov process) is one of those situations. So, I have written an Rcpp function to do this - it is orders of magnitude faster than doing this in R:

```{r engine='Rcpp'}
#include <RcppArmadilloExtensions/sample.h>
// [[Rcpp::depends(RcppArmadillo)]]

using namespace Rcpp; 

// [[Rcpp::export]]
IntegerVector MCsim( unsigned int nMonths, NumericMatrix P, 
                     int startStatus, unsigned int startMonth ) {
  
  IntegerVector sim( nMonths );
  IntegerVector healthStats( P.ncol() );
  NumericVector currentP;
  IntegerVector newstate;
  
  unsigned int q = P.ncol();
  healthStats = Rcpp::seq(1, q);
  
  sim[startMonth - 1] = startStatus;
  
  /* Loop through each month for each individual */
  
  for (unsigned int i = startMonth; i < nMonths; i++) {
    
    /* new state based on health status of last period and
       probability of transitioning to different state     */ 
    
    newstate = RcppArmadillo::sample( healthStats, 
                                      1, 
                                      TRUE, 
                                      P.row(sim(i-1) - 1) ); 
    sim(i) = newstate(0);
    
  }
  
  return sim;
}
```
<br>

#### Generating the data

The data generation process is shown below. The general outline of the process is (1) define transition probabilities, (2) define starting health status distribution, (3) generate starting health statuses and start months, and (4) generate health statuses for each follow-up month.

```{r}
# Transition matrix for moving through health statuses

P <- matrix(c(0.985, 0.015, 0.000, 0.000, 
              0.000, 0.950, 0.050, 0.000,
              0.000, 0.000, 0.850, 0.150,
              0.000, 0.000, 0.000, 1.000), nrow = 4, byrow = TRUE)

maxFU = 400
nPerMonth = 350
N = maxFU * nPerMonth

ddef <- defData(varname = "sHealth", 
                formula = "0.80; 0.15; 0.05", 
                dist = "categorical")

# generate starting health values (1, 2, or 3) for all individuals
set.seed(123)
did <- genData(n = N, dtDefs = ddef)

# each month, 350 age in to the sample
did[, sMonth := rep(1:maxFU, each = nPerMonth)]

# show table for 10 randomly selected individuals
did[id %in% sample(x = did$id, size = 10, replace = FALSE)] 

# generate the health status history based on the transition matrix
dhealth <- did[, .(sHealth, sMonth, health = MCsim(maxFU, P, sHealth, sMonth)), 
                 keyby = id]
dhealth[, month := c(1:.N), by = id]

dhealth
```
<br>

#### Simulation needs burn-in period

The simulation process itself is biased in its early phases as there are too many individuals in the sample who have just aged in compared to those who are "older". (This is sort of the the reverse of the incidence - prevalence bias.) Since individuals tend to have better health status when they are "younger", the average health status of the simulation in its early phases is biased downwards by the preponderance of young individuals in the population. This suggests that any evaluation of simulated data needs to account for a "burn-in" period that ensures there is a mix of "younger" and "older" individuals. To show this, I have calculated an average health score for each period of the simulation and plotted the results. You can see that the sample stabilizes after about 200 months in this simulation.

```{r}
# count number of individuals with a particular heath statust each month

cmonth <- dhealth[month > 0, .N, keyby = .(month, health)]
cmonth

# transform data from "long" form to "wide" form and calculate average

mtotal <- dcast(data = cmonth, 
                formula = month ~ health, 
                fill = 0, 
                value.var = "N")

mtotal[, total := `1` + `2` + `3`]
mtotal[, wavg := (`1` + 2*`2` + 3*`3`)/total]
mtotal

ggplot(data = mtotal, aes(x=month, y=wavg)) +
  geom_line() +
  ylim(1.2, 1.5) +
  geom_hline(yintercept = 1.411, lty = 3) +
  geom_vline(xintercept = 200, lty = 3) +
  xlab("Month") +
  ylab("Average health status") +
  theme(panel.background = element_rect(fill = "grey90"),
        panel.grid = element_blank(), 
        plot.title = element_text(size = 12, vjust = 0.5, hjust = 0) ) + 
  ggtitle("Average health status of simulated population")

```

## Generating monthly study cohorts

Now we are ready to see if we can simulate the incidence - prevalence bias. The idea here is to find the first month during which an individual (1) is "active" (i.e. the period being considered is on or after the individual's start period), (2) has an emergency department visit, and (3) whose health status has reached a specified threshold. 

We can set a final parameter that looks back some number of months (say 6 or 12) to see if there have been any previous qualifying emergency room visits before the study start period (which in our case will be month 290 to mitigate an burn-in bias identified above). This "look-back" will be used to mitigate some of the bias by creating a washout period that makes the prevalent cases look more like incident cases. This look-back parameter is calculated each month for each individual using an Rcpp function that loops through each period:

```{r engine='Rcpp'}
#include <Rcpp.h>

using namespace Rcpp;

// [[Rcpp::export]]
IntegerVector cAddPrior(IntegerVector idx, 
                        IntegerVector event,
                        int lookback) {
  
  int nRow = idx.length();
  IntegerVector sumPrior(nRow, NA_INTEGER);

  for (unsigned int i = lookback; i < nRow; i++) {
    
    IntegerVector seqx = Rcpp::seq(i-lookback, i-1);
    IntegerVector x = event[seqx];
    sumPrior[i] = sum(x);
    
  }
  
  return(sumPrior);
}
```
<br>

#### Generating a single cohort

The following code (1) generates a population (as we did above), (2) generates emergency department visits that are dependent on the health status (the sicker an individual is, the more likely they are to go to the ED), (3) calculates the number of eligible ED visits during the look-back period, and (4) creates the monthly cohorts based on the selection criteria. At the end, we calculate average health status for the cohort by month of cohort - this will be used to illustrate the bias.

```{r}
maxFU = 325 
nPerMonth = 100
N = maxFU * nPerMonth

START = 289 # to allow for adequate burn-in 
HEALTH = 2
LOOKBACK = 6 # how far to lookback

set.seed(123)
did <- genData(n = N, dtDefs = ddef)
did[, sMonth := rep(1:maxFU, each = nPerMonth)]

healthStats <- did[, .(sHealth, 
                       sMonth, 
                       health = MCsim(maxFU, P, sHealth, sMonth)),
                   keyby = id]
    
healthStats[, month := c(1:.N), by = id]
      
# eliminate period without status measurement (0) & death (4)
healthStats <- healthStats[!(health %in% c(0,4))]
  
# ensure burn-in by starting with observations far
# into simulation
healthStats <- healthStats[month > (START - LOOKBACK)]
  
# set probability of emergency department visit  
healthStats[, pED := (health == 1) * 0.02 + 
                     (health == 2) * 0.10 + 
                     (health == 3) * 0.20]

# generate emergency department visit
healthStats[, ed := rbinom(.N, 1, pED)]

healthStats[, edAdj := ed * as.integer(health >= HEALTH)] # if you want to restrict
healthStats[, pSum := cAddPrior(month, edAdj, lookback = LOOKBACK), keyby=id]

# look at one individual
healthStats[id == 28069]

# cohort includes individuals with 1 prior ed visit in
# previous 6 months

cohort <- healthStats[edAdj == 1 & pSum == 0]
cohort <- cohort[, .(month = min(month)), keyby = id]
cohort

# estimate average health status of monthly cohorts

cohortStats <- healthStats[cohort, on = c("id","month")]
sumStats <- cohortStats[ , .(avghealth = mean(health), n = .N), keyby = month]

head(sumStats)
```

## Exploring bias

Finally, we are at the point where we can see what, if any, bias results in selecting our cohorts under the scenario I've outlined above. We start by generating multiple iterations of populations and cohorts and estimating average health status by month under the assumption that we will have a look-back period of 0. That is, we will accept an individual into the first possible cohort regardless of her previous emergency department visit history. The plot below shows average across 1000 iterations. What we see is that the average health status of the cohorts in the first 20 months or so exceed the long run average. The incidence - prevalence bias is extremely strong if we ignore prior ED history!

![](/img/post-incidence/plot00.png)
<br>

#### Taking history into account

Once we start to incorporate ED history by using look-back periods greater than 0, we see that we can reduce bias considerably. The two plots below show the results of using look-back periods of 6 and 12 months. Both have reduced bias, but only at 12 months are we approaching something that actually looks desirable. In fact, under this scenario, we'd probably like to go back 24 months to eliminate the bias entirely. Of course, these particular results are dependent on the simulation assumptions, so determining an appropriate look-back period will certainly depend on the actual data. (When we do finally get the actual data, I will follow-up to let you know what kind of adjustment we needed to make in the real, non-simulated world.)

![](/img/post-incidence/plot06.png)


![](/img/post-incidence/plot12.png)

