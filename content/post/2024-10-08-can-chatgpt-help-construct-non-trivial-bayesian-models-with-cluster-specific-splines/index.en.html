---
title: Can ChatGPT help construct non-trivial bayesian models? An example with cluster-specific splines
author: Package Build
date: '2024-10-08'
slug: []
categories: []
tags:
  - R
  - Bayesian model
  - ChatGPT
type: ''
subtitle: ''
image: ''
draft: TRUE
---



<p>I’ve been curious to see how helpful ChatGPT can be for helping implelementing relatively complicated models in <code>R</code>. About two years, I <a href="https://www.rdatagen.net/post/2022-11-01-modeling-secular-trend-in-crt-using-gam/" target="_blank">described</a> a model that we had developed to estimate a treatment effect in the context of a cluster-randoimzed stepped wedge trial design. We used a generalized additive model (GAM) with site-specific splines to account for general time trends, which can be implemeented using the <code>mgcv</code> package. I was always interested in exploring whether we could implement a Bayeisan version of this model, but was never able to give it a try. Until, that is, I posed this simple question to ChatGPT:</p>
<blockquote>
I want to build an R Stan model with cluster specific random splines - is that possible?
</blockquote>
<p>And as ChatGPT does, it eagerly let me know that this would not be a problem:</p>
<blockquote>
<p>Yes, it’s possible to build a model in R using Stan with cluster-specific random splines. This approach involves using a hierarchical model where each cluster has its own spline, but the splines share a common structure.</p>
<p>Here is a step-by-step outline to guide you through this process:</p>
<ol style="list-style-type: decimal">
<li><strong>Data Preparation</strong>: Organize your data into clusters and ensure it’s in a suitable format for modeling.</li>
<li><strong>Spline Basis Functions</strong>: Generate spline basis functions (e.g., B-splines) for your data. This can be done using packages like <code>splines</code> or <code>mgcv</code> in R.</li>
<li><strong>Stan Model Code</strong>: Write the Stan code for the hierarchical spline model. The model will include cluster-specific random effects for the spline coefficients.</li>
<li><strong>Data List for Stan</strong>: Create a list of data inputs required by the Stan model, including the spline basis functions and the data itself.</li>
<li><strong>Run the Model</strong>: Use the <code>rstan</code> package to compile and fit the model.</li>
</ol>
</blockquote>
<p>Maybe I shouldn’t have been, but I was pretty impressed by the code that followed. I thought I would share some of that here. (Though, obviously, who needs a blog like this when you can to ChatGPT yourself to get any example you might be seeking?)</p>
<div id="preliminaries" class="section level3">
<h3>Preliminaries</h3>
<p>Before I get started, here are the libraries needed to run all of the following code:</p>
<pre class="r"><code>library(ggplot2)
library(simstudy)
library(data.table)
library(mgcv)
library(splines)
library(splines2)
library(cmdstanr)
library(posterior)</code></pre>
</div>
<div id="data-generation" class="section level3">
<h3>Data generation</h3>
<p>In order to explore the modeling options, we wanted to use a relatively simple data generation process. ChatGPT suggested the generating process for <span class="math inline">\(y_{ik}\)</span>, the outcome for individual <span class="math inline">\(i\)</span> in cluster <span class="math inline">\(k\)</span>, be a non-linear function of predictor <span class="math inline">\(x_{ik}\)</span>:
<span class="math display">\[ y_{ik} = \text{sin}(2\pi x_{ik}), \ \ \{ x \in \mathbb{R} \mid 0 \leq x \leq 1 \} \]</span>
The code was simple enough:</p>
<pre class="r"><code>set.seed(2024)

n &lt;- 1000
k &lt;- 10  # number of clusters
x &lt;- runif(n)
cluster &lt;- sample(1:k, n, replace = TRUE)
y &lt;- sin(2  * pi * x) + rnorm(n, sd = 0.35)
dd &lt;- data.table(y, x, cluster)
dd$cluster &lt;- factor(dd$cluster)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-3-1.png" width="816" /></p>
<p>Although the data generation process suggested by ChatGPT was helpful, it had a significant shortcoming. We aimed to model <em>cluster-specific</em> spline curves, but the ChatGPT code generated the same curve for all clusters. To address this, I used the general formulation and added a cluster-specific effect <span class="math inline">\(a_k\)</span>, which stretches the <em>sin</em> curve differently for each cluster:
<span class="math display">\[ y_{ik} = \text{sin}(2\pi a_k x_{ik}), \ \ \{ a \in \mathbb{R} \mid 0.6 \leq a \leq 1.4 \} \]</span></p>
<pre class="r"><code>k &lt;- 10  # number of clusters

defc &lt;- defData(varname = &quot;a&quot;, formula = &quot;0.6;1.4&quot;, dist = &quot;uniform&quot;)
defi &lt;- 
  defDataAdd(varname = &quot;x&quot;, formula = &quot;0;1&quot;, dist = &quot;uniform&quot;) |&gt;
  defDataAdd(
    varname = &quot;y&quot;, 
    formula =  &quot;sin(2 * a * ..pi * x)&quot;, 
    variance = 0.35^2
  )

dc &lt;- genData(k, defc, id = &quot;cluster&quot;)
dd &lt;- genCluster(dc, &quot;cluster&quot;, 100, &quot;id&quot;)
dd &lt;- addColumns(defi, dd)
dd[, cluster := factor(cluster)]</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-5-1.png" width="816" /></p>
</div>
<div id="data-modeling" class="section level3">
<h3>Data modeling</h3>
<p>The goal is to estimate cluster-specific curves that capture the relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> within each cluster. We aim for these curves to reflect the overall trend without overfitting the data; in other words, we want the function to provide a smooth and interpretable representation of the relationship, balancing flexibility and simplicity. While the purpose of my conversation with ChatGPT was to get a Bayesian version of this random spline model, I started off by asking for it to provide a generalized additive model (GAM):
<span class="math display">\[ y_{ik} = \beta_0 + s_k(x_{ik}) + \epsilon_{ik}, \ \ \epsilon \sim N(0, \sigma_y) \]</span></p>
<p>where <span class="math inline">\(s_k(x)\)</span> is a smooth spline function of <span class="math inline">\(x\)</span>. Once the model is estimated, we can obtain predictions to generate a curve that reflects the relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, which can then be plotted over the raw data:</p>
<pre class="r"><code>gam &lt;- gamm(
  y ~ s(x) + s(x, cluster, bs = &quot;fs&quot;, k = 8),
  data = dd, method=&quot;REML&quot;
)

dd$g &lt;- predict(gam$gam)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-7-1.png" width="816" /></p>
<div id="bayesian-spline-model" class="section level4">
<h4>Bayesian spline model</h4>
<p>The first model that ChatGPT generated can be described using this notation:</p>
<p><strong>Data</strong></p>
<ul>
<li><span class="math inline">\(N\)</span>: number of individuals</li>
<li><span class="math inline">\(K\)</span>: number of clusters</li>
<li><span class="math inline">\(M\)</span>: number of spline basis functions</li>
<li><span class="math inline">\(y_{ik}\)</span>: outcome for individual <span class="math inline">\(i\)</span> in cluster <span class="math inline">\(k\)</span>, <span class="math inline">\(i \in 1,\dots,N\)</span>, <span class="math inline">\(k \in 1,\dots ,K\)</span></li>
<li><span class="math inline">\(\boldsymbol{X} \in \mathbb{R}^{N \times M}\)</span>: matrix of spline basis function values</li>
</ul>
<p><strong>Parameters</strong></p>
<ul>
<li><span class="math inline">\(\boldsymbol{\beta_{k}} \in \mathbb{R}^M\)</span>: spline coefficients for cluster <span class="math inline">\(k\)</span> (a vector of length <span class="math inline">\(M\)</span> for each cluster)</li>
<li><span class="math inline">\(\sigma_y\)</span>: standard deviation of the observation noise</li>
<li><span class="math inline">\(\sigma_\beta\)</span>: prior standard deviation for the spline coefficients</li>
</ul>
<p><strong>Model</strong></p>
<p><em>Likelihood</em>:</p>
<p><span class="math display">\[ y_{ik} \sim N\left( \sum_{m=1}^M X_{im} \beta_{km}, \sigma_y  \right), \ i \in 1,\dots, N, \ k \in 1, \dots, K\]</span></p>
<p><em>Priors</em>:</p>
<p><span class="math display">\[
\boldsymbol{\beta_{k}} \sim N(0, \sigma_{\beta} \boldsymbol{I_M}), \ \ k \in 1,...,K \\
\sigma_{y} \sim N(0, 1), \ \ \sigma_y \gt 0 \\
\sigma_{\beta} \sim N(0, 1), \ \ \sigma_{\beta} \gt 0
\]</span></p>
<p>The <code>Stan</code> code provided by ChatGPT largely aligns with the description above. I also requested code to generate outcome predictions for each observation, which is implemented in the <em>generated quantities</em> block. My goal was to plot the median of those predictions for each individual <span class="math inline">\(i\)</span> to compare with the GAM plot above.”</p>
<pre class="stan"><code>data {
  int&lt;lower=1&gt; N;                          // number of observations
  int&lt;lower=1&gt; K;                          // number of clusters
  int&lt;lower=1&gt; M;                          // number of basis functions
  array[N] int&lt;lower=1, upper=K&gt; cluster;  // cluster ids
  matrix[N, M] X_spline;                   // basis function values
  vector[N] y;                             // response variable
}

parameters {
  matrix[K, M] beta;          // cluster-specific spline coefficients
  real&lt;lower=0&gt; sigma_y;      // observation noise
  real&lt;lower=0&gt; sigma_beta;   // prior standard deviation for beta
}

model {
  sigma_y ~ normal(0, 1);
  sigma_beta ~ normal(0, 1);
  
  // Priors for beta
  
  for (k in 1:K) {
    beta[k] ~ normal(0, sigma_beta);
  }
  
  // Likelihood
  
  for (n in 1:N) {
    y[n] ~ normal(X_spline[n] * beta[cluster[n]]&#39;, sigma_y);
  }
}

generated quantities {
  
  vector[N] y_pred;                    // Vector of observations.
  
  for (n in 1:N) {
    y_pred[n] = normal_rng(X_spline[n] * beta[cluster[n]]&#39;, sigma_y);
  }
}</code></pre>
</div>
<div id="spline-basis-functions" class="section level4">
<h4>Spline basis functions</h4>
<pre class="r"><code>n_knots &lt;- 8
knot_dist &lt;- 1/(n_knots + 1)
probs &lt;- seq(knot_dist, 1 - knot_dist, by = knot_dist)
knots &lt;- quantile(dd$x, probs = probs)
spline_basis &lt;- bs(dd$x, knots = knots, degree = 3, intercept = TRUE)
X_spline &lt;- as.matrix(spline_basis)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-10-1.png" width="816" /></p>
</div>
<div id="data-list-for-stan" class="section level4">
<h4>Data list for stan</h4>
<pre class="r"><code>stan_data &lt;- list(
  N = nrow(dd),           # number of observations
  K = k,                  # number of clusters
  M = ncol(X_spline),     # number of basis functions
  cluster = dd$cluster,   # vector of cluster ids
  X_spline = X_spline,    # basis function values
  y = dd$y                # resonse variable
)</code></pre>
</div>
<div id="run-stan-model" class="section level4">
<h4>Run stan model</h4>
<pre class="r"><code>mod &lt;- cmdstan_model(&quot;code/spline.stan&quot;)

fit &lt;- mod$sample(
  data = stan_data,
  chains = 4,
  iter_warmup = 500,
  iter_sampling = 2000,
  parallel_chains = 4,
  refresh = 0 # print update every 500 iters
)</code></pre>
<pre><code>## Running MCMC with 4 parallel chains...</code></pre>
<pre><code>## Chain 2 finished in 6.7 seconds.
## Chain 3 finished in 7.3 seconds.
## Chain 1 finished in 7.6 seconds.
## Chain 4 finished in 7.5 seconds.
## 
## All 4 chains finished successfully.
## Mean chain execution time: 7.3 seconds.
## Total execution time: 7.7 seconds.</code></pre>
<pre class="r"><code>draws &lt;- as_draws_df(fit$draws())

ds &lt;- summarize_draws(draws, .fun = median) |&gt; data.table()
dd$np &lt;- ds[substr(variable, 1, 3) == &quot;y_p&quot;, 2]</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-13-1.png" width="816" /></p>
</div>
</div>
<div id="penalized-spline" class="section level3">
<h3>Penalized spline</h3>
<pre class="stan"><code>model {
  sigma_y ~ normal(0, 1);
  sigma_beta ~ normal(0, 1);

  // Priors for beta
  for (k in 1:K) {
    beta[k] ~ normal(0, sigma_beta);
  }
  
  //Penalization
  for (k in 1:K) {
    target += -lambda * sum(square(D2_spline * beta[k]&#39;));
  }
  
  // Likelihood
  for (n in 1:N) {
    y[n] ~ normal(X_spline[n] * beta[cluster[n]]&#39;, sigma_y);
  }
}</code></pre>
<pre class="r"><code>D2 &lt;- dbs(dd$x, knots = knots, degree = 3, derivs = 2, intercept = TRUE)
D2_spline &lt;- as.matrix(D2)

stan_data &lt;- list(
  N = nrow(dd),
  K = k,
  M = ncol(X_spline),
  cluster = dd$cluster,
  X_spline = X_spline,
  D2_spline = D2_spline,
  y = dd$y,
  lambda = 0.00001
)</code></pre>
<pre><code>## Running MCMC with 4 parallel chains...</code></pre>
<pre><code>## Chain 4 finished in 18.7 seconds.
## Chain 1 finished in 18.8 seconds.
## Chain 2 finished in 18.8 seconds.
## Chain 3 finished in 18.9 seconds.
## 
## All 4 chains finished successfully.
## Mean chain execution time: 18.8 seconds.
## Total execution time: 19.0 seconds.</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-17-1.png" width="816" /></p>
<p>We’d probably want to use a cubic spline - but I wanted to illustrate the impact of penalization.</p>
<p>
<p><small><font color="darkkhaki">
Reference:</p>
<p>OpenAI. (2024). ChatGPT (September 30, Version) [Large language model]. <a href="https://chat.openai.com/" class="uri">https://chat.openai.com/</a></p>
<p>Support:</p>
<p>This work is supported within the National Institutes of Health (NIH) Health Care Systems Research Collaboratory by cooperative agreement UG3/UH3AT009844 from the National Institute on Aging. This work also received logistical and technical support from the NIH Collaboratory Coordinating Center through cooperative agreement U24AT009676. Support was also provided by the NIH National Center for Complementary and Integrative Health Administrative Supplement for Complementary Health Practitioner Research Experience through cooperative agreement UH3AT009844 and by the National Center for Complementary and Integrative Health of the National Institutes of Health under award number UH3AT009844. Work also supported by Memorial Sloan Kettering Cancer Center Support Grant/Core Grant P30CA008748. The author was the sole writer of this blog post and has no conflicts. The content is solely the responsibility of the author and does not necessarily represent the official views of the National Institutes of Health.</p>
</font></small>
</p>
</div>
