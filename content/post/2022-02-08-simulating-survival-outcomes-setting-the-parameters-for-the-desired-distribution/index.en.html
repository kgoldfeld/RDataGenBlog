---
title: 'Simulating survival outcomes: setting the parameters for the desired distribution'
author: Package Build
date: '2022-02-08'
slug: []
categories: []
tags:
  - R
  - simulation
  - survival analysis
type: ''
subtitle: ''
image: ''
draft: TRUE
---

<script src="{{< blogdown/postref >}}index.en_files/header-attrs/header-attrs.js"></script>


<p>The package <code>simstudy</code> has some functions that facilitate generating survival data using an underlying Weibull distribution. Originally, I added this to the package because I thought it would be interesting to try to do, and I figured it would be useful for me someday (and hopefully some others, as well). Well, now I am working on a project that involves evaluating at least two survival-type processes that are occurring simultaneously. To get a handle on the analytic models we might use, I’ve started to try to simulate a simplified version of the data that we have.</p>
<p>At some point, I’d like to describe the motivating simulations in more detail. But here, I want to focus more generally on the underlying survival data generating process used in <code>simstudy</code>, looking in particular at how to identify the parameters so that the simulated data will come close to matching a desired distribution.</p>
<div id="weibull-cox-proprtional-hazard-data-generation-process" class="section level2">
<h2>Weibull-Cox proprtional hazard data generation process</h2>
<p>This underlying data generating process draws from a Weibull distribution and satisfies the requirements of a Cox proportional hazards model. The approach was drawn directly from this <a href="https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.2059" target="_blank"><em>Bender, Augustin, and Blettner</em></a> paper, so head over there if you really want the details.</p>
<p>The times to survival <span class="math inline">\(T\)</span> are generated using three parameters, <span class="math inline">\(\lambda\)</span> (scale), <span class="math inline">\(\nu\)</span> (shape), and <span class="math inline">\(f\)</span>, which is really <span class="math inline">\(\mathbf{\beta^\prime x}\)</span> from a Cox proportional hazard model that may include a covariate vector <span class="math inline">\(\mathbf{x}\)</span>. In the examples here, there will only be an intercept.</p>
<p><span class="math display">\[T = \left[ \frac{- \lambda \ \text{log}(u) }{\text{exp}(f)}  \right] ^ \nu\]</span></p>
<p>A single instance <span class="math inline">\(T\)</span> is “drawn” from the Weibull distribution by generating <span class="math inline">\(u\)</span> from the uniform <span class="math inline">\(U(0,1)\)</span> distribution. It will be the case that <span class="math inline">\((1-u) \%\)</span> of the survival times <span class="math inline">\(T\)</span> will fall below the values of <span class="math inline">\(T\)</span> determined by <span class="math inline">\(u\)</span>; this will be helpful later when we need to generate data with specific distributions in mind.</p>
<p>It turns out that we don’t really need the scale parameter <span class="math inline">\(\lambda\)</span>, because it can be absorbed into <span class="math inline">\(f\)</span>, so in all the examples that follow, we’ll set <span class="math inline">\(\lambda = 1\)</span>, which leaves us with</p>
<p><span class="math display">\[T = \left[ \frac{- \text{log}(u) }{\text{exp}(f)}  \right] ^ \nu\]</span></p>
<div id="visualizing-the-survival-curves" class="section level3">
<h3>Visualizing the survival curves</h3>
<p>Weibull distribution data generation is extremely flexible, and can provide an infinite number of distributions of a wide range of shapes. Here are some examples, but first, to get things started, here are the packages needed to run all the code here:</p>
<pre class="r"><code>library(simstudy)
library(data.table)
library(ggplot2)</code></pre>
<p>The function <code>get_surv</code> generates data for the survival curve. It is deterministic in that it does not generate draws of <span class="math inline">\(u\)</span>, but calculates a specific <span class="math inline">\(T\)</span> for each value of <span class="math inline">\(u\)</span> distribution evenly between 0 and 1.</p>
<pre class="r"><code>get_surv &lt;- function(f, shape, n = 100) {
  
  u &lt;- seq(1, 0.001, length = n)
  
  dd &lt;- data.table(
    f = f,
    shape = shape,
    T = (-(log(u)/exp(f)))^(shape),
    p = round(1 - cumsum(rep(1/length(u), length(u))), 3)
  )
  
  return(dd)

}

get_surv(-10, .3, n = 10)</code></pre>
<pre><code>##       f shape        T   p
##  1: -10   0.3  0.00000 0.9
##  2: -10   0.3 10.56988 0.8
##  3: -10   0.3 13.26785 0.7
##  4: -10   0.3 15.31471 0.6
##  5: -10   0.3 17.11875 0.5
##  6: -10   0.3 18.85288 0.4
##  7: -10   0.3 20.64903 0.3
##  8: -10   0.3 22.68619 0.2
##  9: -10   0.3 25.40811 0.1
## 10: -10   0.3 35.86613 0.0</code></pre>
<p>Here are 16 arbitrary distributions using four different values of <span class="math inline">\(f\)</span> and <span class="math inline">\(\nu\)</span>. Each panel represents a different value of <span class="math inline">\(\nu\)</span>, ranging from 0.16 to 0.22.</p>
<pre class="r"><code>f &lt;- c(-26, -27, -28, -29)
shape &lt;- c(0.16, .18, .20, .22)

eg &lt;- expand.grid(f=f, shape=shape)
eg &lt;- asplit(eg, MARGIN = 1)

l &lt;- lapply(eg, function(x) get_surv(x[1], x[2]))
l &lt;- rbindlist(l)

ggplot(data = l, aes(x = T, y = p)) +
  geom_line(aes(group = f, color = factor(f))) +
  ylim(0,1) +
  xlim(0, 800) +
  facet_grid ( ~ shape) +
  theme(panel.grid = element_blank(),
        axis.text = element_text(size = 7.5)) +
  scale_color_manual(
    values = c(&quot;#7D9D33&quot;, &quot;#CED38C&quot;, &quot;#DCC949&quot;, &quot;#BCA888&quot;, &quot;#CD8862&quot;, &quot;#775B24&quot;),
    name = &quot;  f&quot;
  )</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-3-1.png" width="768" /></p>
</div>
</div>
<div id="generating-a-particular-distribution" class="section level2">
<h2>Generating a particular distribution</h2>
<p>The interpretation of the parameters is a bit opaque. If we have covariates embedded in <span class="math inline">\(f\)</span> the coefficients do have pretty clear interpretations as hazard ratios. But the intercept term (remember, I have set <span class="math inline">\(\lambda = 1\)</span>) really defines the scale. So how do we go about selecting values for <span class="math inline">\(f\)</span> and <span class="math inline">\(\nu\)</span> to get the desired distribution?</p>
<p>If we can reasonably characterize the desired distribution by two points on the survival curve, the task actually becomes remarkably easy. By this, I mean we pick two time points and a probability of survival for each time point. For example, we may want a distribution with 80% survival until day 180 and 20% survival at day 365. Or, in a second scenario, we may want to have 90% survival at day 180 and 40% survival at day 365. Here is an animation of how we might find the curves by adjusting <span class="math inline">\(f\)</span> and <span class="math inline">\(\nu\)</span> (see <a href="#addendum">addendum</a> for code to generate this):</p>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-4-1.gif" /><!-- --></p>
<div id="determining-the-parameter-values" class="section level3">
<h3>Determining the parameter values</h3>
<p>If we have two points in mind, there is an extremely simple analytic solution that can derive <span class="math inline">\(f\)</span> and <span class="math inline">\(\nu\)</span> so that we can identify a Weibull-Cox based survival curve that is guaranteed to pass through both points.</p>
<p>For any time point <span class="math inline">\(T\)</span>, we have from the equation above</p>
<span class="math display">\[\begin{aligned}
log(T) &amp;= \nu \ \text{log} \left[ \frac{-\text{log}(u)}{exp(f)}  \right] \\ 
\\ 
&amp;= \nu \ \left ( \text{log}\left[-\text{log}(u)\right] - \text{log}\left[ \text{exp}(f) \right] \right ) \\
\\
&amp;= \nu \ (\text{log}\left[-\text{log}(u)\right] - f)
\end{aligned}\]</span>
<p>If we have desired points <span class="math inline">\((T_1,u_1)\)</span> and <span class="math inline">\((T_2,u_2)\)</span>, then we write can a simple system of two equations with two unknowns, <span class="math inline">\(f^*\)</span> and <span class="math inline">\(\nu^*\)</span>, the target parameters:</p>
<p><span class="math display">\[ \text{log}(T_1) = \nu \ (\text{log} \left[ -\text{log}(u_1)\right] - f)\]</span></p>
<p><span class="math display">\[ \text{log}(T_2) = \nu \ (\text{log} \left[ -\text{log}(u_2)\right] - f)\]</span></p>
<p>Using simple algebra, we can rearrange terms to provide solutions for <span class="math inline">\(f\)</span> and <span class="math inline">\(\nu\)</span> (I’ll spare you the extra steps):</p>
<p><span class="math display">\[\nu^* = \frac{\text{log}(T_2) - \text{log}(T_1)}{\text{log}(-\text{log}(u_2)) - \text{log}(-\text{log}(u_1))}\]</span></p>
<p><span class="math display">\[f^* = \text{log}(-\text{log}(u_1)) - \nu^{*^{-1}} \text{log}(T_1)\]</span></p>
</div>
<div id="scenario-three" class="section level3">
<h3>Scenario three</h3>
<p>If we want a curve that where there is 95% survival at day 180 and 40% survival at the end of 2 years, the desired parameters are</p>
<p><span class="math display">\[\nu^* = \frac{\text{log}(365*2) - \text{log}(180)}{\text{log}(-\text{log}(0.40)) - \text{log}(-\text{log}(0.95))} = \frac{1.400}{2.883} = 0.486\]</span></p>
<p><span class="math display">\[f^* = \text{log}(-\text{log}(0.95)) - \frac{1}{0.486} \text{log}(180) = -2.970 - 10.685 = -13.655\]</span></p>
<p><br></p>
<p>We can generate points along this curve and then plot them:</p>
<pre class="r"><code>dsurv &lt;- get_surv(-13.655, 0.486, n = 1000)
dsurv</code></pre>
<pre><code>##             f shape          T     p
##    1: -13.655 0.486    0.00000 0.999
##    2: -13.655 0.486   26.55994 0.998
##    3: -13.655 0.486   37.20774 0.997
##    4: -13.655 0.486   45.32308 0.996
##    5: -13.655 0.486   52.13693 0.995
##   ---                               
##  996: -13.655 0.486 1714.16472 0.004
##  997: -13.655 0.486 1748.87893 0.003
##  998: -13.655 0.486 1792.58585 0.002
##  999: -13.655 0.486 1852.33947 0.001
## 1000: -13.655 0.486 1950.02084 0.000</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-6-1.png" width="528" /></p>
<p>Of course, what we really want to do is sample from a distribution defined by these parameters in order to conduct simulation experiments, not just generate and look at deterministic functions. This would include adding covariates and possibly censoring. But all of that remains for another day.</p>
<p>
<p><small><font color="darkkhaki">
Reference:</p>
<p>Bender, Ralf, Thomas Augustin, and Maria Blettner. “Generating survival times to simulate Cox proportional hazards models.” Statistics in medicine 24, no. 11 (2005): 1713-1723.</p>
</font></small>
</p>
<p><a name="addendum"></a></p>
<p> </p>
</div>
</div>
<div id="addendum" class="section level2">
<h2>Addendum</h2>
<p>Here is the code that is used to generate the animated plot, which done with the <code>gganimate</code> package:</p>
<pre class="r"><code>library(gganimate)

sdd &lt;- list()

sdd[[1]] &lt;- get_surv(-6,  1, n = 1000)
sdd[[2]] &lt;- get_surv(-7.566, 0.783 , n = 1000)
sdd[[3]] &lt;- get_surv(-9.981, 0.587, n = 1000)
sdd[[4]] &lt;- get_surv(-11.137, 0.521, n = 1000)
sdd[[5]] &lt;- get_surv(-13.814, 0.417, n = 1000)
sdd[[6]] &lt;- get_surv(-16.014, 0.358, n = 1000)
sdd[[7]] &lt;- get_surv(-6,  1, n = 1000)
sdd[[8]] &lt;- get_surv(-8.125, 0.777 , n = 1000)
sdd[[9]] &lt;- get_surv(-10.183, 0.619, n = 1000)
sdd[[10]] &lt;- get_surv(-12.481, 0.490, n = 1000)
sdd[[11]] &lt;- get_surv(-14.595, 0.414, n = 1000)
sdd[[12]] &lt;- get_surv(-18.139, 0.327, n = 1000)

k &lt;- length(sdd)

sdds &lt;- lapply(1:k, function(x) sdd[[x]][ , c(&quot;iter&quot;, &quot;color&quot;) := list(x, &quot;black&quot;)])
sdds[[k/2]][, color := &quot;green&quot;]
sdds[[k]][, color := &quot;green&quot;]
sdd &lt;- rbindlist(sdds)

targets &lt;- data.table(iter = 1:k, days1 = rep(180, k), days2 = rep(365, k),
  p1 = rep(c(.8, .9), each = k/2), p2 = rep(c(.2, .4), each = k/2))

dt_anot &lt;- sdd[, .SD[1,], keyby = iter]
dt_anot[iter &lt;= (k/2), targets := 1]
dt_anot[iter &gt; (k/2), targets := 2]
dt_anot[, targets := factor(targets, labels = c(&quot;Scenario one&quot;, &quot;Scenario two&quot;))]
dt_anot[, color := &quot;black&quot;]
dt_anot[iter == (k/2), color := &quot;green&quot;]
dt_anot[iter == k, color := &quot;green&quot;]

a &lt;- ggplot() +
  geom_point(data = targets, aes(x = days1, y=p1), pch = 1, size = 2) +
  geom_point(data = targets, aes(x = days2, y=p2), pch = 1, size = 2) +
  geom_point(data = sdd, aes(x = T, y = p, group = p, color = color), size = .2) +
  geom_vline(xintercept = c(180, 365), lty = 1, size = .3, color = &quot;grey70&quot;) +
  geom_text(x = 750, y = .68, size = 5.5, hjust = &quot;left&quot;, fontface = &quot;bold&quot;,
            aes(label = targets), data = dt_anot) +
  geom_text(x = 750, y = .6, size = 5.5, hjust = &quot;left&quot;,
            aes(label = paste(&quot;f:&quot;, f), color = color), data = dt_anot) +
  geom_text(x = 750, y = .54, size = 5.5, hjust = &quot;left&quot;,
            aes(label = paste(&quot;shape:&quot;, shape), color = color), data = dt_anot) +
  scale_x_continuous(limits = c(0, 1250), 
                     breaks = c(seq(0, 1250, by = 250), 180, 365), name = &quot;time&quot;) +
  scale_color_manual(values = c(&quot;black&quot;,&quot;#7D9D33&quot;)) +
  scale_y_continuous(limits = c(0.05, 0.995), 
                     breaks = c(0.2, 0.4, 0.6, 0.8), name = &quot;probability of survival&quot;) +
  theme(panel.grid = element_blank(),
        legend.position = &quot;none&quot;) +
  transition_states(iter, state_length = 1, transition_length = 1) 

animate(a, duration = 24, fps = 10, height = 350, width = 550)</code></pre>
<p><strong><em>A note on where the parameters for the animation came from</em></strong></p>
<p>You may be wondering where the parameters used in the animation come from. I really wanted to generate a series of curves that started at a fair distance from the true value and converged to the right spot. My idea was to use a simple loss function that involved the unknown parameters <span class="math inline">\(f\)</span> and <span class="math inline">\(\nu\)</span>, which would be optimized (in this case minimized) at the correct values (the same as those derived above). If I could recover the interim values of optimization algorithm, those would provide a sequence of parameters and curves the converge on the true values.</p>
<p>The loss function is a simple squared loss, which is the sum of the squared loss for both points that define the curve:</p>
<p><span class="math display">\[\left[ \hat{\nu} \ (\text{log} \left[ -\text{log}(u_1)\right] - \hat{f}) - \text{log}(T_1) \right]^2 + \left[ \hat{\nu} \ (\text{log} \left[ -\text{log}(u_2)\right] - \hat{f}) - \text{log}(T_2) \right]^2\]</span></p>
<p>This is implemented as function <code>fx</code>, which is to be optimized using function <code>optim</code>. I know this may not be the best optimization option in R, but given that this is quite a simple problem, it should suffice. In the function <span class="math inline">\(x[1]\)</span> represents <span class="math inline">\(f\)</span>, and <span class="math inline">\(x[2]\)</span> represents <span class="math inline">\(\nu\)</span>.</p>
<pre class="r"><code>fx &lt;- function(x, p, times) {
  (x[2]*(log(-log(p[1])) - x[1]) - log(times[1])) ^ 2 + 
  (x[2]*(log(-log(p[2])) - x[1]) - log(times[2])) ^ 2 
}</code></pre>
<p>The optimization provides starting values for <span class="math inline">\(f\)</span> and <span class="math inline">\(\nu\)</span>. I chose values of <span class="math inline">\(f\)</span> and <span class="math inline">\(\nu\)</span> that would locate the initial curve between the two target points. <span class="math inline">\(\nu\)</span> is constrained to be non-negative (and <span class="math inline">\(f\)</span> is unconstrained). The key here is that the <em>trace</em> option is set so that interim values of <span class="math inline">\(f\)</span> and <span class="math inline">\(\nu\)</span> are reported. I am not showing the full output here, because it is quite lengthy. I only used four interim values (plus the starting and ending values) to create the animation. The final output includes the values of <span class="math inline">\(f\)</span> and <span class="math inline">\(\nu\)</span> that optimize the quadratic loss:</p>
<pre class="r"><code>optim(
  par = c(-(log((180+365)/2) - log(-log(.5))), 1), 
  fn = fx, 
  p = c(.8, .2), 
  times = c(180, 365),
  method = &quot;L-BFGS-B&quot;, 
  lower = c(-Inf, 0),
  upper = c(Inf, Inf),
  control= list(trace = 5)
)</code></pre>
<pre><code>## $par
## [1] -16.0137061   0.3577952
## 
## $value
## [1] 1.065948e-13
## 
## $counts
## function gradient 
##       33       33 
## 
## $convergence
## [1] 0
## 
## $message
## [1] &quot;CONVERGENCE: REL_REDUCTION_OF_F &lt;= FACTR*EPSMCH&quot;</code></pre>
<p>Incidentally, our analytic formulas give us</p>
<p><span class="math display">\[\nu^* = \frac{\text{log}(365) - \text{log}(180)}{\text{log}(-\text{log}(0.2)) - \text{log}(-\text{log}(0.8))} = 0.3577951\]</span></p>
<p><span class="math display">\[f^* = \text{log}(-\text{log}(0.8)) - \frac{1}{0.3577951} \text{log}(180) =-16.01371\]</span></p>
<p><br></p>
</div>
