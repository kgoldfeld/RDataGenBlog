---
title: A GAM for time trends in a stepped-wedge trial with a binary outcome
author: Package Build
date: '2023-01-17'
slug: []
categories: []
tags:
  - R
  - Cluster randomized trials
  - GAM
type: ''
subtitle: ''
image: ''
draft: TRUE
---



<p>In a previous <a href="https://www.rdatagen.net/post/2022-12-13-modeling-the-secular-trend-in-a-stepped-wedge-design/" target="_blank">post</a>, I described some of my early efforts to analyze data from a stepped-wedge, cluster-randomized trial using a generalized additive model (a GAM), focusing on continuous outcomes. I have spent the past few weeks developing a similar model for a binary outcome, and have started to explore model comparison and methods to evaluate goodness-of-fit. I am putting it here so that I have a record of what I’ve done, and, more importantly, in case anyone might find this helpful.</p>
<div id="data-generation" class="section level3">
<h3>Data generation</h3>
<p>The data generation process used here follows along pretty closely with the <a href="https://www.rdatagen.net/post/2022-12-13-modeling-the-secular-trend-in-a-stepped-wedge-design/" target="_blank">earlier post</a>, except the outcome has changed from continuous to binary. And I’ve increased the correlation in period effects because it doesn’t seem like things should change so fast from period to period, particularly if the time periods themselves are relatively short. The correlation still decays over time.</p>
<pre class="r"><code>library(simstudy)
library(ggplot2)
library(data.table)
library(mgcv)
library(gratia)
library(patchwork)
library(mgcViz)
library(DHARMa)
library(itsadug)</code></pre>
<p>The data generation process is as follows, with 24 sites, 25 time periods, and 100 individuals per site per time period:</p>
<p><span class="math display">\[
y_{ijk} \sim Bin\left(p_{jk}\right)\\
log\left( \frac{p_{ijk}}{1-p_{ijk}} \right) = -1.5 + a_j + b_{jk} + 0.65 A_{jk}
\]</span></p>
<p>where <span class="math inline">\(y_{ijk} \in \{0,1\}\)</span> is the outcome, and <span class="math inline">\(p(y_{ijk} = 1) = p_{ijk}\)</span>. The log-odds ratio is a linear function of the site specific effect <span class="math inline">\(a_{j}\)</span>, the site-specific period <span class="math inline">\(k\)</span> effect <span class="math inline">\(b_{jk}\)</span>, and treatment status of site <span class="math inline">\(j\)</span> in period <span class="math inline">\(k\)</span>, <span class="math inline">\(A_{jk} \in \{ 0, 1\}\)</span> depending the the stage of stepped wedge. The treatment effect in this case (an odds ratio) is <span class="math inline">\(exp(0.65) = 1.9\)</span>. The <span class="math inline">\(a_j \sim N(0, 0.6\)</span>. The vector of site-period effects <span class="math inline">\(\mathbf{b_j} \sim N(0, \Sigma_b)\)</span>, where <span class="math inline">\(\Sigma_b = DRD\)</span> is a <span class="math inline">\(25 \times 25\)</span> covariance matrix based on a diagonal matrix <span class="math inline">\(D\)</span> and an auto-regressive correlation structure <span class="math inline">\(R\)</span>:</p>
<p><span class="math display">\[
D = \sqrt{0.1} * I_{25 \times 25}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
R =\begin{bmatrix}
1 &amp; \rho &amp; \rho^2 &amp; \dots &amp; \rho^{24} \\
\rho &amp; 1 &amp; \rho &amp; \dots &amp; \rho^{23} \\
\rho^2 &amp; \rho &amp; 1 &amp; \dots &amp; \rho^{22} \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
\rho^{24} &amp; \rho^{23} &amp; \rho^{22} &amp; \dots &amp; 1 \\
\end{bmatrix}, \ \ \rho = 0.95
\]</span></p>
<p>Here is the implementation of this data generation process using <code>simstudy</code>:</p>
<pre class="r"><code>def &lt;- defData(varname = &quot;a&quot;, formula = 0, variance = 0.6)
def &lt;- defData(def, varname = &quot;mu_b&quot;, formula = 0, dist = &quot;nonrandom&quot;)
def &lt;- defData(def, varname = &quot;s2_b&quot;, formula = 0.1, dist = &quot;nonrandom&quot;)
  
defOut &lt;- defDataAdd(varname = &quot;y&quot;, 
  formula = &quot;-1.5 + a + b + 0.65 * A&quot;, 
  dist = &quot;binary&quot;, link=&quot;logit&quot;
)

set.seed(1913)

ds &lt;- genData(24, def, id = &quot;site&quot;)
ds &lt;- addPeriods(ds, 25, &quot;site&quot;, perName = &quot;k&quot;)
ds &lt;- addCorGen(
  dtOld = ds, idvar = &quot;site&quot;, 
  rho = 0.95, corstr = &quot;ar1&quot;,
  dist = &quot;normal&quot;, param1 = &quot;mu_b&quot;, param2 = &quot;s2_b&quot;, cnames = &quot;b&quot;
)

ds &lt;- trtStepWedge(ds, &quot;site&quot;, nWaves = 24, 
  lenWaves = 1, startPer = 1, 
  grpName = &quot;A&quot;, perName = &quot;k&quot;
)

ds$site &lt;- as.factor(ds$site)
  
dd &lt;- genCluster(ds, &quot;timeID&quot;, numIndsVar = 100, level1ID = &quot;id&quot;)
dd &lt;- addColumns(defOut, dd)

dd</code></pre>
<pre><code>##        site  k     a mu_b s2_b timeID      b startTrt A    id y
##     1:    1  0 0.142    0  0.1      1 -0.867        1 0     1 0
##     2:    1  0 0.142    0  0.1      1 -0.867        1 0     2 0
##     3:    1  0 0.142    0  0.1      1 -0.867        1 0     3 0
##     4:    1  0 0.142    0  0.1      1 -0.867        1 0     4 0
##     5:    1  0 0.142    0  0.1      1 -0.867        1 0     5 0
##    ---                                                         
## 59996:   24 24 0.879    0  0.1    600 -0.546       24 1 59996 0
## 59997:   24 24 0.879    0  0.1    600 -0.546       24 1 59997 0
## 59998:   24 24 0.879    0  0.1    600 -0.546       24 1 59998 0
## 59999:   24 24 0.879    0  0.1    600 -0.546       24 1 59999 1
## 60000:   24 24 0.879    0  0.1    600 -0.546       24 1 60000 0</code></pre>
<p>Here is visualization of the observed proportions of a good outcome (<span class="math inline">\(y = 1\)</span>) by site and period:</p>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
<div id="model-estimation-using-a-gam" class="section level3">
<h3>Model estimation using a GAM</h3>
<p>The first model will include a treatment effect and an overall smooth function of time, and then a site-specific smooth “effect”. I am using the function <code>bam</code> in the <code>mgcv</code> package, though I could use the <code>gamm</code> function, the <code>gam</code> function, or even the <code>gamm4</code> function of the <code>gamm4</code> package. In this case, all provide quite similar estimates, but <code>bam</code> has the advantage of running faster with this large data set. Here is the model:</p>
<p><span class="math display">\[
\text{log-odds}\left[P(y_{ijk} = 1)\right] = \beta_0 + \beta_1 A_{jk} + s(k) + s_j(k)
\]</span></p>
<pre class="r"><code>fit.A &lt;- bam(
  y ~ A + s(k) + s(k, site, bs = &quot;fs&quot;), 
  data = dd, 
  method = &quot;fREML&quot;,
  family = &quot;binomial&quot;
)</code></pre>
<pre class="r"><code>summary(fit.A)</code></pre>
<pre><code>## 
## Family: binomial 
## Link function: logit 
## 
## Formula:
## y ~ A + s(k) + s(k, site, bs = &quot;fs&quot;)
## 
## Parametric coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -1.4804     0.1583   -9.35   &lt;2e-16 ***
## A             0.6951     0.0529   13.15   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##             edf Ref.df  Chi.sq p-value    
## s(k)       2.77   3.34    1.29    0.64    
## s(k,site) 91.69 238.00 5640.97  &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.122   Deviance explained = 10.6%
## fREML =  85129  Scale est. = 1         n = 60000</code></pre>
<p>The plot on the right shows the “average” smooth of time across all sites, and the one on the left shows the site-specific effects over time. The between-site variability is quite apparent.</p>
<pre class="r"><code>draw(fit.A) +
  plot_annotation(&quot;&quot;) &amp;
  theme(panel.grid = element_blank())</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
<div id="goodness-of-fit" class="section level3">
<h3>Goodness of fit</h3>
<p>I am particularly interested in understanding if the model is a good fit for the data generation process. One way to do this is simulate data from the model repeatedly, and the visually assess whether the observed data fits into the range of simulations. I am using the <code>simulate.gam</code> function from the <code>mgcViz</code> package.</p>
<p>In this case, I created 95% bands based on the simulated data, and it looks like observed data fits into the bands reasonably well.</p>
<pre class="r"><code>sim &lt;- simulate.gam(fit.A, nsim = 1000)

ls &lt;- split(sim, rep(1:ncol(sim), each = nrow(sim)))

dq &lt;- lapply(ls, 
  function(x) {
    d &lt;- cbind(dd, sim = x)
    d[, .(obs = mean(y), sim = mean(sim)), keyby = .(site, k)]
  }
)

dl &lt;- rbindlist(dq, idcol = &quot;.id&quot;)
df &lt;- dl[, .(obs = mean(obs), min = quantile(sim, p = 0.025), 
             max = quantile(sim, 0.975)), keyby = .(site, k)]

ggplot(data = df, aes(x= k, y = obs)) +
  geom_ribbon(aes(x = k, ymin = min, ymax = max),
              alpha = 0.2, fill = &quot;forestgreen&quot;) +
  geom_point(color = &quot;forestgreen&quot;, size = 1) +
  
  facet_wrap( ~ site, ncol = 6) +
  theme(panel.grid = element_blank())</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>An alternative way to assess the goodness of fit is to generate a QQ-type plot that will alert us to any deviations. I am using the <code>DHARMa</code> package, which “uses a simulation-based approach to create readily interpretable scaled (quantile) residuals for fitted (generalized) linear mixed models.” The QQ-plot is based on a scaled residual, which is defined as “the value of the empirical density function at the value of the observed data.” The empirical density function comes from the same simulated data I just used to generated the 95% bands. It turns out that these residuals should be uniformly distributed if the model is a good fit. (See <a href="https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html" target="_blank">here</a> for more details.)</p>
<p>The QQ-plot indicates a good fit if all the residuals lie on the diagonal line, as they do here:</p>
<pre class="r"><code>simResp &lt;- matrix(dl$sim, nrow = 600)
obsResp &lt;- dq[[1]]$obs

DHARMaRes = createDHARMa(
  simulatedResponse = simResp, 
  observedResponse = obsResp, 
  integerResponse = F
)

plotQQunif(DHARMaRes, testDispersion = F, testOutliers = F)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-9-1.png" width="480" /></p>
<p>And a plot of the residuals against the predicted values also indicates a uniform distribution:</p>
<pre class="r"><code>plotResiduals(DHARMaRes, quantreg = T)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-10-1.png" width="480" /></p>
<div id="a-model-with-no-site-specific-period-effects" class="section level4">
<h4>A model with no site-specific period effects</h4>
<p>Now, it is clearly a bad idea to fit a model without site-specific time effects, since I generated the data under that very assumption. However, I wanted to make sure the goodness-of-fit tests perform adequately.</p>
<pre class="r"><code>fit.1curve &lt;- bam(
  y ~ A + s(k, k = 4)  , 
  data = dd, 
  method = &quot;fREML&quot;,
  family = &quot;binomial&quot;
)</code></pre>
<p>In this visual representation, the bands clearly are not capturing the site variability:</p>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>And both the QQ- and residual-plots are consistent with the visual plot: this second model is not at all a good fit:</p>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-13-1.png" width="480" /><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-13-2.png" width="480" /></p>
<p>We can formally compare the AIC from each model using function <code>compareML</code> from the package <code>itsadug</code>, which confirms that the model with the site-specific curve is an improvement:</p>
<pre class="r"><code>compareML(fit.A, fit.1curve)</code></pre>
<pre><code>## fit.A: y ~ A + s(k) + s(k, site, bs = &quot;fs&quot;)
## 
## fit.1curve: y ~ A + s(k, k = 4)
## 
## Chi-square test of fREML scores
## -----
##        Model Score Edf Difference    Df   p.value Sig.
## 1 fit.1curve 85146   4                                
## 2      fit.A 85129   7     16.823 3.000 2.352e-07  ***
## 
## AIC difference: -6166.12, model fit.A has lower AIC.</code></pre>
</div>
<div id="a-model-with-no-treatment-effect" class="section level4">
<h4>A model with no treatment effect</h4>
<p>It is not obvious that including a treatment effect is necessary, since the smoothed curve can likely accommodate the shifts arising due to treatment. After all, treatment is confounded with time. So, I am fitting a third model.</p>
<pre class="r"><code>fit.noA &lt;- bam(
  y ~ s(k) + s(k, site, bs = &quot;fs&quot;), 
  data = dd, 
  method = &quot;fREML&quot;,
  family = &quot;binomial&quot;
)</code></pre>
<p>The QQ-plot indicates that this model fits quite well, which is not entirely a surprise. (The 95% band plot as looks reasonable, but I haven’t included here.)</p>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-16-1.png" width="480" /></p>
<p>However, if we compare the two models using AIC, the model with the treatment effect does appear superior:</p>
<pre class="r"><code>compareML(fit.A, fit.noA)</code></pre>
<pre><code>## fit.A: y ~ A + s(k) + s(k, site, bs = &quot;fs&quot;)
## 
## fit.noA: y ~ s(k) + s(k, site, bs = &quot;fs&quot;)
## 
## Model fit.noA preferred: lower fREML score (5.899), and lower df (1.000).
## -----
##     Model Score Edf Difference    Df
## 1   fit.A 85129   7                 
## 2 fit.noA 85123   6     -5.899 1.000
## 
## AIC difference: -81.59, model fit.A has lower AIC.</code></pre>
</div>
</div>
