---
title: Generating variable cluster sizes to assess power in cluster randomize trials
author: Package Build
date: '2023-04-18'
slug: []
categories: []
tags:
  - R
  - Cluster randomized trials
type: ''
subtitle: ''
image: ''
draft: TRUE
---



<p>In a recent discussion with a collaborator about setting the sample size for a proposed cluster randomized trial, the question of variable cluster sizes came up. Given a fixed overall sample size, it is generally better (in terms of statistical power) if the sample is equally distributed across the different clusters; highly variable cluster sizes increase the standard errors of effect size estimates and reduce the ability to determine if an intervention or treatment is effective.</p>
<p>When I started to prepare a quick simulation to demonstrate this phenomenon, I quickly realized that there was no easy way using <code>simstudy</code> (my simulation package of choice) to generate the desired variable cluster sizes while holding the total sample size constant. I thought about it for a bit and came up with a simple solution that is now implemented and available for download (<font size="3"><code>devtools::install_github("kgoldfeld/simstudy")</code></font>). My plan here is to describe this solution, and then show the results of the simulation that inspired the need for (and uses) the new functionality.</p>
<div id="quick-recap-on-how-to-generate-cluster-data-with-simstudy" class="section level3">
<h3>Quick recap on how to generate cluster data with simstudy</h3>
<p>There are two ways I would have typically simulated clustered data using a data generation process defined by a linear mixed-effects model. In both cases, we would define a variable <span class="math inline">\(n\)</span> the represents the number of subjects per cluster.</p>
<p>In the first approach, we would assume perfectly balanced cluster sizes and fix <span class="math inline">\(n\)</span> at a constant value. In the example, we will generate 10 clusters with 20 members each. In this case, I am generating the cluster-level random effect and treatment assignment. The individual-level outcome is a function of the treatment assignment and the cluster effect, as well as random individual-level variation. All of this is specified in the data generation definitions:</p>
<pre class="r"><code>library(simstudy)

d0 &lt;- defData(varname = &quot;n&quot;, formula = 20, dist = &quot;nonrandom&quot;)
d0 &lt;- defData(d0, varname = &quot;a&quot;, formula = 0, variance = 0.33)
d0 &lt;- defData(d0, varname = &quot;rx&quot;, formula = &quot;1;1&quot;, dist = &quot;trtAssign&quot;)

d1 &lt;- defDataAdd(varname = &quot;y&quot;, formula = &quot;18 + 1.6 * rx + a&quot;, 
          variance = 16, dist = &quot;normal&quot;)</code></pre>
<p>The data are generated in two steps. First, the cluster-level data are generated:</p>
<pre class="r"><code>set.seed(2761)

dc &lt;- genData(10, d0, &quot;site&quot;)
dc</code></pre>
<pre><code>##     site  n       a rx
##  1:    1 20 -0.3548  1
##  2:    2 20 -1.1232  1
##  3:    3 20 -0.5963  0
##  4:    4 20 -0.0503  1
##  5:    5 20  0.0894  0
##  6:    6 20  0.5294  1
##  7:    7 20  1.2302  0
##  8:    8 20  0.9663  1
##  9:    9 20  0.0993  0
## 10:   10 20  0.6508  0</code></pre>
<p>And then the individual level data are generated, <span class="math inline">\(n = 20\)</span> subjects for each site:</p>
<pre class="r"><code>dd &lt;- genCluster(dc, &quot;site&quot;, &quot;n&quot;, &quot;id&quot;)
dd &lt;- addColumns(d1, dd)
dd</code></pre>
<pre><code>##      site  n      a rx  id    y
##   1:    1 20 -0.355  1   1 17.7
##   2:    1 20 -0.355  1   2 16.2
##   3:    1 20 -0.355  1   3 19.2
##   4:    1 20 -0.355  1   4 20.6
##   5:    1 20 -0.355  1   5 14.7
##  ---                           
## 196:   10 20  0.651  0 196 25.3
## 197:   10 20  0.651  0 197 22.1
## 198:   10 20  0.651  0 198 13.2
## 199:   10 20  0.651  0 199 15.6
## 200:   10 20  0.651  0 200 13.8</code></pre>
<p>If we want <em>variable</em> cluster sizes, we could slightly modify the data definitions so that <span class="math inline">\(n\)</span> is no longer constant. (From here on out, I am just generating <span class="math inline">\(n\)</span> and the cluster-level data without the random effects and treatment assignment, but I could have just as easily included the full data.) Here, I am using the Poisson distribution, but I could use the negative binomial distribution if I wanted more variation across clusters:</p>
<pre class="r"><code>d0 &lt;- defData(varname = &quot;n&quot;, formula = 20, dist = &quot;poisson&quot;)
genData(10, d0, &quot;site&quot;)</code></pre>
<pre><code>##     site  n
##  1:    1 13
##  2:    2 18
##  3:    3 21
##  4:    4 26
##  5:    5 25
##  6:    6 27
##  7:    7 23
##  8:    8 30
##  9:    9 23
## 10:   10 20</code></pre>
<p>This is great, but the total sample size is no longer fixed at 200 (here we have randomly generated 226 individuals). The total will vary from sample to sample. So, if we want to have both across-cluster variability <em>and</em> constant total sample size, we need a new approach.</p>
</div>
<div id="new-approach-using-simstudy" class="section level3">
<h3>New approach using simstudy</h3>
<p>There is a new <code>simstudy</code> distribution called “clusterSize”, which requires two parameters: the (fixed) total sample size (input into the <em>formula</em> field) and a (non-negative) dispersion measure that represents the variability across clusters (input into the <em>variance</em> field). (The idea behind the data generation is described in the <a href="#addendum">addendum</a>.) If the dispersion is set to <span class="math inline">\(0\)</span>, then we will have constant cluster sizes:</p>
<pre class="r"><code>d0 &lt;- defData(varname = &quot;n&quot;, formula = 200, variance = 0, dist = &quot;clusterSize&quot;)
genData(10, d0, &quot;site&quot;)</code></pre>
<pre><code>##     site  n
##  1:    1 20
##  2:    2 20
##  3:    3 20
##  4:    4 20
##  5:    5 20
##  6:    6 20
##  7:    7 20
##  8:    8 20
##  9:    9 20
## 10:   10 20</code></pre>
<p>When we increase the dispersion, we start to introduce cluster-size variability but keep the overall sample size at 200:</p>
<pre class="r"><code>d0 &lt;- defData(varname = &quot;n&quot;, formula = 200, variance = 0.2, dist = &quot;clusterSize&quot;)
genData(10, d0, &quot;site&quot;)</code></pre>
<pre><code>##     site  n
##  1:    1 20
##  2:    2 28
##  3:    3 25
##  4:    4 24
##  5:    5 28
##  6:    6 22
##  7:    7  7
##  8:    8 13
##  9:    9 22
## 10:   10 11</code></pre>
<p>And we can have extreme variability with a very high dispersion value:</p>
<pre class="r"><code>d0 &lt;- defData(varname = &quot;n&quot;, formula = 200, variance = 5, dist = &quot;clusterSize&quot;)
genData(10, d0, &quot;site&quot;)</code></pre>
<pre><code>##     site   n
##  1:    1  10
##  2:    2   2
##  3:    3  17
##  4:    4   2
##  5:    5  49
##  6:    6 110
##  7:    7   1
##  8:    8   4
##  9:    9   1
## 10:   10   4</code></pre>
</div>
<div id="application-cluster-size-variability-and-statistical-power" class="section level3">
<h3>Application: cluster-size variability and statistical power</h3>
<p>I conducted a simulation experiment to assess the impact of the dispersion parameter on the estimated power for a cluster randomized trial with cluster-level effects. In the simulation (code is available <a href="https://github.com/kgoldfeld/RDataGenBlog/blob/master/content/post/2023-04-18-generating-variable-cluster-sizes-to-assess-power-in-cluster-randomize-trials/code/powerd.R" target="_blank">here</a>), I assumed 20 clusters (10 randomized to the experimental arm, 10 to the control arm) and a total of 500 participants (so on average 25 per arm).</p>
<p>The specific model I used to generate the data was</p>
<p><span class="math display">\[y_{ij} = 20 + 1.6 * A_{i} + a_{i} + e_{ij},\]</span></p>
<p>where <span class="math inline">\(y_{ij}\)</span> is the continuous outcome for subject <span class="math inline">\(j\)</span> in cluster <span class="math inline">\(i\)</span>. <span class="math inline">\(A_i\)</span> is the treatment indicator for cluster <span class="math inline">\(i\)</span>, <span class="math inline">\(A_i = 1\)</span> if cluster <span class="math inline">\(i\)</span> has been randomized to the experimental arm, <span class="math inline">\(A_i = 0\)</span> otherwise. <span class="math inline">\(a_i\)</span> is the cluster-specific random effect, is normally distributed: <span class="math inline">\(a_i \sim N(\mu = 0, \sigma_a^2)\)</span>. <span class="math inline">\(e_{ij}\)</span> is the (unmeasured) individual <span class="math inline">\(j\)</span> effect, and is also normally distributed: <span class="math inline">\(e_{ij} \sim N(\mu =0, \sigma_e^2 = 16)\)</span>.</p>
<p>Statistical power is directly influenced by overall variability of the outcome, which in this case includes the cluster and individual level variation. Specifically, power is a function of the intra-class (or intra-cluster) correlation (ICC), which can be calculated using
<span class="math display">\[ICC = \frac{\sigma_a^2}{\sigma_a^2 + \sigma_e^2}.\]</span>
In the simulations, ICCs ranged from <span class="math inline">\(0.1\)</span> to <span class="math inline">\(0.4\)</span>. Since <span class="math inline">\(\sigma_e^2\)</span> was fixed, the variance <span class="math inline">\(\sigma^2_a\)</span> was determined by the ICC.</p>
<p>The focus of these simulations is to provide a figure that illustrates the impact of cluster-size variability (with constant total sample size) on power. I used different <em>dispersion</em> assumptions, ranging from 0 to 0.5, to generate different data sets. For each of the 44 ICC/dispersion parameter combinations, I generated 10,000 data sets and estimated a linear mixed effect model for each. The power was calculated for each combination by looking at the proportion of the <em>p-values</em> less than 0.05. The figure below shows the results; it appears that both higher ICCs and cluster size variability lead to reduced power:</p>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/figure-1.png" width="480" /></p>
<p><a name="addendum"></a></p>
<p> </p>
</div>
<div id="addendum---a-simple-trick-to-generate-variation" class="section level3">
<h3>Addendum - a simple trick to generate variation</h3>
<p>Generating the variable cluster sizes under a fixed total is actually quite simple if you take advantage of the <em>Dirichlet</em> distribution. The <em>Dirichlet</em> distribution is essentially a multivariate generalization of the <em>beta</em> distribution. In the <em>Dirichlet</em> distribution, the multivariate values range from 0 to 1, and they sum to 1. Given the range of the data, it is very natural to use values generated from this distribution as probabilities or proportions, which is what the <code>simstudy</code> <em>clusterSize</em> distribution does. This is perhaps easiest to see in a simple example.</p>
<p>Values from the Dirichlet distribution can be generated using the <code>rdirichlet</code> function in the the <code>dirmult</code> package. The key parameter, called the <em>concentration</em> parameter, is a vector of length <em>k</em>, where <em>k</em> is the number of values (e.g. clusters) we are interested in generating. In the first example, I am generating 10 values using a concentration parameter of 32. (In the <code>simstudy</code> implementation of the <em>clusterSize</em> distribution, the dispersion parameter <span class="math inline">\(d\)</span> is 1/<em>concentration</em>.)</p>
<p>Generating 20 values, we can see that all values are between 0 and 1, and sum to 1:</p>
<pre class="r"><code>x &lt;- dirmult::rdirichlet(1, alpha = rep(32, 20) )[1,]
x</code></pre>
<pre><code>##  [1] 0.0442 0.0465 0.0374 0.0506 0.0516 0.0516 0.0623 0.0429 0.0601 0.0404
## [11] 0.0490 0.0517 0.0589 0.0566 0.0320 0.0568 0.0458 0.0610 0.0542 0.0462</code></pre>
<pre class="r"><code>sum(x)</code></pre>
<pre><code>## [1] 1</code></pre>
<p>From here, it is easy generate values between 0 and 400 if we have a total sample size of 400.</p>
<pre class="r"><code>s1 &lt;- floor(x*400)
s1</code></pre>
<pre><code>##  [1] 17 18 14 20 20 20 24 17 24 16 19 20 23 22 12 22 18 24 21 18</code></pre>
<pre class="r"><code>sum(s1)</code></pre>
<pre><code>## [1] 389</code></pre>
<p>Due to rounding, the sum does not equal to 400. In the <code>simstudy</code> function this rounding error is accounted for by allocating an additional unit to randomly selected clusters.</p>
<p>If we use a lower <em>concentration parameter</em> (in this case 4), there should be more variability, and indeed there appears to be:</p>
<pre class="r"><code>x &lt;- dirmult::rdirichlet(1, alpha = rep(4, 20) )[1,]
s2 &lt;- floor(x * 400)
s2</code></pre>
<pre><code>##  [1] 17 27  7 11 18 24 13 26  5 25 23 28 19 26 14 11 43 22 24  9</code></pre>
<p>It appears that the second sample is more variable than the first, and we can confirm this with the standard deviation:</p>
<pre class="r"><code>c(sd1 = sd(s1), sd2 = sd(s2))</code></pre>
<pre><code>##  sd1  sd2 
## 3.30 9.05</code></pre>
</div>
