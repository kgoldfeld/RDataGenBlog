---
title: A Bayesian proportional hazards model with a penalized spline
author: Package Build
date: '2025-03-04'
slug: []
categories: []
tags:
  - R
  - survival analysis
  - Bayesian analysis
type: ''
subtitle: ''
image: ''
draft: TRUE
---



<p>In my previous <a href="https://www.rdatagen.net/post/2025-02-11-estimating-a-bayesian-proportional-hazards-model/" target="_blank">post</a>, I outlined a Bayesian approach to proportional hazards modeling. This post serves as an addendum, providing code to incorporate a spline to model a time-varying hazard ratio non linearly. In a second addendum to come I will present a separate model with a site-specific random effect, essential for a cluster-randomized trial. These components lay the groundwork for analyzing a stepped-wedge cluster-randomized trial, where both splines and site-specific random effects will be integrated into a single model. I plan on describing this comprehensive model in a final post.</p>
<div id="simulating-data-with-a-time-varying-hazard-ratio" class="section level3">
<h3>Simulating data with a time-varying hazard ratio</h3>
<p>Here are the <code>R</code> packages used in the post:</p>
<pre class="r"><code>library(simstudy)
library(ggplot2)
library(data.table)
library(survival)
library(survminer)
library(splines)
library(splines2)
library(cmdstanr)</code></pre>
<p>The dataset simulates a randomized controlled trial in which patients are assigned either to the treatment group (<span class="math inline">\(A=1\)</span>) or control group (<span class="math inline">\(A=0\)</span>) in a <span class="math inline">\(1:1\)</span> ratio. Patients enroll over nine quarters, with the enrollment quarter denoted by <span class="math inline">\(M\)</span>, <span class="math inline">\(M \in \{0, \dots, 8 \}\)</span>. The time-to-event outcome, <span class="math inline">\(Y\)</span>, depends on both treatment assignment and enrollment quarter. To introduce non-linearity, I define the relationship using a cubic function, with true parameters specified as follows:</p>
<pre class="r"><code>defI &lt;- 
  defData(varname = &quot;A&quot;, formula = &quot;1;1&quot;, dist = &quot;trtAssign&quot;) |&gt;
  defData(varname = &quot;M&quot;, formula = &quot;0;8&quot;, dist = &quot;uniformInt&quot;)

defS &lt;-
  defSurv(
    varname = &quot;eventTime&quot;,
    formula = &quot;..int + ..beta * A + ..alpha_1 * M + ..alpha_2 * M^2 + ..alpha_3 * M^3&quot;,
    shape = 0.30)  |&gt;
  defSurv(varname = &quot;censorTime&quot;, formula = -11.3, shape = 0.40)

# parameters

int &lt;- -11.6      
beta &lt;-  0.70
alpha_1 &lt;-  0.10   
alpha_2 &lt;-  0.40    
alpha_3 &lt;- -0.05</code></pre>
<p>I’ve generated a single data set of <span class="math inline">\(640\)</span> study participants, <span class="math inline">\(320\)</span> in each arm. The plot below shows the Kaplan-Meier curves by arm for each enrollment period.</p>
<pre class="r"><code>set.seed(7368) # 7362

dd &lt;- genData(640, defI)
dd &lt;- genSurv(dd, defS, timeName = &quot;Y&quot;, censorName = &quot;censorTime&quot;,
  eventName = &quot;event&quot;, typeName = &quot;eventType&quot;, keepEvents = TRUE)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/surv_plots-1.png" width="288" /></p>
</div>
<div id="bayesian-model" class="section level3">
<h3>Bayesian model</h3>
<p>This Bayesian proportional hazards model builds directly on the approach from my previous <a href="https://www.rdatagen.net/post/2025-02-11-estimating-a-bayesian-proportional-hazards-model/" target="_blank">post</a>. Since the effect of <span class="math inline">\(M\)</span> on <span class="math inline">\(Y\)</span> follows a non-linear pattern, I model this relationship using a spline to account for temporal variation in the hazard. The partial likelihood is a function of the treatment effect and spline basis function coefficients, given by:</p>
<p><span class="math display">\[
L(\beta,\mathbf{\gamma}) = \prod_{i=1}^{N} \left( \frac{\exp \left(\beta A_i + \sum_{m=1} ^ M \gamma_m X_{m_i} \right)} {\sum_{j \in R(t_i)} \exp\left(\beta A_j + \sum_{m=1} ^ M \gamma_m X_{m_j}\right) } \right)^{\delta_i}
\]</span>
where:</p>
<ul>
<li><span class="math inline">\(M\)</span>: number of spline basis functions</li>
<li><span class="math inline">\(N\)</span>: number of observations (censored or not)</li>
<li><span class="math inline">\(A_i\)</span>: binary indicator for treatment</li>
<li><span class="math inline">\(X_{m_i}\)</span>: value of the <span class="math inline">\(m^{\text{th}}\)</span> spline basis function for the <span class="math inline">\(i^{\text{th}}\)</span> observation</li>
<li><span class="math inline">\(\delta_i\)</span>: event indicator (<span class="math inline">\(\delta_i = 1\)</span> if the event occurred, <span class="math inline">\(\delta_i = 0\)</span> if censored)</li>
<li><span class="math inline">\(\beta\)</span>: treatment coefficient</li>
<li><span class="math inline">\(\gamma_m\)</span>: spline coefficient for the <span class="math inline">\(m^\text{th}\)</span> spline basis function</li>
<li><span class="math inline">\(R(t_i)\)</span>: risk set at time <span class="math inline">\(t_i\)</span> (including only individuals censored <em>after</em> <span class="math inline">\(t_i\)</span>)</li>
</ul>
<p>The spline component of the model is adapted from a model I <a href="https://www.rdatagen.net/post/2024-10-08-can-chatgpt-help-construct-non-trivial-bayesian-models-with-cluster-specific-splines/" target="_blank">described</a> last year. In this formulation, time-to-event is modeled as a function of the vector <span class="math inline">\(\mathbf{X_i}\)</span> rather than the period itself. The number of basis functions is determined by the number of knots, with each segment of the curve estimated using B-spline basis functions. To minimize overfitting, we include a penalization term based on the second derivative of the B-spline basis functions. The strength of this penalization is controlled by a tuning parameter, <span class="math inline">\(\lambda\)</span>, which is provided to the model.</p>
<p>The Stan code, provided in full here, was explained in earlier posts. The principal difference from the previous post is the addition of the spline-related data and parameters, as well as the penalization term in the model.:</p>
<pre class="r"><code>stan_code &lt;-
&quot;
functions {

  // Binary search optimized to return the last index with the target value

  int binary_search(vector v, real tar_val) {
    int low = 1;
    int high = num_elements(v);
    int result = -1;

    while (low &lt;= high) {
      int mid = (low + high) %/% 2;
      if (v[mid] == tar_val) {
        result = mid; // Store the index
        high = mid - 1; // Look for earlier occurrences
      } else if (v[mid] &lt; tar_val) {
        low = mid + 1;
      } else {
        high = mid - 1;
      }
    }
    return result;
  }
}

data {

  int&lt;lower=0&gt; K;          // Number of covariates
  int&lt;lower=0&gt; N_o;        // Number of uncensored observations
  vector[N_o] t_o;         // Event times (sorted in decreasing order)

  int&lt;lower=0&gt; N;          // Number of total observations
  vector[N] t;             // Individual times (sorted in decreasing order)
  matrix[N, K] x;          // Covariates for all observations

  // Spline-related data
  
  int&lt;lower=1&gt; Q;          // Number of basis functions
  matrix[N, Q] B;          // Spline basis matrix
  matrix[N, Q] D2_spline;  // 2nd derivative for penalization
  real lambda;             // penalization term
}

parameters {
  vector[K] beta;          // Fixed effects for covariates
  vector[Q] gamma;         // Spline coefficients
}

model {
  
  // Prior
  
  beta ~ normal(0, 4);
  
  // Spline coefficients prior
  
  gamma ~ normal(0, 4);
  
  // Penalization term for spline second derivative
  
  target += -lambda * sum(square(D2_spline * gamma));
  
  // Calculate theta for each observation to be used in likelihood
  
  vector[N] theta;
  vector[N] log_sum_exp_theta;
  
  for (i in 1:N) {
    theta[i] = dot_product(x[i], beta) + dot_product(B[i], gamma);  
  }
  
  // Compute cumulative sum of log(exp(theta)) from last to first observation
  
  log_sum_exp_theta[N] = theta[N];
  
  for (i in tail(sort_indices_desc(t), N-1)) {
    log_sum_exp_theta[i] = log_sum_exp(theta[i], log_sum_exp_theta[i + 1]);
  }

  // Likelihood for uncensored observations
  
  for (n_o in 1:N_o) {
    int start_risk = binary_search(t, t_o[n_o]); // Use binary search
    
    real log_denom = log_sum_exp_theta[start_risk];
    target += theta[start_risk] - log_denom;
  }
}
&quot;</code></pre>
<p>To estimate the model, we need to get the data ready to pass to <code>Stan</code>, compile the <code>Stan</code> code, and then sample from the model using <code>cmdstanr</code>:</p>
<pre class="r"><code>dx &lt;- copy(dd)
setorder(dx, Y)

dx.obs &lt;- dx[event == 1]
N_obs &lt;- dx.obs[, .N]
t_obs &lt;- dx.obs[, Y]

N_all &lt;- dx[, .N]
t_all &lt;- dx[, Y]
x_all &lt;- data.frame(dx[, .(A)])

# Spline-related info

n_knots &lt;- 5
spline_degree &lt;- 3
knot_dist &lt;- 1/(n_knots + 1)
probs &lt;- seq(knot_dist, 1 - knot_dist, by = knot_dist)
knots &lt;- quantile(dx$M, probs = probs)
spline_basis &lt;- bs(dx$M, knots = knots, degree = spline_degree, intercept = TRUE)
B &lt;- as.matrix(spline_basis)

D2 &lt;- dbs(dx$M, knots = knots, degree = spline_degree, derivs = 2, intercept = TRUE)
D2_spline &lt;- as.matrix(D2)

K &lt;- ncol(x_all)             # num covariates - in this case just A

stan_data &lt;- list(
  K = K,
  N_o = N_obs,
  t_o = t_obs,
  N = N_all,
  t = t_all,
  x = x_all,
  Q = ncol(B),
  B = B,
  D2_spline = D2_spline,
  lambda = 0.10
)

# compiling code

stan_model &lt;- cmdstan_model(write_stan_file(stan_code))

# sampling from model

fit &lt;- stan_model$sample(
  data = stan_data,
  iter_warmup = 1000,
  iter_sampling = 4000,
  chains = 4,
  parallel_chains = 4,
  max_treedepth = 15,
  refresh = 0
)</code></pre>
<pre><code>## Running MCMC with 4 parallel chains...
## 
## Chain 4 finished in 68.9 seconds.
## Chain 2 finished in 69.1 seconds.
## Chain 3 finished in 69.9 seconds.
## Chain 1 finished in 75.5 seconds.
## 
## All 4 chains finished successfully.
## Mean chain execution time: 70.9 seconds.
## Total execution time: 75.6 seconds.</code></pre>
<p>The posterior mean (and median) for <span class="math inline">\(\beta\)</span>, the treatment effect, are quite close to the “true” value of 0.70:</p>
<pre class="r"><code>fit$summary(variables = c(&quot;beta&quot;, &quot;gamma&quot;))</code></pre>
<pre><code>## # A tibble: 10 × 10
##    variable   mean median     sd    mad     q5   q95  rhat ess_bulk ess_tail
##    &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
##  1 beta[1]   0.689  0.689 0.0844 0.0857  0.551 0.828  1.00    3664.    4002.
##  2 gamma[1] -1.75  -1.77  1.33   1.35   -3.91  0.468  1.00    1364.    1586.
##  3 gamma[2] -1.59  -1.60  1.33   1.35   -3.75  0.626  1.00    1360.    1551.
##  4 gamma[3] -1.22  -1.24  1.33   1.35   -3.39  0.978  1.00    1365.    1515.
##  5 gamma[4] -0.115 -0.127 1.33   1.35   -2.28  2.09   1.00    1361.    1576.
##  6 gamma[5]  1.97   1.95  1.34   1.35   -0.206 4.20   1.00    1366.    1581.
##  7 gamma[6]  2.63   2.61  1.33   1.34    0.452 4.84   1.00    1358.    1586.
##  8 gamma[7]  1.08   1.05  1.33   1.34   -1.08  3.28   1.00    1360.    1505.
##  9 gamma[8] -0.238 -0.260 1.33   1.34   -2.40  1.97   1.00    1355.    1543.
## 10 gamma[9] -0.914 -0.935 1.33   1.35   -3.07  1.30   1.00    1356.    1549.</code></pre>
<p>The figure below shows the estimated spline and the 95% credible interval. The green line represents the posterior median log hazard ratio for each period (relative to the middle period, 4), with the shaded band indicating the corresponding credible interval. The purple points represent the log hazard ratios implied by the data generation process. For example, the log hazard ratio comparing period 1 to period 4 for both arms is:</p>
<p><span class="math display">\[
\begin{array}{c}
(-11.6 + 0.70A +0.10\times1 + 0.40 \times 1^2 -0.05\times1^3) - (-11.6 + 0.70A +0.10\times4 + 0.40 \times 4^2 -0.05\times4^3) = \\
(0.10 + 0.40 - 0.05) - (0.10 \times 4 + 0.40 \times 16 - 0.05 \times 64 ) = \\
0.45 - 3.60 = -3.15
\end{array}
\]</span></p>
<p>It appears that the median posterior aligns quite well with the values used in the data generation process:</p>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/lHRplot-1.png" width="720" /></p>
<p>For the next post, I will present another scenario that includes random effects for a cluster randomized trial (but will not include splines).</p>
</div>
