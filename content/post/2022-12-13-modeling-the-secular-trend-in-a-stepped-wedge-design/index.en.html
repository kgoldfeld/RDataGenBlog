---
title: Modeling the secular trend in a stepped-wedge design
author: Package Build
date: '2022-12-13'
slug: []
categories: []
tags:
  - R
  - Cluster randomized trials
type: ''
subtitle: ''
image: ''
draft: true
---



<p><a href="https://www.rdatagen.net/post/2022-11-01-modeling-secular-trend-in-crt-using-gam/" target="_blank">Recently</a> I started a discussion about modeling secular trends using flexible models in the context of cluster randomized trials. I’ve been motivated by a trial I am involved with that is using a stepped-wedge study design. The initial post focused on more standard parallel designs; here, I want to extend the discussion explicitly to the stepped-wedge design.</p>
<div id="the-stepped-wedge-design" class="section level3">
<h3>The stepped-wedge design</h3>
<p>Stepped-wedge designs are a special class of cluster randomized trial where each cluster is observed in both treatment arms (as opposed to the classic parallel design where only some of the clusters receive the treatment). In what is essentially a cross-over design, each cluster transitions in a single direction from control (or pre-intervention) to intervention. I’ve written about this in a number of different contexts (for example, with respect to <a href="https://www.rdatagen.net/post/alternatives-to-stepped-wedge-designs/">power analysis</a>, <a href="https://www.rdatagen.net/post/intra-cluster-correlations-over-time/">complicated ICC patterns</a>, <a href="https://www.rdatagen.net/post/bayes-model-to-estimate-stepped-wedge-trial-with-non-trivial-icc-structure/">using Bayesian models for estimation</a>, <a href="https://www.rdatagen.net/post/simulating-an-open-cohort-stepped-wedge-trial/">open cohorts</a>, and <a href="https://www.rdatagen.net/post/2021-12-07-exploring-design-effects-of-stepped-wedge-designs-with-baseline-measurements/">baseline measurements to improve efficiency</a>).</p>
<p>In the classic stepped-wedge design, groups of sites (considered waves) are randomized to intervention starting times. For example, if there are 24 sites divided into 6 waves (so 4 sites per wave), there will be six starting times and 7 measurement periods (if we want to have at least one baseline/control period for each wave, and at least one intervention period per wave). Schematically, the design looks like this:</p>
<p><img src="images/6_waves.png" style="width:75.0%" /></p>
<p>We could use a linear mixed effects model to estimate the intervention effect <span class="math inline">\(\delta\)</span>, which might look like this:</p>
<p><span class="math display">\[
  Y_{ijk} = a_{j} + \beta_{k} + \delta A_{jk} + e_{ijk}
\]</span></p>
<p>where <span class="math inline">\(Y_{ijk}\)</span> is the (continuous) outcome of individual <span class="math inline">\(i\)</span> in cluster <span class="math inline">\(j\)</span> during time period <span class="math inline">\(k\)</span>. <span class="math inline">\(a_j\)</span> is the random intercept for site <span class="math inline">\(j\)</span>, and we assume that <span class="math inline">\(a_j \sim N(0, \sigma^2_a)\)</span>. <span class="math inline">\(A_{jk}\)</span> is the intervention indicator for site <span class="math inline">\(j\)</span> during time period <span class="math inline">\(k\)</span>. <span class="math inline">\(\beta_k\)</span> is a period-specific effect. And <span class="math inline">\(e_{ijk}\)</span> is the individual level effect, <span class="math inline">\(e_{ijk} \sim N(0, \sigma^2_e)\)</span>.</p>
<p>In the particular study motivating these posts, the situation is different in a key way: given its complexity, the intervention can only be implemented at one site a time, so that the number of waves equals the number of sites. This leads to this slightly more elaborate schematic:</p>
<p><img src="images/24_waves.png" style="width:75.0%" /></p>
<p>The challenge under this scenario is that <span class="math inline">\(k\)</span> (the number of periods) is starting to get quite large, requiring us to estimate a large number of period specific effects <span class="math inline">\(\beta_k\)</span>. In addition, the periods are actually shorter, so we have less information available to estimate those period effects. An alternative approach, as you may have anticipated, is to smooth the secular trend, using a model that looks like this:</p>
<p><span class="math display">\[
Y_{ijk} = a_{j} + s(k) + \delta A_{jk} + e_{ijk}
\]</span></p>
<p>where <span class="math inline">\(s(.)\)</span> is a smooth function of time. And by using a smooth function, we can take this one step further and specify a <em>site-specific</em> smoothing function <span class="math inline">\(s_j(.)\)</span>:</p>
<p><span class="math display">\[
Y_{ijk} = a_{j} + s_j(k) + \delta A_{jk} + e_{ijk}
\]</span></p>
<p>So, we will use either cubic splines or generalized additive models (GAMs) to estimate the curve, which will allow us to control for the period effect while estimating the treatment effect. By smoothing the function, we are assuming that the measurements closer in time are more highly correlated than measurements further apart.</p>
</div>
<div id="data-generation-process" class="section level3">
<h3>Data generation process</h3>
<p>Here is the data generation process that we will use to explore the different models:</p>
<p><span class="math display">\[
Y_{ijk} \sim N(\mu_{ijk}, \sigma^2 = 40) \\
\mu_{ijk} = a_{j} + b_{jk} + \delta A_{jk} \\
a_j \sim N(0, \sigma^2_a = 9) \\
b_{jk} \sim N(0, \Sigma_b) \\
\delta = 5\\
\]</span></p>
<p>In this data generation process, the time effect will <em>not</em> be explicitly smooth, but the underlying covariance structure used to generate the period effects will induce some level of smoothness. This is similar to what was described in the previous <a href="https://www.rdatagen.net/post/2022-11-01-modeling-secular-trend-in-crt-using-gam/">post</a>. As in that earlier example, <span class="math inline">\(b_{jk}\)</span> is a site-specific time period effect for each time period <span class="math inline">\(k\)</span>; the vector of cluster-time effects <span class="math inline">\(\mathbf{b_j} \sim N(0, \Sigma_b)\)</span>, where <span class="math inline">\(\Sigma_b = DRD\)</span> is a <span class="math inline">\(25 \times 25\)</span> covariance matrix based on a diagonal matrix <span class="math inline">\(D\)</span> and an auto-regressive correlation structure <span class="math inline">\(R\)</span>:</p>
<p><span class="math display">\[
D = 4 * I_{25 \times 25}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
R =\begin{bmatrix}
1 &amp; \rho &amp; \rho^2 &amp; \dots &amp; \rho^{24} \\
\rho &amp; 1 &amp; \rho &amp; \dots &amp; \rho^{23} \\
\rho^2 &amp; \rho &amp; 1 &amp; \dots &amp; \rho^{22} \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
\rho^{24} &amp; \rho^{23} &amp; \rho^{22} &amp; \dots &amp; 1 \\
\end{bmatrix}, \ \ \rho = 0.7
\]</span></p>
<p>Now we are ready to implement this data generating process using <code>simstudy</code>. First the R packages that we will need:</p>
<pre class="r"><code>library(simstudy)
library(ggplot2)
library(data.table)
library(mgcv)
library(lme4)
library(splines)</code></pre>
<p>The data definitions for <span class="math inline">\(a_j\)</span>, <span class="math inline">\(b_{jk}\)</span>, and <span class="math inline">\(Y_{ijk}\)</span> are established first:</p>
<pre class="r"><code>def &lt;- defData(varname = &quot;a&quot;, formula = 0, variance = 9)
def &lt;- defData(def, varname = &quot;mu_b&quot;, formula = 0, dist = &quot;nonrandom&quot;)
def &lt;- defData(def, varname = &quot;s2_b&quot;, formula = 16, dist = &quot;nonrandom&quot;)

defOut &lt;- defDataAdd(varname = &quot;y&quot;, formula = &quot;a + b + 5 * A&quot;, variance = 40)</code></pre>
<p>We (1) generate 24 sites with random intercepts, (2) create 25 periods for each site, (3) generate the period-specific effects (<span class="math inline">\(b_{jk}\)</span>) for each site, and (4) assign the treatment status based on the stepped-wedge design:</p>
<pre class="r"><code>set.seed(1234)

ds &lt;- genData(24, def, id = &quot;site&quot;)                  #1
ds &lt;- addPeriods(ds, 25, &quot;site&quot;, perName = &quot;k&quot;)      #2

ds &lt;- addCorGen(dtOld = ds, idvar = &quot;site&quot;,  
                rho = 0.8, corstr = &quot;ar1&quot;,
                dist = &quot;normal&quot;, param1 = &quot;mu_b&quot;, 
                param2 = &quot;s2_b&quot;, cnames = &quot;b&quot;)       #3

ds &lt;- trtStepWedge(ds, &quot;site&quot;, nWaves = 24, 
                   lenWaves = 1, startPer = 1, 
                   grpName = &quot;A&quot;, perName = &quot;k&quot;)     #4

ds$site &lt;- as.factor(ds$site)

ds</code></pre>
<pre><code>##      site  k         a mu_b s2_b timeID          b startTrt A
##   1:    1  0 -3.621197    0   16      1 -3.6889733        1 0
##   2:    1  1 -3.621197    0   16      2 -1.6620662        1 1
##   3:    1  2 -3.621197    0   16      3  1.5816344        1 1
##   4:    1  3 -3.621197    0   16      4  4.0869655        1 1
##   5:    1  4 -3.621197    0   16      5  1.9385573        1 1
##  ---                                                         
## 596:   24 20  1.378768    0   16    596 -1.5470625       24 0
## 597:   24 21  1.378768    0   16    597 -1.7687554       24 0
## 598:   24 22  1.378768    0   16    598  4.1179282       24 0
## 599:   24 23  1.378768    0   16    599  7.1421562       24 0
## 600:   24 24  1.378768    0   16    600  0.3645013       24 1</code></pre>
<p>In the last two steps, we create 30 individuals per site per period and generate each individual-level outcome. The figure shows the outcomes for all the sites over time:</p>
<pre class="r"><code>dd &lt;- genCluster(ds, &quot;timeID&quot;, numIndsVar = 30, level1ID = &quot;id&quot;)
dd &lt;- addColumns(defOut, dd)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-5-1.png" width="960" /></p>
</div>
<div id="model-estimation" class="section level3">
<h3>Model estimation</h3>
<p>I am fitting three models to this simulated data set: (1) a mixed effects model with fixed time period effects, (2), a mixed effects model with a random cubic spline for the period effect for each site, and (3) a generalized additive model with a site-specific smooth function for time. For each estimated model, I’ve overlaid the predicted values on top of the observed (generated) data points.</p>
<p>I’ve also conducted an experiment using 5000+ replicated data sets to see how each model really performs with respect to the estimation of the treatment effect. (Code for these replications can be found <a href="https://github.com/kgoldfeld/RDataGenBlog/blob/master/content/post/2022-12-13-modeling-the-secular-trend-in-a-stepped-wedge-design/replications/reps_hpc.R" target="_blank">here</a>). These replications provide information about some operating characteristics of the different models (estimated bias, root mean squared error (RMSE), average estimated standard error, and coverage rate, i.e. proportion of 95% confidence intervals that include the true value 5).</p>
<div id="mixed-effects-model-with-fixed-time-period-effects" class="section level4">
<h4>Mixed effects model with fixed time-period effects</h4>
<p>Here’s the first model. Note that I am not estimating an intercept so that each period effect is directly estimated. (I did try to estimate the 600 site-specific period random effects, but it proved too computationally intensive for my computer, which ground away for a half hour before I mercifully stopped it). The model does include a site-specific random intercept.</p>
<pre class="r"><code>fitlme_k &lt;- lmer(y ~ A + factor(k) - 1 + (1|site), data = dd)
summary(fitlme_k)</code></pre>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: y ~ A + factor(k) - 1 + (1 | site)
##    Data: dd
## 
## REML criterion at convergence: 122095.4
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -4.1545 -0.6781 -0.0090  0.6765  4.2816 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  site     (Intercept) 10.76    3.280   
##  Residual             51.37    7.167   
## Number of obs: 18000, groups:  site, 24
## 
## Fixed effects:
##             Estimate Std. Error t value
## A            5.83701    0.18482  31.582
## factor(k)0  -1.72745    0.72085  -2.396
## factor(k)1  -2.44884    0.72089  -3.397
## factor(k)2  -1.61074    0.72102  -2.234
## factor(k)3  -0.09524    0.72122  -0.132
## factor(k)4  -0.85081    0.72151  -1.179
## factor(k)5  -0.11645    0.72188  -0.161
## factor(k)6  -0.57468    0.72233  -0.796
## factor(k)7  -0.13628    0.72287  -0.189
## factor(k)8   0.01035    0.72348   0.014
## factor(k)9  -0.63440    0.72418  -0.876
## factor(k)10  0.33878    0.72496   0.467
## factor(k)11  0.34778    0.72581   0.479
## factor(k)12  0.21387    0.72675   0.294
## factor(k)13  1.25549    0.72777   1.725
## factor(k)14  0.60881    0.72887   0.835
## factor(k)15 -0.30760    0.73005  -0.421
## factor(k)16 -0.56911    0.73131  -0.778
## factor(k)17 -1.43275    0.73265  -1.956
## factor(k)18 -1.46688    0.73406  -1.998
## factor(k)19 -2.12147    0.73555  -2.884
## factor(k)20 -1.47431    0.73712  -2.000
## factor(k)21 -1.85067    0.73877  -2.505
## factor(k)22 -1.32576    0.74050  -1.790
## factor(k)23 -1.12176    0.74229  -1.511
## factor(k)24 -1.31230    0.74417  -1.763</code></pre>
<p>The predicted values indicate that the model does not pick up the site-specific variation over time:</p>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-7-1.png" width="960" /></p>
<p>Although the estimate of the treatment effect from the single data set is 5.8 [95% CI: 5.5, 6.2], the treatment effect estimate from this model is actually <em>unbiased</em> (based on evaluating the results from the replications). However, RMSE = 0.97 (which is equivalent to the true standard error of the estimated treatment effect since there is no bias), but the average estimated standard error was only 0.18, and the coverage of the 95% CIs was only 29%. Indeed the estimated confidence interval from our single data set did not include the true value. Based on all of this, the model doesn’t seem all that promising, particularly with respect to measuring the uncertainty.</p>
</div>
<div id="mixed-effects-model-with-site-specific-natural-cubic-spline" class="section level4">
<h4>Mixed effects model with site-specific natural cubic spline</h4>
<p>With the second model, also a mixed effects model, I’ve included a random cubic spline (based on four knots) instead of the random intercept:</p>
<pre class="r"><code>dd[, normk := (k - min(k))/(max(k) - min(k))]
knots &lt;- c(.2, .4, .6, .8)

fitlme_s &lt;- lmer(y ~ A + ( ns(normk, knots = knots) - 1 | site ), data = dd)
summary(fitlme_s)</code></pre>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: y ~ A + (ns(normk, knots = knots) - 1 | site)
##    Data: dd
## 
## REML criterion at convergence: 120120.9
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -4.0707 -0.6768  0.0080  0.6671  4.1554 
## 
## Random effects:
##  Groups   Name                      Variance Std.Dev. Corr                   
##  site     ns(normk, knots = knots)1 30.97    5.565                           
##           ns(normk, knots = knots)2 59.08    7.686     0.33                  
##           ns(normk, knots = knots)3 28.10    5.301     0.12 -0.10            
##           ns(normk, knots = knots)4 75.10    8.666     0.16  0.55 -0.31      
##           ns(normk, knots = knots)5 28.28    5.318     0.49  0.14  0.58 -0.28
##  Residual                           45.25    6.727                           
## Number of obs: 18000, groups:  site, 24
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  -2.0677     0.1830  -11.30
## A             5.0023     0.3052   16.39
## 
## Correlation of Fixed Effects:
##   (Intr)
## A -0.088</code></pre>
<p>This time we can see that the model predictions better reflect the site-specific time trends:</p>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-9-1.png" width="960" /></p>
<p>This model also provides an unbiased estimate (in the case of the first data set, the estimate was spot on 5.0 [4.4, 5.6].) The RMSE was lower than the first model (0.78) and the average estimate of the standard error was slightly higher (0.31). The coverage was also higher, but still only 56%. There is still room for improvement.</p>
</div>
<div id="gam-with-site-specific-smoother" class="section level4">
<h4>GAM with site-specific smoother</h4>
<p>This last model is a GAM (using the <code>gam</code> function from the <code>mgcv</code> package). A key parameter in the smoothing function <code>s</code> is the <em>bs</em> argument for the type of basis spline. I’ve used the option “fs” that allows for “random factor smooth interactions,” which is what we need here. In addition, the dimension of the basis (the argument <em>k</em>, not to be confused with the period <em>k</em>), was set by evaluating the selection criterion (GCV) as well investigating the RMSE and the average estimated standard errors. A value of <em>k</em> between 10 and 15 seems to be ideal, I’ve settled on <span class="math inline">\(k = 12\)</span>.</p>
<pre class="r"><code>gamfit &lt;- gam(y ~ A + s(k, site, bs = &quot;fs&quot;, k = 12), data = dd)
summary(gamfit)</code></pre>
<pre><code>## 
## Family: gaussian 
## Link function: identity 
## 
## Formula:
## y ~ A + s(k, site, bs = &quot;fs&quot;, k = 12)
## 
## Parametric coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -0.4595     0.7429  -0.619    0.536    
## A             5.2864     0.4525  11.682   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Approximate significance of smooth terms:
##             edf Ref.df    F p-value    
## s(k,site) 261.7    287 32.8  &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## R-sq.(adj) =  0.403   Deviance explained = 41.2%
## GCV = 41.693  Scale est. = 41.082    n = 18000</code></pre>
<p>The predicted value plot highlights that this model has estimated site-specific secular functions that are a little more wriggly than the cubic splines.</p>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-11-1.png" width="960" /></p>
<p>In spite of the less smooth curve, the GAM estimate is unbiased as well with a slightly lower RMSE (0.76) then the cubic spline model (0.78). Better yet, the estimated standard errors averaged 0.45, and the coverage is 76% (compared to 56% from the cubic spline model).</p>
<p>In general, at least in this simulation setting, the GAM seems to be an improvement over the random cubic spline model. However, this last model still underestimates the measure of uncertainty, suggesting there is more work to be done. Next, I will explore estimation of robust standard errors using bootstrap methods.</p>
<p>To be continued …</p>
<p> </p>
</div>
</div>
