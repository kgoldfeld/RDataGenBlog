---
title: Generating clustered data with marginal correlations - highlighting two simstudy updates
author: Package Build
date: '2022-11-29'
slug: []
categories: []
tags:
  - R
type: ''
subtitle: ''
image: ''
draft: TRUE
---

A student is working on a project to derive an analytic solution to the problem of sample size determination in the context of cluster randomized trials and repeated individual-level measurement (something I've [thought](https://www.rdatagen.net/post/2021-11-23-design-effects-with-baseline-measurements/){target="_blank"} a little bit about before). Though the goal is an analytic solution, we do want confirmation with simulation. So, I was a little disheartened to discover that the routines I'd developed for this sort of data generation were not quite up to the task. I've had to quickly fix that, and the updates are available in the development version of `simstudy`, which can be downloaded using *devtools::install_github("kgoldfeld/simstudy")*. While some of the changes are under the hood, I have added a new function, `genMatBlock`, which I'll describe here and show some examples.

### Correlation in cluster randomized trials

The fundamental issue with cluster randomized trials is that the outcomes for a group of patients in a specific cluster are going to be correlated, which impacts both how much we "learn" from each individual and estimate of uncertainty (i.e., standard errors). The more highly correlated individuals are, the less we learn from each individual. (In the extreme case, if there is perfect correlation, we really only have a sample of one from each group.) That correlation structure can depend on whether outcomes generally vary over time (so that patient outcomes within a cluster close to time might be more correlated than outcomes collect from patients far apart in time) and whether measurements are collected for the same individuals over time (you might expect the measurements of the same individual to be more highly correlated than measurements of two different individuals). The assumed correlation structure needs to reflect all of these design issues.

In simulating data from a cluster randomized trial, have at least two options. The first is to use random effects to induce correlation. A  simple data generating process for a binary outcome with a treatment indicator and one covariate that would result in within-cluster correlation would start with a formulation like this:

$$ P(Y_{ij} = 1) = \pi_{ij}, \ \ \ Y_{ij} \in \{0,1\}$$
$$
log \left( \frac{\pi_{ij}}{1-p{ij}} \right) = \beta_0 + \beta_1 A_j + \beta_2X_i + b_j
$$

where $Y_{ij}$ is the outcome for individual $i$ in cluster $j$. ($A$ is a treatment indicator and $X$ is a covariate.) The key here is $b_j$, which is a cluster level effect that is typically assumed to have a normal distribution N(0, $\sigma_b^2)$. In the simulation, we would use use values to generate a probability $\pi_{ij}$ for each, and each of those $\pi_{ij}$'s within a cluster would be correlated by the presence of the cluster effect $b_j$. It would follow that the $Y_{ij}$'s would also be correlated within cluster $j$. We can call this the *conditional* data generation process, and we could use a mixed-effects regression model to recover the parameters.

Alternatively, we can dispose of $b_j$, like this:

$$
log \left( \frac{\pi_{ij}}{1-p{ij}} \right) = \beta_0 + \beta_1 A_j + \beta_2X_i
$$

As before, we would generate the $\pi_{ij}$'s, but those probabilities would be uncorrelated now (except of course the correlation due to randomization assignment, but this would be across cluster boundaries). We would introduce within-cluster correlation directly into the $Y_{ij}$'s by using using multivariate data generation process. If we were in the realm of normally distributed outcomes, we would use a multivariate normal data generating process $MVN(\mathbf{\mu}, \Sigma)$, where $\Sigma$ is a covariance matrix. (This could be done in `simstudy` using `genCorData` or `addCorData`.) In this case, with a binary outcome, we need an analogous approach. This is what is implemented in the `simstudy` functions `genCorGen` and `addCorGen`.

### The correlation structure

OK - that is a bit more background than I intended (though probably not enough). Now onto the functions and simulations. 

Ultimately, we might be interested in using `addCorGen` to generate data with a somewhat complex correlation structure. In the first example, we have a scenario with multiple measurement periods though an individual is measured only once. 

```{r, message=FALSE}
library(simstudy)
library(data.table)
```

#### Multiple time periods, single individual measurement

```{r}
b0 <- -1.0; delta <- 1; number_inds = 3;

###

defC <- defData(varname = "A", formula = "1;1", dist = "trtAssign")

defI <- defDataAdd(varname = "z", formula = 0, variance = 0.10)
defI <- defDataAdd(defI, varname = "p",
                   formula = "..b0 + ..delta * A + .5*z",
                   dist = "nonrandom", link = "logit")

###

target_cor <- genBlockMat(rho = c(0.3, 0.2, 0.1), nInds = number_inds, nPeriods = 3)
target_cor

###

set.seed(1234)

dc <- genData(n = 10, dtDefs = defC, id = "site")
dc <- addPeriods(dtName = dc, nPeriods = number_inds, 
        idvars = "site", perName = "period")
dd <- genCluster(dtClust = dc, cLevelVar = "timeID", 
        numIndsVar = 3, level1ID = "idnum")
dd <- addColumns(defI, dd)

setkey(dd, "site", "period","idnum")

genCorDT <- function(dx) {
  
  addCorGen(dx, idvar = "site", corMatrix = target_cor,
      dist = "binary", param1 = "p", cnames = "y", method = "ep")
}

dres <- genCorDT(dd)
head(dres, n = 9)

reps <- lapply(1:2500, function(x) genCorDT(dd))

empir <- function(s) {
  drep <- data.table::rbindlist(reps, idcol = "rep")
  drep <- drep[site == s, ]
  drep[, seq := 1:.N, keyby = rep]
  dmat <- as.matrix(dcast(drep, rep ~ seq, value.var = "y")[, -1])
  
  mu <- cbind(round(apply(dmat, 2, mean), 2), round(dd[site == s, p], 2))
  S <- round(cor(dmat), 1) 
  
  return(list(mu = mu, S = S))
}

empir(s=7)
```

### Multiple time periods, repeated individual measurements

```{r}
b0 <- -1.0; b1 <- .5; delta <- -0.3; number_inds = 3;

###

defC <- defData(varname = "A", formula = "1;1", dist = "trtAssign")

defI <- defDataAdd(varname = "z", formula = 0, variance = 0.10)
defI <- defDataAdd(defI, varname = "p",
                   formula = "..b0 + ..b1* measure + ..delta * A * measure + z",
                   dist = "nonrandom", link = "logit")
###

target_cor <- genBlockMat(rho = c(0.3, .1), nInds = number_inds, nPeriods = 2, iRho = 0.5)
target_cor

###

set.seed(1234)

dc <- genData(n = 10, dtDefs = defC, id = "site")
dc <- genCluster(dtClust = dc, cLevelVar = "site", 
        numIndsVar = number_inds, level1ID = "idnum")
dd <- addPeriods(dtName = dc, nPeriods = 2, idvars = "idnum", perName = "measure")
dd <- addColumns(defI, dd)

setkey(dd, "site", "measure", "idnum")

dres <- genCorDT(dd)

head(dres, n = 6)

###

reps <- lapply(1:2500, function(x) genCorDT(dd))

empir(s = 2)
```