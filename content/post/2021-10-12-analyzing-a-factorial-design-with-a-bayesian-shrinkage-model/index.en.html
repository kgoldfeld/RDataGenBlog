---
title: A Bayesian analysis of a factorial design focusing on effect size estimates
author:
date: '2021-10-12'
slug: []
categories: []
tags:
  - R
  - Bayesian model
type: ''
subtitle: ''
image: ''
draft: true
---

<script src="{{< blogdown/postref >}}index.en_files/header-attrs/header-attrs.js"></script>


<p>This is a continuation of my <a href="" target="_blank">discussion</a> on alternative ways to analyze data and present findings for a factorial study design where we are interested in whether applying multiple interventions is beneficial. Last time, I presented an approach that focused on variance estimation, and used an example of 2 interventions with 4 different levels for each, implying a study of 16 arms. This time around, I am considering a study that has 3 different interventions, but only 2 levels for each (i.e., yes or no), for a total of 8 arms. Under these assumptions, the posterior distributions based on the variance-based model are bi-modal in shape, making it quite difficult to interpret the findings. So, I decided to turn the focus away from variance and emphasize the effect size estimates for each arm compared to control.</p>
<div id="bayesian-model-specification" class="section level3">
<h3>Bayesian model specification</h3>
<p>There are three interventions (<span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, and <span class="math inline">\(c\)</span>), each with two levels; the full factorial design will have 8 arms. ED <span class="math inline">\(j\)</span> is randomized to one level in each of <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, and <span class="math inline">\(c\)</span>, and <span class="math inline">\(a_j \in \{0,1\}\)</span>, <span class="math inline">\(b_j\in \{0,1\}\)</span>, and <span class="math inline">\(c_j\in \{0,1\}\)</span>. <span class="math inline">\(\boldsymbol{Z_{j}}\)</span> is a vector of <span class="math inline">\(m\)</span> ED-specific factors, including those that are used for stratification as well as time. <span class="math inline">\(\boldsymbol{X_{ij}}\)</span> is a vector of <span class="math inline">\(k\)</span> patient level characteristics, including at least age, race, and gender.</p>
<p>Here is the model for outcome <span class="math inline">\(y\)</span>, a binary measure:</p>
<p><span class="math display">\[
y_{i} \sim \text{binomial}\left(p_{i}\right)
\]</span>
<span class="math display">\[
\text{log}\left( \frac{p_{i}}{1-p_{i}}\right) =  \tau_0 + \tau_a a_i + \tau_b b_i + \tau_c c_i + \tau_{ab} a_i b_i +  \tau_{ac} a_i c_i + \tau_{bc} b_i c_i + \tau_{abc}a_i b_i c_i
\]</span></p>
<p>The parameters <span class="math inline">\(\tau_a, \tau_b, \text{ and } \tau_{c}\)</span> are the log odds ratios associated with the level of treatment <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, and <span class="math inline">\(c\)</span>, respectively. <span class="math inline">\(\tau_{ab}, \tau_{ac}, \text{and } \tau_{bc}\)</span> are the combined effects of the pairs, and <span class="math inline">\(\tau_{abc}\)</span> is the added effect of implementing all three interventions simultaneously.</p>
<p>Here are the prior distribution assumptions:</p>
<span class="math display">\[\begin{aligned}
  \tau_0 &amp;\sim N(\mu=0, \sigma = 1) \\
  \tau_a, \tau_b, \tau_c &amp;\sim N(\mu = \delta_m, \sigma = \sigma_m) \\
  \tau_{ab}, \tau_{ac}, \tau_{bc} &amp;\sim N(\mu = \delta_x, \sigma = \sigma_x) \\
  \tau_{abc} &amp;\sim N(\mu = 0, \sigma = 1) \\
  \delta_m  &amp;\sim N(\mu = 0, \sigma = 1) \\
  \sigma_m &amp;\sim t_\text{student}(\text{df}=3, \mu=0, \sigma = 2.5), \ \sigma_m \ge 0 \\
  \delta_x  &amp;\sim N(0, 1) \\
  \sigma_x &amp;\sim t_\text{student}(\text{df}=3, \mu = 0, \sigma = 2.5), \ \sigma_x \ge 0 \\
\end{aligned}\]</span>
<p>The estimates for the main effects <span class="math inline">\(\tau_a, \ \tau_b, \text{ and } \tau_c\)</span> are partially pooled because their prior distributions share a common mean <span class="math inline">\(\delta_m\)</span> and standard deviation <span class="math inline">\(\sigma_m\)</span>. Likewise the prior distributions for the pair-wise interaction effects share a common mean <span class="math inline">\(\delta_x\)</span> and standard deviation <span class="math inline">\(\sigma_x\)</span>. These four <em>hyperparameters</em> are estimated from the data. The prior distributions for the intervention effects <span class="math inline">\(\delta_m\)</span> and <span class="math inline">\(\delta_x\)</span> are specified with the aim towards conservativism or skepticism, with a large portion of the distribution centered around 0. The priors for the variance parameters are more diffuse (using a <span class="math inline">\(t\)</span>-distribution with 3-degrees of freedom, a compromise between a <em>Cauchy</em> distribution with very broad tails and a <em>normal</em> distribution with more constrained tails).</p>
</div>
<div id="inference" class="section level3">
<h3>Inference</h3>
<p>Statistical inference will be based on an examination of the posterior distributions for the log odds ratios comparing each of the treatment combinations with the control arm where none of the interventions are implemented. We can also compare across different combinations to assess if one particular combination seems to be stronger than another. Since we are not using a null-hypothesis testing framework and the effect estimates are pooled across the interventions, adjustments for multiple testing are not necessary.</p>
<p>The figure below is <em>forest plot</em> based on simulated data that shows how the posterior distributions will be represented. Each line represents a combination of interventions. In this case, it appears that each of the interventions is effect alone (i.e.Â P(lOR &lt; 0) = 1), but it seems that combining interventions <em>A</em> and <em>B</em> is a good option. We could conduct further analysis to assess the probability that this combination is more effective than either of the interventions alone. Finally, it does not appear that applying all three interventions is necessary.</p>
</div>
<div id="data-definition-and-generation" class="section level3">
<h3>Data definition and generation</h3>
<pre class="r"><code>library(simstudy)
library(cowplot)
library(magick)
library(paletteer)
library(ggplot2)
library(data.table)
library(ggpubr)
library(cmdstanr)
library(posterior)
library(ggdist)
library(glue)</code></pre>
<pre class="r"><code>f &lt;- &quot;..t_0 + ..t_a*a + ..t_b*b + ..t_c*c + 
      ..t_ab*a*b + ..t_ac*a*c + ..t_bc*b*c + ..t_abc*a*b*c&quot;

defY &lt;- defDataAdd(varname = &quot;y&quot;, formula = f, dist = &quot;binary&quot;, link=&quot;logit&quot;)

t_0 &lt;-  -1.4

t_a &lt;-   0.5
t_b &lt;-   0.6
t_ab &lt;- -0.2

t_c &lt;- t_ac &lt;- t_bc &lt;- t_abc &lt;- 0.0

dt_to_list &lt;- function(dx) {
  
  N &lt;- nrow(dx)                               ## number of observations 
  x_abc &lt;- model.matrix(~a*b*c, data = dx)
  y &lt;- dx[, y]
  
  list(N = N, x_abc = x_abc, y = y)
}</code></pre>
<pre class="r"><code>set.seed(73961)

dd &lt;- genData(8*1000) # for final version use 1000
dd &lt;- addMultiFac(dd, nFactors = 3, colNames = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;))
dd &lt;- addColumns(defY, dd)</code></pre>
</div>
<div id="model-fitting" class="section level3">
<h3>Model fitting</h3>
<pre class="r"><code>mod &lt;- cmdstan_model(&quot;code/model_ind.stan&quot;)

fit &lt;- mod$sample(
  data = dt_to_list(dd),
  refresh = 0,
  chains = 4L,
  parallel_chains = 4L,
  iter_warmup = 1000,
  iter_sampling = 2500,
  adapt_delta = 0.98,
  max_treedepth = 20,
  show_messages = FALSE,
  seed = 29817
)

posterior &lt;- data.frame(as_draws_rvars(fit$draws(variables = &quot;lOR&quot;)))</code></pre>
<pre><code>## Running MCMC with 4 parallel chains...
## 
## Chain 1 finished in 195.6 seconds.
## Chain 4 finished in 214.3 seconds.
## Chain 3 finished in 236.6 seconds.
## Chain 2 finished in 252.2 seconds.
## 
## All 4 chains finished successfully.
## Mean chain execution time: 224.7 seconds.
## Total execution time: 252.7 seconds.</code></pre>
<pre><code>## 
## Warning: 11 of 10000 (0.0%) transitions ended with a divergence.
## This may indicate insufficient exploration of the posterior distribution.
## Possible remedies include: 
##   * Increasing adapt_delta closer to 1 (default is 0.8) 
##   * Reparameterizing the model (e.g. using a non-centered parameterization)
##   * Using informative or weakly informative prior distributions</code></pre>
</div>
<div id="presenting-the-results" class="section level3">
<h3>Presenting the results</h3>
<pre class="r"><code>pcts &lt;- c(.025, 0.25, .50, 0.75, .975)
sumstats &lt;- data.table(t(quantile(posterior$lOR, pcts)))
setnames(sumstats, glue(&quot;p{pcts}&quot;))
sumstats$var &lt;- glue(&quot;lOR[{1:7}]&quot;) 

p &lt;- ggplot(data = sumstats, aes(y = var, yend = var)) +
  geom_vline(xintercept = 0, color = &quot;grey85&quot;) +
  geom_segment(aes(x = p0.025, xend = p0.975)) +
  geom_segment(aes(x = p0.25, xend = p0.75), size = 1.25, color = &quot;#9a0000&quot;) +
  geom_point(aes(x = p0.5), size = 2.5) +
  theme(panel.grid = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_text(margin = margin(t = 0, r = -12, b = 0, l = 0)),
        plot.title = element_text(size = 10, face = &quot;bold&quot;)
  ) +
  ylab(&quot;treatment assignments (three interventions)&quot;) +
  xlab(&quot;log odds ratio&quot;) +
  xlim(-.5, 1.5) +
  ggtitle(&quot;Posterior distribution of log OR by treatment assignment&quot;)

pimage &lt;- axis_canvas(p, axis = &#39;y&#39;) +
  draw_image(&quot;r_icons/r111.png&quot;, y = 6.5, scale = 0.35) +
  draw_image(&quot;r_icons/r011.png&quot;, y = 5.5, scale = 0.35) +
  draw_image(&quot;r_icons/r101.png&quot;, y = 4.5, scale = 0.35) +
  draw_image(&quot;r_icons/r110.png&quot;, y = 3.5, scale = 0.35) +
  draw_image(&quot;r_icons/r001.png&quot;, y = 2.5, scale = 0.35) +
  draw_image(&quot;r_icons/r010.png&quot;, y = 1.5, scale = 0.35) +
  draw_image(&quot;r_icons/r100.png&quot;, y = 0.5, scale = 0.35)

ggdraw(insert_yaxis_grob(p, pimage, position = &quot;left&quot;, width = grid::unit(.17, &quot;null&quot;)))</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code>data &lt;- with(posterior, data.frame(
  x = c(&quot;ab vs a&quot;, 
        &quot;ab vs b&quot;, 
        &quot;abc vs bc&quot;,
        &quot;abc vs ab&quot;),
  diff = c(lOR[4] - lOR[1], 
           lOR[4] - lOR[2], 
           lOR[7] - lOR[6], 
           lOR[7] - lOR[4])
))

ggplot(data = data, aes(dist = diff, x = x)) +
  geom_hline(yintercept = 0, color = &quot;grey80&quot;, size = .3) +
  stat_dist_eye(fill = &quot;pink&quot;, position=&quot;dodge&quot;) +
  theme(panel.grid = element_blank(),
        axis.title.x = element_blank()) +
  ylab(&quot;difference&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p><a name="addendum"></a></p>
</div>
<div id="addendum" class="section level3">
<h3>Addendum</h3>
<pre class="stan"><code>data {
  
  int&lt;lower=0&gt; N;                       // number patients
  matrix&lt;lower=0, upper=1&gt;[N, 8] x_abc;
  int&lt;lower=0,upper=1&gt; y[N];            // outcome for individual i
  
}

parameters {
  
  vector[8] z;

  real delta_m;
  real&lt;lower = 0&gt; sigma_m;
  
  real delta_x;
  real&lt;lower=0&gt; sigma_x;
  
}

transformed parameters {
  
  vector[8] tau;
  
  tau[1] = z[1];
  
  for (i in 2:4){
    tau[i] = sigma_m * z[i] + delta_m;
  }
  
  for (i in 5:7){
    tau[i] = sigma_x * z[i] + delta_x;
  }
  
  tau[8] = z[8];
  
  
}

model {
  
  sigma_m ~ student_t(3, 0, 2.5);
  sigma_x ~ student_t(3, 0, 2.5);

  delta_m ~ normal(0, 1);
  delta_x ~ normal(0, 1);
  
  z ~ std_normal();

  y ~ bernoulli_logit(x_abc * tau);
  
}

generated quantities {
  
  real lOR[7];
  
  lOR[1] = tau[2];                                            //  a=1, b=0, c=0
  lOR[2] = tau[3];                                            //  a=0, b=1, c=0
  lOR[3] = tau[4];                                            //  a=0, b=0, c=1
  lOR[4] = tau[2] + tau[3] + tau[5];                          //  a=1, b=1, c=0
  lOR[5] = tau[2] + tau[4] + tau[6];                          //  a=1, b=0, c=1
  lOR[6] = tau[3] + tau[4] + tau[7];                          //  a=0, b=1, c=1
  lOR[7] = tau[2]+tau[3]+tau[4]+tau[5]+tau[6]+tau[7]+tau[8];  //  a=1, b=1, c=1
  
}</code></pre>
</div>
