---
title: Skeptical Bayesian priors might help minimize skepticism about subgroup analyses
author: Keith Goldfeld
date: '2022-01-04'
slug: []
categories: []
tags:
  - R
  - Bayesian model
type: ''
subtitle: ''
image: ''
---

<script src="{{< blogdown/postref >}}index.en_files/header-attrs/header-attrs.js"></script>


<p>Over the past couple of years, I have been working with an amazing group of investigators as part of the CONTAIN trial to study whether COVID-19 convalescent plasma (CCP) can improve the clinical status of patients hospitalized with COVID-19 and requiring noninvasive supplemental oxygen. This was a multi-site study in the US that randomized 941 patients to either CCP or a saline solution placebo. The overall <a href="https://jamanetwork.com/journals/jamainternalmedicine/article-abstract/2787090" target="_blank">findings</a> suggest that CCP did not benefit the patients who received it, but if you drill down a little deeper, the story may be more complicated than that.</p>
<p>Of course, it is the “drilling down” part that gets people (and biostatisticians) a little nervous. Once we get beyond the primary analysis, all bets are off. If we look hard enough at the data, we may eventually find something that is interesting to report on. But, just because we find something with the data in hand, it does not mean that we would find it again in another data set from another study. Any conclusions we draw may be unwarranted:</p>
<p><br></p>
<div class="figure">
<img src="extra/significant.png" style="width:50.0%" alt="" />
<p class="caption">Source: <a href="https://xkcd.com/882/" target="_blank">XKCD</a></p>
</div>
<p>The CONTAIN trial was conducted under very difficult circumstances, where the context was rapidly changing over time. Particularly challenging was the fact that new therapies were introduced for hospitalized patients over the course of the trial. And when we looked at the data, we noticed that while all patients had poor clinical outcomes in the first several months of the study, CCP appeared to offer some benefits. Later on in the study, when corticosteroids and remdesivir were standard of care, overall patient outcomes were dramatically improved, and CCP was no longer providing any benefits. This was a very interesting finding that we felt merited some discussion.</p>
<p>Not surprisingly, we have received some push back, suggesting that this finding is a classic case of <a href="https://www.rdatagen.net/post/regression-to-the-mean/" target="_blank">regression to the mean</a>. Normally, I would not have been comfortable presenting those findings, particularly not in a highly visible journal article. But we had used a Bayesian modelling framework with quite quite skeptical prior distribution assumptions to evaluate the primary outcome and the exploratory outcomes, so we felt that while we needed to be cautious in how we presented the results, these were not green jelly bean findings. Given the strong biological plausibility, we felt quite strongly about adding these findings to the growing body of literature about CCP.</p>
<p>In this post, I am sharing a series of simulations to explore how conservative our conservative approach really is. This is <a href="https://www.rdatagen.net/post/2021-12-21-controling-type-1-error-rates-in-rcts-with-interim-looks-a-bayesian-perspective/" target="_blank">another look</a> at assessing Type I error rates, a frequentist notion, in the context of a Bayesian study design.</p>
<div id="the-subgroup-specific-treatment-effect" class="section level2">
<h2>The subgroup-specific treatment effect</h2>
<p>Let’s say there is a data generation process for individual <span class="math inline">\(i\)</span> with a (binary) outcome <span class="math inline">\(Y_i\)</span> with some (binary) treatment or exposure <span class="math inline">\(A_i\)</span> that looks like</p>
<p><span class="math display">\[log\left(\frac{P(Y_i=1)}{P(Y_i=0)}\right ) = \alpha + \delta A_i.\]</span></p>
<p>The log-odds is dependent only on the level of exposure <span class="math inline">\(A\)</span>.</p>
<p>Let’s say that we’ve also measured some characteristic <span class="math inline">\(G\)</span>, which is a categorical variable with three levels. While the primary aim of the study is to estimate <span class="math inline">\(\delta\)</span>, the log-odds ratio comparing treated with controls, we might also be interested in a subgroup analysis based on <span class="math inline">\(G\)</span>. That is, is there a unique group-level treatment effect for any level of <span class="math inline">\(G\)</span>, <span class="math inline">\(G \in \{1,2,3\}\)</span>? In terms of the model, this would be</p>
<p><span class="math display">\[ log\left(\frac{P(Y_i=1|G_i=g)}{P(Y_i=0|G_i=g)}\right ) = \alpha_g + \delta_g A_i, \ \  g \in \{1,2,3\}.\]</span></p>
<p>In the case here, we actually know that <span class="math inline">\(\alpha_g = \alpha\)</span> and <span class="math inline">\(\delta_g = \delta\)</span> for all <span class="math inline">\(g\)</span> because the data generation process is independent of <span class="math inline">\(G\)</span>. However, due to sampling error it is quite possible that we will observe some differences in the data.</p>
</div>
<div id="simulation" class="section level2">
<h2>Simulation</h2>
<p>We start by simulating this case of a single grouping with three potential subgroup analyses. First, here are the libraries used to create the examples in this post:</p>
<pre class="r"><code>library(simstudy)
library(data.table)
library(posterior)
library(bayesplot)
library(cmdstanr)
library(gtsummary)
library(paletteer)
library(ggplot2)
library(ggdist)</code></pre>
<div id="data-generation" class="section level4">
<h4>Data generation</h4>
<p>I’m generating 1000 subjects, with 500 in each treatment arm <span class="math inline">\(A\)</span>. About a third fall into each level of <span class="math inline">\(G\)</span>, and the binary outcome <span class="math inline">\(Y\)</span> takes a value of <span class="math inline">\(1\)</span> <span class="math inline">\(10\%\)</span> of the time for all subjects regardless of their treatment or group level</p>
<pre class="r"><code>def &lt;- defData(varname = &quot;g&quot;, formula = &quot;1/3;1/3;1/3&quot;, dist = &quot;categorical&quot;)
def &lt;- defData(def, &quot;a&quot;, formula = &quot;1;1&quot;, dist = &quot;trtAssign&quot;)
def &lt;- defData(def, &quot;y&quot;, formula = &quot;0.10&quot;, dist = &quot;binary&quot;)

RNGkind(&quot;L&#39;Ecuyer-CMRG&quot;)
set.seed(67)

dd &lt;- genData(1000, def)
dd</code></pre>
<pre><code>##         id g a y
##    1:    1 3 1 0
##    2:    2 3 1 0
##    3:    3 2 1 0
##    4:    4 2 0 0
##    5:    5 3 0 0
##   ---           
##  996:  996 2 0 0
##  997:  997 1 0 0
##  998:  998 1 1 0
##  999:  999 3 0 0
## 1000: 1000 3 1 0</code></pre>
<p>We can fit a simple <strong>logistic regression model</strong> to estimate <span class="math inline">\(\delta\)</span>, the overall effect of the treatment. We see that the estimate of the OR is very close to 1, suggesting the odds of <span class="math inline">\(Y=1\)</span> is similar for both groups, so no apparent treatment effect. (Note that the exponentiated intercept is an estimate of the odds of <span class="math inline">\(Y=1\)</span> for the control arm. The data generation process assumed <span class="math inline">\(P(Y=1) = 0.10\)</span>, so the odds are <span class="math inline">\(0.1/0.9 = 0.11\)</span>.)</p>
<pre class="r"><code>fitglm &lt;- glm(y ~ a, data = dd, family = &quot;binomial&quot;)
tbl_regression(fitglm, intercept = TRUE, exponentiate = TRUE)</code></pre>
<div id="mzrpzijtnm" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#mzrpzijtnm .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#mzrpzijtnm .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#mzrpzijtnm .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#mzrpzijtnm .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#mzrpzijtnm .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#mzrpzijtnm .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#mzrpzijtnm .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#mzrpzijtnm .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#mzrpzijtnm .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#mzrpzijtnm .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#mzrpzijtnm .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#mzrpzijtnm .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#mzrpzijtnm .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#mzrpzijtnm .gt_from_md > :first-child {
  margin-top: 0;
}

#mzrpzijtnm .gt_from_md > :last-child {
  margin-bottom: 0;
}

#mzrpzijtnm .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#mzrpzijtnm .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#mzrpzijtnm .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#mzrpzijtnm .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#mzrpzijtnm .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#mzrpzijtnm .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#mzrpzijtnm .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#mzrpzijtnm .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#mzrpzijtnm .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#mzrpzijtnm .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#mzrpzijtnm .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#mzrpzijtnm .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#mzrpzijtnm .gt_left {
  text-align: left;
}

#mzrpzijtnm .gt_center {
  text-align: center;
}

#mzrpzijtnm .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#mzrpzijtnm .gt_font_normal {
  font-weight: normal;
}

#mzrpzijtnm .gt_font_bold {
  font-weight: bold;
}

#mzrpzijtnm .gt_font_italic {
  font-style: italic;
}

#mzrpzijtnm .gt_super {
  font-size: 65%;
}

#mzrpzijtnm .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
</style>
<table class="gt_table">
  
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1"><strong>Characteristic</strong></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1"><strong>OR</strong><sup class="gt_footnote_marks">1</sup></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1"><strong>95% CI</strong><sup class="gt_footnote_marks">1</sup></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1"><strong>p-value</strong></th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td class="gt_row gt_left">(Intercept)</td>
<td class="gt_row gt_center">0.11</td>
<td class="gt_row gt_center">0.08, 0.14</td>
<td class="gt_row gt_center"><0.001</td></tr>
    <tr><td class="gt_row gt_left">a</td>
<td class="gt_row gt_center">1.02</td>
<td class="gt_row gt_center">0.67, 1.55</td>
<td class="gt_row gt_center">>0.9</td></tr>
  </tbody>
  
  <tfoot>
    <tr class="gt_footnotes">
      <td colspan="4">
        <p class="gt_footnote">
          <sup class="gt_footnote_marks">
            <em>1</em>
          </sup>
           
          OR = Odds Ratio, CI = Confidence Interval
          <br />
        </p>
      </td>
    </tr>
  </tfoot>
</table>
</div>
<p>So, we could not infer that for the entire group treatment <span class="math inline">\(A\)</span> has any effect. But, maybe for some subgroups there is a treatment effect? We can fit a generalized linear model that allows the intercept and effect estimate to vary by level of <span class="math inline">\(G\)</span>, and assess whether this is the case for subgroups defined by <span class="math inline">\(G\)</span>.</p>
<pre class="r"><code>fitglm &lt;- glm(y ~ factor(g) + a:factor(g) - 1, data = dd, family = &quot;binomial&quot;)
tbl_regression(fitglm, exponentiate = TRUE)</code></pre>
<div id="vrfcerwkzj" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#vrfcerwkzj .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#vrfcerwkzj .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#vrfcerwkzj .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#vrfcerwkzj .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#vrfcerwkzj .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#vrfcerwkzj .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#vrfcerwkzj .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#vrfcerwkzj .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#vrfcerwkzj .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#vrfcerwkzj .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#vrfcerwkzj .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#vrfcerwkzj .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#vrfcerwkzj .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#vrfcerwkzj .gt_from_md > :first-child {
  margin-top: 0;
}

#vrfcerwkzj .gt_from_md > :last-child {
  margin-bottom: 0;
}

#vrfcerwkzj .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#vrfcerwkzj .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#vrfcerwkzj .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#vrfcerwkzj .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#vrfcerwkzj .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#vrfcerwkzj .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#vrfcerwkzj .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#vrfcerwkzj .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#vrfcerwkzj .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#vrfcerwkzj .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#vrfcerwkzj .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#vrfcerwkzj .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#vrfcerwkzj .gt_left {
  text-align: left;
}

#vrfcerwkzj .gt_center {
  text-align: center;
}

#vrfcerwkzj .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#vrfcerwkzj .gt_font_normal {
  font-weight: normal;
}

#vrfcerwkzj .gt_font_bold {
  font-weight: bold;
}

#vrfcerwkzj .gt_font_italic {
  font-style: italic;
}

#vrfcerwkzj .gt_super {
  font-size: 65%;
}

#vrfcerwkzj .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
</style>
<table class="gt_table">
  
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1"><strong>Characteristic</strong></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1"><strong>OR</strong><sup class="gt_footnote_marks">1</sup></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1"><strong>95% CI</strong><sup class="gt_footnote_marks">1</sup></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1"><strong>p-value</strong></th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td class="gt_row gt_left">factor(g)</td>
<td class="gt_row gt_center"></td>
<td class="gt_row gt_center"></td>
<td class="gt_row gt_center"></td></tr>
    <tr><td class="gt_row gt_left" style="text-align: left; text-indent: 10px;">1</td>
<td class="gt_row gt_center">0.09</td>
<td class="gt_row gt_center">0.05, 0.15</td>
<td class="gt_row gt_center"><0.001</td></tr>
    <tr><td class="gt_row gt_left" style="text-align: left; text-indent: 10px;">2</td>
<td class="gt_row gt_center">0.11</td>
<td class="gt_row gt_center">0.07, 0.18</td>
<td class="gt_row gt_center"><0.001</td></tr>
    <tr><td class="gt_row gt_left" style="text-align: left; text-indent: 10px;">3</td>
<td class="gt_row gt_center">0.12</td>
<td class="gt_row gt_center">0.08, 0.20</td>
<td class="gt_row gt_center"><0.001</td></tr>
    <tr><td class="gt_row gt_left">factor(g) * a</td>
<td class="gt_row gt_center"></td>
<td class="gt_row gt_center"></td>
<td class="gt_row gt_center"></td></tr>
    <tr><td class="gt_row gt_left" style="text-align: left; text-indent: 10px;">1 * a</td>
<td class="gt_row gt_center">1.23</td>
<td class="gt_row gt_center">0.57, 2.76</td>
<td class="gt_row gt_center">0.6</td></tr>
    <tr><td class="gt_row gt_left" style="text-align: left; text-indent: 10px;">2 * a</td>
<td class="gt_row gt_center">1.24</td>
<td class="gt_row gt_center">0.64, 2.45</td>
<td class="gt_row gt_center">0.5</td></tr>
    <tr><td class="gt_row gt_left" style="text-align: left; text-indent: 10px;">3 * a</td>
<td class="gt_row gt_center">0.69</td>
<td class="gt_row gt_center">0.32, 1.44</td>
<td class="gt_row gt_center">0.3</td></tr>
  </tbody>
  
  <tfoot>
    <tr class="gt_footnotes">
      <td colspan="4">
        <p class="gt_footnote">
          <sup class="gt_footnote_marks">
            <em>1</em>
          </sup>
           
          OR = Odds Ratio, CI = Confidence Interval
          <br />
        </p>
      </td>
    </tr>
  </tfoot>
</table>
</div>
<p>While there is more variability in the estimates, we still wouldn’t conclude that there are treatment effects within each level of <span class="math inline">\(G\)</span>.</p>
</div>
<div id="the-bayesian-model" class="section level4">
<h4>The Bayesian model</h4>
<p>Since the purpose of this post is to illustrate how an appropriately specified Bayesian model can provide slightly more reliable estimates, particularly in the case where there really are no underlying treatment effects, here is a Bayes model that estimates subgroup-level intercepts and treatment effects:</p>
<p><span class="math display">\[Y_{ig} \sim Bin(p_{ig})\]</span>
<span class="math display">\[log\left(\frac{p_{ig}}{1-p_{ig}}\right) = \alpha_g + \delta_gA_i, \ \ g \in \{1,2,3\}  \]</span></p>
<p>The prior distribution assumptions for the parameters <span class="math inline">\(\alpha_g\)</span> and <span class="math inline">\(\delta_g\)</span> are</p>
<span class="math display">\[\begin{aligned}
  \alpha_g &amp;\sim N(\mu = 0, \sigma = 10), \ \ g \in \{1,2,3\} \\

  \delta_g &amp;\sim N(\mu=\delta, \sigma = 0.3537), \ \ g \in \{1,2,3\} \\

  \delta &amp;\sim N(\mu = 0, \sigma = 0.3537)
\end{aligned}\]</span>
<p>Note that the variance of the <span class="math inline">\(\delta_g\text{&#39;s}\)</span> around <span class="math inline">\(\delta\)</span> has been specified, but it could be estimated. However, since there are very few levels of <span class="math inline">\(G\)</span>, estimation of the variance can be slow; to speed the simulations, I’ve chosen a quicker path by specifying a pretty informative prior.</p>
</div>
<div id="fitting-the-bayes-model" class="section level4">
<h4>Fitting the Bayes model</h4>
<p>The <code>Stan</code> code that implements this model can be found in the <a href="#addendum">addendum</a>. To estimate the model, the the data need to be passed as a list - and here is a function to convert the <code>R</code> data into the proper format:</p>
<pre class="r"><code>listdat &lt;- function(dx, grpvar) {
  
  dx[, grp := factor(get(grpvar))]
  
  N &lt;- dx[, .N]
  L &lt;- dx[, nlevels(grp)]
  y &lt;- dx[, y]
  a &lt;- dx[, a]
  grp &lt;-dx[, as.numeric(grp)]
  
  list(N = N, L = L, y = y, a = a, grp = grp)
}</code></pre>
<p>After compiling the program, samples from the posterior are drawn using four chains. There will be a total of 12000 samples (not including the warm-up samples):</p>
<pre class="r"><code>mod &lt;- cmdstan_model(&quot;extra/simulation.stan&quot;)

fitbayes &lt;- mod$sample(
    data = listdat(dd, &quot;g&quot;),
    refresh = 0,
    chains = 4L,
    parallel_chains = 4L,
    iter_warmup = 1500,
    iter_sampling = 3000
)</code></pre>
<pre><code>## Running MCMC with 4 parallel chains...
## 
## Chain 3 finished in 5.3 seconds.
## Chain 2 finished in 5.7 seconds.
## Chain 1 finished in 5.9 seconds.
## Chain 4 finished in 6.1 seconds.
## 
## All 4 chains finished successfully.
## Mean chain execution time: 5.8 seconds.
## Total execution time: 6.2 seconds.</code></pre>
<p>The estimates are quite similar to the <code>glm</code> estimates, though the ORs are pulled slightly towards 1 as a result of the informative prior. This is going to be the trick that ultimately protects the Type I error rate from completely blowing up.</p>
<pre class="r"><code>fitbayes$summary(c(&quot;Odds_g&quot;,&quot;OR_g&quot;))</code></pre>
<pre><code>## # A tibble: 6 × 10
##   variable    mean median     sd    mad     q5   q95  rhat ess_bulk ess_tail
##   &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
## 1 Odds_g[1] 0.0932 0.0910 0.0237 0.0230 0.0586 0.136  1.00    8636.    9489.
## 2 Odds_g[2] 0.118  0.116  0.0258 0.0254 0.0800 0.165  1.00    8924.    8875.
## 3 Odds_g[3] 0.115  0.112  0.0262 0.0260 0.0757 0.161  1.00    9734.    9569.
## 4 OR_g[1]   1.16   1.11   0.345  0.317  0.689  1.80   1.00    8077.    8824.
## 5 OR_g[2]   1.17   1.13   0.320  0.300  0.724  1.77   1.00    7922.    8641.
## 6 OR_g[3]   0.884  0.848  0.256  0.239  0.527  1.36   1.00    8817.    8620.</code></pre>
<p>And here is a plot of the posterior distributions for the treatment effect at each subgroup defined by the levels of <span class="math inline">\(G\)</span>:</p>
<pre class="r"><code>OR_df &lt;- data.frame(as_draws_rvars(fitbayes$draws(variables = &quot;OR_g&quot;)))

p_data &lt;- with(OR_df, data.frame(
  cat = c(&quot;c1&quot;, &quot;c2&quot;, &quot;c3&quot;),
  OR_g = OR_g
))

ggplot(data = p_data, aes(dist = OR_g, y = cat)) +
  geom_vline(xintercept = 1, color = &quot;grey80&quot;, size = .3) +
  stat_dist_halfeye(fill = palettes_d$awtools$a_palette[6], position=&quot;dodge&quot;) +
  theme(panel.grid = element_blank()) +
  ylab(&quot;category&quot;) +
  scale_x_continuous(limits = c(0, 2), name = &quot;OR&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-8-1.png" width="384" /></p>
<p>It is easy to see that the 95% credible intervals all include the value of 1, no treatment effect, so we wouldn’t be tempted to conclude that there is any treatment effect. We can also check manually to see if at least one of the credible intervals excludes 1. The answer is still “no.”</p>
<pre class="r"><code>with(OR_df, any((quantile(OR_g, .025) &gt; 1) | (quantile(OR_g, .975) &lt; 1)))</code></pre>
<pre><code>## [1] FALSE</code></pre>
</div>
</div>
<div id="increasing-the-number-of-subgroups" class="section level2">
<h2>Increasing the number of subgroups</h2>
<p>As the jelly beans make clear, things can really start to go awry when we start to investigate many possible subgroups. This can either be a single characteristic (like color) that has many, many levels, each of which can be a subgroup, or this can be many different characteristics that each have a few different levels. In our trial, we had the latter, all based on baseline data collection (and all reported as categories). These included health status, age, blood type, time between COVID symptom onset, medications, quarter of enrollment, and others.</p>
<p>My interest here is to see how fast the Type I error increases as the number of subgroups increases. I consider that a Type I error has occurred if <em>any</em> of the subgroups would be declared what I am calling potentially “interesting”. “Interesting” and by no means definitive, because while the results might suggest that treatment effects are stronger in a particular subgroup, we do need to be aware that these are exploratory analyses.</p>
<p>To explore Type I error rates, I will generate 20 categories, each of which has three levels. I can then use the model estimates from each of the subgroup analyses to evaluate how many times I would draw the wrong conclusion.</p>
<div id="generating-multiple-categories" class="section level4">
<h4>Generating multiple categories</h4>
<p>To illustrate how I code all of this, I am starting with a case where there are four categories, each with three levels. In the data set, these categories are named <em>g1</em>, <em>g2</em>, <em>g3</em>, and <em>g4</em>:</p>
<pre class="r"><code>genRepeatDef &lt;- function(nvars, prefix, formula, variance, dist, link = &quot;identity&quot;) {
  varnames &lt;- paste0(prefix, 1 : nvars)
  data.table(varname = varnames, 
             formula = formula, 
             variance = variance, 
             dist = dist, link = link)
}

def &lt;- genRepeatDef(4, &quot;g&quot;, &quot;1/3;1/3;1/3&quot;, 0, &quot;categorical&quot;)
def &lt;- defData(def, &quot;a&quot;, formula = &quot;1;1&quot;, dist = &quot;trtAssign&quot;)
def &lt;- defData(def, &quot;y&quot;, formula = &quot;0.10&quot;, dist = &quot;binary&quot;)

def</code></pre>
<pre><code>##    varname     formula variance        dist     link
## 1:      g1 1/3;1/3;1/3        0 categorical identity
## 2:      g2 1/3;1/3;1/3        0 categorical identity
## 3:      g3 1/3;1/3;1/3        0 categorical identity
## 4:      g4 1/3;1/3;1/3        0 categorical identity
## 5:       a         1;1        0   trtAssign identity
## 6:       y        0.10        0      binary identity</code></pre>
<p>A single data set based on these definitions looks like this:</p>
<pre class="r"><code>RNGkind(&quot;L&#39;Ecuyer-CMRG&quot;)
set.seed(67) #4386212 83861 7611291

dd &lt;- genData(1000, def)
dd</code></pre>
<pre><code>##         id g1 g2 g3 g4 a y
##    1:    1  3  3  2  1 0 0
##    2:    2  3  3  1  3 1 1
##    3:    3  2  3  2  1 1 0
##    4:    4  2  1  1  1 0 0
##    5:    5  3  1  2  3 0 0
##   ---                     
##  996:  996  2  1  2  1 0 0
##  997:  997  1  1  2  2 1 0
##  998:  998  1  1  2  1 0 0
##  999:  999  3  2  1  1 1 0
## 1000: 1000  3  3  3  3 1 0</code></pre>
<p>The function <code>fitmods</code> estimates both the <code>glm</code> and <code>stan</code> models for a single category. The models provide subgroup estimates of treatment effects, just as the example above did:</p>
<pre class="r"><code>fitmods &lt;-function(dx, grpvar) {
  
  # GLM
  
  dx[, grp := factor(get(grpvar))]
  fitglm &lt;- glm(y ~ grp + a:grp - 1, data = dx, family = &quot;binomial&quot;)
  
  pvals &lt;- coef(summary(fitglm))[, &quot;Pr(&gt;|z|)&quot;]

  lpval &lt;- length(pvals)
  freq_res &lt;- any(pvals[(lpval/2 + 1) : lpval] &lt; 0.05)
  
  # Bayes
  
  dat &lt;- listdat(dx, grpvar)
  
  fitbayes &lt;- mod$sample(
    data = dat,
    refresh = 0,
    chains = 4L,
    parallel_chains = 4L,
    iter_warmup = 1500,
    iter_sampling = 3000
  )
  
  OR_df &lt;- data.frame(as_draws_rvars(fitbayes$draws(variables = &quot;OR_g&quot;)))
  bayes_res &lt;- with(OR_df, 
    any((quantile(OR_g, .025) &gt; 1) | (quantile(OR_g, .975) &lt; 1)))
  
  # Return results

  list(type1_dt = data.table(var = grpvar, bayes_res, freq_res),
       OR_post = data.frame(var = grpvar, cat = paste0(&quot;c&quot;,1:3), OR_df)
  )
  
}</code></pre>
<p>In this case, I am calling the function <code>fitmods</code> for each of the four categorical groupings <em>g1</em> through <em>g4</em>:</p>
<pre class="r"><code>res &lt;- lapply(paste0(&quot;g&quot;, 1:4), function(a) fitmods(dd, a))</code></pre>
<pre><code>## Running MCMC with 4 parallel chains...
## 
## Chain 2 finished in 5.3 seconds.
## Chain 1 finished in 5.4 seconds.
## Chain 4 finished in 5.5 seconds.
## Chain 3 finished in 5.7 seconds.
## 
## All 4 chains finished successfully.
## Mean chain execution time: 5.5 seconds.
## Total execution time: 5.7 seconds.
## Running MCMC with 4 parallel chains...
## 
## Chain 2 finished in 5.5 seconds.
## Chain 1 finished in 5.6 seconds.
## Chain 3 finished in 5.6 seconds.
## Chain 4 finished in 5.5 seconds.
## 
## All 4 chains finished successfully.
## Mean chain execution time: 5.5 seconds.
## Total execution time: 5.6 seconds.
## Running MCMC with 4 parallel chains...
## 
## Chain 4 finished in 5.5 seconds.
## Chain 2 finished in 5.6 seconds.
## Chain 1 finished in 5.8 seconds.
## Chain 3 finished in 5.9 seconds.
## 
## All 4 chains finished successfully.
## Mean chain execution time: 5.7 seconds.
## Total execution time: 5.9 seconds.
## Running MCMC with 4 parallel chains...
## 
## Chain 2 finished in 5.8 seconds.
## Chain 1 finished in 5.8 seconds.
## Chain 3 finished in 5.8 seconds.
## Chain 4 finished in 6.0 seconds.
## 
## All 4 chains finished successfully.
## Mean chain execution time: 5.9 seconds.
## Total execution time: 6.1 seconds.</code></pre>
<p>One of the arguments returned by <code>fitmods</code> is a data.table of summary results for each of the four categorical grouping. If any of the effect estimates for one or more of the three subgroup levels in a category was deemed “interesting” (based on a p-value &lt; 0.05 for the <code>glm</code> model, and the value 1 falling outside the 95% credible interval for the <code>stan</code> model), then the function returned a value of 1 or TRUE. In this case, at least one of the subgroups within <em>g4</em> would have been declared interesting based on the <code>glm</code> and <code>stan</code> models; at least one of the subgroups within <em>g2</em> would have been deemed interesting, but only based on the <code>glm</code> model:</p>
<pre class="r"><code>type1_dt &lt;- rbindlist(lapply(res, function(x) x$type1_dt))
type1_dt</code></pre>
<pre><code>##    var bayes_res freq_res
## 1:  g1     FALSE    FALSE
## 2:  g2     FALSE     TRUE
## 3:  g3     FALSE    FALSE
## 4:  g4      TRUE     TRUE</code></pre>
<p>We can see this visually for the <code>stan</code> models by looking at the density plots for each subgroup within each category:</p>
<pre class="r"><code>dc &lt;- do.call(&quot;rbind&quot;, lapply(res, function(x) x$OR_post))

ggplot(data = dc, aes(dist = OR_g, y = cat)) +
  geom_vline(xintercept = 1, color = &quot;grey80&quot;, size = .3) +
  stat_dist_halfeye(fill = palettes_d$awtools$a_palette[7], alpha = .8) +
  theme(panel.grid = element_blank()) +
  xlab(&quot;OR&quot;) +
  facet_wrap(~ var)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>We calculate the first occurrence of an <em>interesting</em> subgroup by looking across <em>g1</em> through <em>g4</em>. This will be useful for figuring out the Type I error rates for different numbers of categories. In this case, the first interesting subgroup based on the <code>stan</code> model is found when there are four categories; for the <code>glm</code> model, the first interesting subgroup is with two categories.</p>
<pre class="r"><code>first_true &lt;- sapply(type1_dt[, c(2,3)], function(x) match(TRUE, x))
first_true</code></pre>
<pre><code>## bayes_res  freq_res 
##         4         2</code></pre>
</div>
</div>
<div id="simulation-study-results" class="section level2">
<h2>Simulation study results</h2>
<p>Now, with that background, here are the results based on 1050 simulated data sets (because I had access to 75 cores on a high performance computing cluster) with 20 categorical groups of three levels each. For each data set <span class="math inline">\(r, \ r \in \{1,\dots,1050\}\)</span>, I determined the first occurrence of an “interesting” finding among the 20 categories for each model, and stored this in <span class="math inline">\(F_{br}\)</span> and <span class="math inline">\(F_{fr}\)</span> for the Bayes and frequentist models, respectively. <span class="math inline">\(T_m(g)\)</span> is the error rate for the model type <span class="math inline">\(m\)</span>, <span class="math inline">\(m \in \{b, f\}\)</span> with <span class="math inline">\(g\)</span> number of categories, and</p>
<p><span class="math display">\[
T_m(g) = \frac{\sum_{r=1}^{1050} I(F_{mr} \le g)}{1050}
\]</span></p>
<p>Here is a plot of the Type I error rates calculated different numbers of categories. With the frequentist model (based on p-values) the error rates get quite large quite quickly, exceeding 50% by the time we reach 8 categories. In comparison, the error rates under the Bayes model with skeptical prior assumptions are held in check quite a bit better.</p>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>Even for the Bayes approach, however, the error rate is close to 20% for 12 categories. So, we still need to be careful in drawing conclusions. In the case that we do find some potentially interesting results (which we did in the case of the CCP CONTAIN trial), readers certainly have a right to be skeptical, but there is no reason to completely dismiss the findings out of hand. These sorts of findings suggest that more work needs to be done to better understand the nature of the treatment effects.</p>
<p><a name="addendum"></a></p>
<div id="addendum" class="section level3">
<h3>Addendum</h3>
<pre class="stan"><code>data {
  int&lt;lower=0&gt; N;              // number of observations
  int&lt;lower=1&gt; L;              // number of levels
  int&lt;lower=0,upper=1&gt; y[N];   // vector of categorical outcomes
  int&lt;lower=0,upper=1&gt; a[N];   // treatment arm for individual
  int&lt;lower=1,upper=4&gt; grp[N]; // grp for individual  
}

parameters {
  vector[L] alpha_g;           // group effect
  real delta_g[L];             // group treatment effects
  real delta;                  // overall treatment effect
}

transformed parameters{ 
  
  vector[N] yhat;

  for (i in 1:N)  
    yhat[i] = alpha_g[grp[i]] + a[i] * delta_g[grp[i]];
}

model {
  
  // priors
  
  alpha_g ~ normal(0, 10);
  delta_g ~ normal(delta, 0.3537);
  delta ~ normal(0, 0.3537);
  
  // outcome model
  
  for (i in 1:N)
    y[i] ~  bernoulli_logit(yhat[i]);
}

generated quantities {
  
  real&lt;lower = 0&gt; OR_g[L];
  real&lt;lower = 0&gt; Odds_g[L];

  real&lt;lower = 0&gt; OR;

  for (i in 1:L) {
    OR_g[i] = exp(delta_g[i]);   
    Odds_g[i] = exp(alpha_g[i]);
  }
  
  OR = exp(delta);
  
}</code></pre>
</div>
</div>
