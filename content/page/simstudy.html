---
title: "simstudy package"
comments: false
---



<STYLE TYPE="text/css">
<!--
  td{
    font-family: Arial; 
    font-size: 8pt;
    height: 2px;
    padding:0px;
    cellpadding="0";
    cellspacing="0";
    text-align: center;
  }
  th {
    font-family: Arial; 
    font-size: 9pt;
    height: 20px;
    font-weight: bold;
    text-align: center;
  }
  table { 
    border-spacing: 0px;
    border-collapse: collapse;
  }
--->
</STYLE>
<p>Simulation using <a href="https://cran.r-project.org/web/packages/simstudy/index.html"><code>simstudy</code></a> has two primary steps. First, the user <strong>defines</strong> the data elements of a data set. Second, the user <strong>generates</strong> the data, using the definitions in the first step. Additional functionality exists to simulate observed or randomized <strong>treatment assignment/exposures</strong>, to generate <strong>survival</strong> data, to create <strong>longitudinal/panel</strong> data, to create <strong>multi-level/hierarchical</strong> data, to create datasets with <strong>correlated variables</strong> based on a specified covariance structure, to <strong>merge</strong> datasets, and to create data sets with <strong>missing</strong> data.</p>
<div id="defining-the-data" class="section level2">
<h2>Defining the data</h2>
<p>The key to simulating data in <code>simstudy</code> is the creation of series of data defintion tables that look like this:</p>
<table>
<thead>
<tr class="header">
<th align="left">varname</th>
<th align="left">formula</th>
<th align="right">variance</th>
<th align="left">dist</th>
<th align="left">link</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">nr</td>
<td align="left">7</td>
<td align="right">0</td>
<td align="left">nonrandom</td>
<td align="left">identity</td>
</tr>
<tr class="even">
<td align="left">x1</td>
<td align="left">10;20</td>
<td align="right">0</td>
<td align="left">uniform</td>
<td align="left">identity</td>
</tr>
<tr class="odd">
<td align="left">y1</td>
<td align="left">nr + x1 * 2</td>
<td align="right">8</td>
<td align="left">normal</td>
<td align="left">identity</td>
</tr>
<tr class="even">
<td align="left">y2</td>
<td align="left">nr - 0.2 * x1</td>
<td align="right">0</td>
<td align="left">poisson</td>
<td align="left">log</td>
</tr>
<tr class="odd">
<td align="left">xCat</td>
<td align="left">0.3;0.2;0.5</td>
<td align="right">0</td>
<td align="left">categorical</td>
<td align="left">identity</td>
</tr>
<tr class="even">
<td align="left">g1</td>
<td align="left">5+xCat</td>
<td align="right">1</td>
<td align="left">gamma</td>
<td align="left">log</td>
</tr>
<tr class="odd">
<td align="left">a1</td>
<td align="left">-3 + xCat</td>
<td align="right">0</td>
<td align="left">binary</td>
<td align="left">logit</td>
</tr>
</tbody>
</table>
<p>These <em>definition</em> tables can be generated two ways. One option is to to use any external editor that allows the creation of <code>csv</code> files, which can be read in with a call to <code>defRead</code>. An alternative is to make repeated calls to the function <code>defData</code>. Here, we illustrate the R code that builds this definition table internally:</p>
<pre class="r"><code>def &lt;- defData(varname = &quot;nr&quot;, dist = &quot;nonrandom&quot;, formula = 7, id = &quot;idnum&quot;)
def &lt;- defData(def, varname = &quot;x1&quot;, dist = &quot;uniform&quot;, formula = &quot;10;20&quot;)
def &lt;- defData(def, varname = &quot;y1&quot;, formula = &quot;nr + x1 * 2&quot;, variance = 8)
def &lt;- defData(def, varname = &quot;y2&quot;, dist = &quot;poisson&quot;, formula = &quot;nr - 0.2 * x1&quot;, 
    link = &quot;log&quot;)
def &lt;- defData(def, varname = &quot;xCat&quot;, formula = &quot;0.3;0.2;0.5&quot;, dist = &quot;categorical&quot;)
def &lt;- defData(def, varname = &quot;g1&quot;, dist = &quot;gamma&quot;, formula = &quot;5+xCat&quot;, variance = 1, 
    link = &quot;log&quot;)
def &lt;- defData(def, varname = &quot;a1&quot;, dist = &quot;binary&quot;, formula = &quot;-3 + xCat&quot;, 
    link = &quot;logit&quot;)</code></pre>
<p>The first call to <code>defData</code> without specifying a definition name (in this example the definition name is <em>def</em>) creates a <strong>new</strong> data.table with a single row. An additional row is added to the table <code>def</code> each time the function <code>defData</code> is called. Each of these calls is the definition of a new field in the data set that will be generated. In this example, the first data field is named ‘nr’, defined as a constant with a value to be 7. In each call to <code>defData</code> the user defines a variable name, a distribution (the default is ‘normal’), a mean formula (if applicable), a variance parameter (if applicable), and a link function for the mean (defaults to ‘identity’).</p>
<p>The possible distributions include <strong>normal</strong>, <strong>gamma</strong>, <strong>poisson</strong>, <strong>zero-truncated poisson</strong>, <strong>binary</strong>, <strong>uniform</strong>, <strong>categorical</strong>, and <strong>deterministic/non-random</strong>. For all of these distributions, key parameters defining the distribution are entered in the <code>formula</code>, <code>variance</code>, and <code>link</code> fields.</p>
<p>In the case of the <strong>normal</strong> and <strong>gamma</strong> distributions, the formula specifies the mean. The formula can be a scalar value (number) or a string that represents a function of previously defined variables in the data set definition (or, as we will see later, in a previously generated data set). In the example, the mean of <code>y1</code>, a normally distributed value, is declared as a linear function of <code>nr</code> and <code>x1</code>, and the mean of <code>g1</code> is a function of the category defined by <code>xCat</code>. The <code>variance</code> field is defined only for normal and gamma random variables, and can only be defined as a scalar value. In the case of gamma random variables, the value entered in variance field is really a dispersion value <span class="math inline">\(d\)</span>, where the actual variance will be <span class="math inline">\(d \times mean^2\)</span>.</p>
<p>In the case of the <strong>poisson</strong>, <strong>zero-truncated poisson</strong>, and <strong>binary</strong> distributions, the formula also specifies the mean. The variance is not a valid parameter in these cases, but the <code>link</code> field is. The default link is ‘identity’ but a ‘log’ link is available for the poisson distributions and a “logit” link is available for the binary outcomes. In this example, <code>y2</code> is defined as poisson random variable with a mean that is function of <code>nr</code> and <code>x1</code> on the log scale. For binary variables, which take a value of 0 or 1, the formula represents probability (with the ‘identity’ link) or log odds (with the ‘logit’ link) of the variable having a value of 1. In the example, <code>a1</code> has been defined as a binary random variable with a log odds that is a function of <code>xCat</code>.</p>
<p>Variables defined with a <strong>uniform</strong>, <strong>categorical</strong>, or <strong>deterministic/non-random</strong> distribution are specified using the formula only. The <code>variance</code> and <code>link</code> fields are not used in these cases.</p>
<p>For a uniformly distributed variable, The formula is a string with the format “a;b”, where <em>a</em> and <em>b</em> are scalars or functions of previously defined variables. The uniform distribution has two parameters - the minimum and the maximum. In this case, <em>a</em> represents the minimum and <em>b</em> represents the maximum.</p>
<p>For a categorical variable with <span class="math inline">\(k\)</span> categories, the formula is a string of probabilities that sum to 1: “<span class="math inline">\(p_1 ; p_2 ; ... ; p_k\)</span>”. <span class="math inline">\(p_1\)</span> is the probability of the random variable falling category 1, <span class="math inline">\(p_2\)</span> is the probablity of category 2, etc. The probabilities can be specified as functions of other variables previously defined. In the example, <code>xCat</code> has three possibilities with probabilites 0.3, 0.2, and 0.5, respectively.</p>
<p>Non-random variables are defined by the formula. Since these variables are deterministic, variance is not relevant. They can be functions of previously defined variables or a scalar, as we see in the sample for variable defined as <code>nr</code>.</p>
</div>
<div id="generating-the-data" class="section level2">
<h2>Generating the data</h2>
<p>After the data set definitions have been created, a new data set with <span class="math inline">\(n\)</span> observations can be created with a call to function <strong><code>genData</code></strong>. In this example, 1,000 observations are generated using the data set defitions in <strong><code>def</code></strong>, and then stored in the object <strong><code>dt</code></strong>:</p>
<pre class="r"><code>dt &lt;- genData(1000, def)
dt</code></pre>
<pre><code>##       idnum nr       x1       y1  y2 xCat         g1 a1
##    1:     1  7 18.71470 48.13110  25    1 1104.82145  0
##    2:     2  7 12.63977 34.82680  87    2  222.26269  1
##    3:     3  7 13.21247 34.96022  80    1  289.08795  0
##    4:     4  7 19.21613 38.93975  17    3 1218.53035  0
##    5:     5  7 10.70988 24.16021 148    1 1011.98398  0
##   ---                                                  
##  996:   996  7 12.69114 34.43474  88    3 1007.88648  0
##  997:   997  7 11.48129 31.34903 108    3 4146.61939  0
##  998:   998  7 16.88184 41.60436  45    1   27.90073  0
##  999:   999  7 10.24263 25.36589 151    3 4626.50014  0
## 1000:  1000  7 12.72076 33.53079  78    1   37.97592  0</code></pre>
<p>New data can be added to an existing data set with a call to function <strong><code>addColumns</code></strong>. The new data definitions are created with a call to <strong><code>defData</code></strong> and then included as an argument in the call to <strong><code>addColumns</code></strong>:</p>
<pre class="r"><code>addef &lt;- defDataAdd(varname = &quot;zExtra&quot;, dist = &quot;normal&quot;, formula = &quot;3 + y1&quot;, 
    variance = 2)

dt &lt;- addColumns(addef, dt)
dt</code></pre>
<pre><code>##       idnum nr       x1       y1  y2 xCat         g1 a1   zExtra
##    1:     1  7 18.71470 48.13110  25    1 1104.82145  0 51.82939
##    2:     2  7 12.63977 34.82680  87    2  222.26269  1 38.09525
##    3:     3  7 13.21247 34.96022  80    1  289.08795  0 37.20631
##    4:     4  7 19.21613 38.93975  17    3 1218.53035  0 41.14921
##    5:     5  7 10.70988 24.16021 148    1 1011.98398  0 26.37784
##   ---                                                           
##  996:   996  7 12.69114 34.43474  88    3 1007.88648  0 36.83071
##  997:   997  7 11.48129 31.34903 108    3 4146.61939  0 37.31045
##  998:   998  7 16.88184 41.60436  45    1   27.90073  0 45.54451
##  999:   999  7 10.24263 25.36589 151    3 4626.50014  0 30.51333
## 1000:  1000  7 12.72076 33.53079  78    1   37.97592  0 35.63998</code></pre>
</div>
<div id="generating-the-treatmentexposure" class="section level2">
<h2>Generating the treatment/exposure</h2>
<p>Treatment assignment can be accomplished through the original data generation process, using <code>defData</code> and <code>genData</code>. However, the functions <code>trtAssign</code> and <code>trtObserve</code> provide more options to generate treatment assignment.</p>
<div id="assigned-treatment" class="section level3">
<h3>Assigned treatment</h3>
<p>Treatment assignment can simulate how treatment is made in a randomized study. Assignment to treatment groups can be (close to) balanced (as would occur in a block randomized trial); this balancing can be done without or without strata. Alternatively, the assignment can be left to chance without blocking; in this case, balance across treatment groups is not guaranteed, particularly with small sample sizes.</p>
<p>First, create the data definition:</p>
<pre class="r"><code>def &lt;- defData(varname = &quot;male&quot;, dist = &quot;binary&quot;, formula = 0.5, id = &quot;cid&quot;)
def &lt;- defData(def, varname = &quot;over65&quot;, dist = &quot;binary&quot;, formula = &quot;-1.7 + .8*male&quot;, 
    link = &quot;logit&quot;)
def &lt;- defData(def, varname = &quot;baseDBP&quot;, dist = &quot;normal&quot;, formula = 70, variance = 40)

dtstudy &lt;- genData(330, def)</code></pre>
<p><em>Balanced treatment assignment, stratified by gender and age category (not blood pressure)</em></p>
<pre class="r"><code>study1 &lt;- trtAssign(dtstudy, n = 3, balanced = TRUE, strata = c(&quot;male&quot;, &quot;over65&quot;), 
    grpName = &quot;rxGrp&quot;)

study1</code></pre>
<pre><code>##      cid rxGrp male over65  baseDBP
##   1:   1     1    1      0 70.51994
##   2:   2     3    1      0 68.37788
##   3:   3     2    1      0 68.91449
##   4:   4     3    1      1 58.65074
##   5:   5     3    1      1 59.28269
##  ---                               
## 326: 326     1    1      0 61.63004
## 327: 327     2    0      0 78.49473
## 328: 328     2    0      0 71.21033
## 329: 329     3    1      0 71.90673
## 330: 330     2    0      0 67.42199</code></pre>
<p><em>Balanced treatment assignment (without stratification)</em></p>
<pre class="r"><code>study2 &lt;- trtAssign(dtstudy, n = 3, balanced = TRUE, grpName = &quot;rxGrp&quot;)</code></pre>
<p><em>Random (unbalanced) treatment assignment</em></p>
<pre class="r"><code>study3 &lt;- trtAssign(dtstudy, n = 3, balanced = FALSE, grpName = &quot;rxGrp&quot;)</code></pre>
<p><em>Comparison of three treatment assignment mechanisms</em> <img src="/page/simstudy_files/figure-html/unnamed-chunk-10-1.png" width="384" /></p>
</div>
<div id="observed-treatment" class="section level3">
<h3>Observed treatment</h3>
<p>If exposure or treatment is observed (rather than randomly assigned), use <code>trtObserved</code> to generate groups. There may be any number of possible exposure or treatment groups, and the probability of exposure to a specific level can depend on covariates already in the data set. In this case, there are three exposure groups that vary by gender and age:</p>
<pre class="r"><code>formula1 &lt;- c(&quot;-2 + 2*male - .5*over65&quot;, &quot;-1 + 2*male + .5*over65&quot;)
dtExp &lt;- trtObserve(dtstudy, formulas = formula1, logit.link = TRUE, grpName = &quot;exposure&quot;)</code></pre>
<p>Here are the exposure distributions by gender and age:</p>
<p><img src="/page/simstudy_files/figure-html/unnamed-chunk-12-1.png" width="624" /></p>
<p>Here is a second case of three exposures where the exposure is independent of any covariates. Note that specifying the formula as <code>c(.35, .45)</code> is the same as specifying it is <code>c(.35, .45, .20)</code>. Also, when referring to probabilities, the identity link is used:</p>
<pre class="r"><code>formula2 &lt;- c(0.35, 0.45)

dtExp2 &lt;- trtObserve(dtstudy, formulas = formula2, logit.link = FALSE, grpName = &quot;exposure&quot;)</code></pre>
<p><img src="/page/simstudy_files/figure-html/unnamed-chunk-14-1.png" width="624" /></p>
</div>
</div>
<div id="survival-data" class="section level2">
<h2>Survival data</h2>
<p>Time-to-event data, including both survival and censoring times, are created using functions <code>defSurv</code> and <code>genSurv</code>. The survival data definitions require a variable name as well as a specification of a scale value, which determines the mean survival time at a baseline level of covariates (i.e. all covariates set to 0). The Weibull distribution is used to generate these survival times. In addition, covariates (which have been defined previously) that influence survival time can be included in the <code>formula</code> field. Positive coeffecients are associated with longer survival times (and lower hazard rates). Finally, the <em>shape</em> of the distribution can be specified. A <code>shape</code> value of 1 reflects the <em>exponential</em> distribution.</p>
<pre class="r"><code># Baseline data definitions

def &lt;- defData(varname = &quot;x1&quot;, formula = 0.5, dist = &quot;binary&quot;)
def &lt;- defData(def, varname = &quot;x2&quot;, formula = 0.5, dist = &quot;binary&quot;)
def &lt;- defData(def, varname = &quot;grp&quot;, formula = 0.5, dist = &quot;binary&quot;)

# Survival data definitions

sdef &lt;- defSurv(varname = &quot;survTime&quot;, formula = &quot;1.5*x1&quot;, scale = &quot;grp*50 + (1-grp)*25&quot;, 
    shape = &quot;grp*1 + (1-grp)*1.5&quot;)
sdef &lt;- defSurv(sdef, varname = &quot;censorTime&quot;, scale = 80, shape = 1)

sdef</code></pre>
<pre><code>##       varname formula               scale               shape
## 1:   survTime  1.5*x1 grp*50 + (1-grp)*25 grp*1 + (1-grp)*1.5
## 2: censorTime       0                  80                   1</code></pre>
<p>The data are generated with calls to <code>genData</code> and <code>genSurv</code>:</p>
<pre class="r"><code># Baseline data definitions

dtSurv &lt;- genData(300, def)
dtSurv &lt;- genSurv(dtSurv, sdef)

head(dtSurv)</code></pre>
<pre><code>##    id x1 x2 grp survTime censorTime
## 1:  1  1  1   1      380         21
## 2:  2  1  0   1      162         32
## 3:  3  0  1   0        0        539
## 4:  4  0  1   1       26         11
## 5:  5  0  0   1       56         17
## 6:  6  0  0   1      169         84</code></pre>
<pre class="r"><code># A comparison of survival by group and x1

dtSurv[, round(mean(survTime), 1), keyby = .(grp, x1)]</code></pre>
<pre><code>##    grp x1    V1
## 1:   0  0   9.8
## 2:   0  1  22.1
## 3:   1  0  53.8
## 4:   1  1 221.1</code></pre>
<p>Observed survival times and censoring indicators can be generated by defining new fields:</p>
<pre class="r"><code>cdef &lt;- defDataAdd(varname = &quot;obsTime&quot;, formula = &quot;pmin(survTime, censorTime)&quot;, 
    dist = &quot;nonrandom&quot;)
cdef &lt;- defDataAdd(cdef, varname = &quot;status&quot;, formula = &quot;I(survTime &lt;= censorTime)&quot;, 
    dist = &quot;nonrandom&quot;)

dtSurv &lt;- addColumns(cdef, dtSurv)

head(dtSurv)</code></pre>
<pre><code>##    id x1 x2 grp survTime censorTime obsTime status
## 1:  1  1  1   1      380         21      21      0
## 2:  2  1  0   1      162         32      32      0
## 3:  3  0  1   0        0        539       0      1
## 4:  4  0  1   1       26         11      11      0
## 5:  5  0  0   1       56         17      17      0
## 6:  6  0  0   1      169         84      84      0</code></pre>
<pre class="r"><code># estimate proportion of censoring by x1 and group

dtSurv[, round(1 - mean(status), 2), keyby = .(grp, x1)]</code></pre>
<pre><code>##    grp x1   V1
## 1:   0  0 0.09
## 2:   0  1 0.21
## 3:   1  0 0.39
## 4:   1  1 0.81</code></pre>
<p>Here is a Kaplan-Meier plot of the data by the four groups:</p>
<p><img src="/page/simstudy_files/figure-html/unnamed-chunk-18-1.png" width="624" /></p>
</div>
<div id="longitudinal-data" class="section level2">
<h2>Longitudinal data</h2>
<p>To simulate longitudinal data, we start with a ‘cross-sectional’ data set and convert it to a time-dependent data set. The original cross-sectional data set may or may not include time-dependent data in the columns. In the next example, we measure outcome <code>Y</code> once before and twice after intervention <code>T</code> in a randomized trial:</p>
<pre class="r"><code>tdef &lt;- defData(varname = &quot;T&quot;, dist = &quot;binary&quot;, formula = 0.5)
tdef &lt;- defData(tdef, varname = &quot;Y0&quot;, dist = &quot;normal&quot;, formula = 10, variance = 1)
tdef &lt;- defData(tdef, varname = &quot;Y1&quot;, dist = &quot;normal&quot;, formula = &quot;Y0 + 5 + 5 * T&quot;, 
    variance = 1)
tdef &lt;- defData(tdef, varname = &quot;Y2&quot;, dist = &quot;normal&quot;, formula = &quot;Y0 + 10 + 5 * T&quot;, 
    variance = 1)

dtTrial &lt;- genData(500, tdef)
dtTrial</code></pre>
<pre><code>##       id T        Y0       Y1       Y2
##   1:   1 0  9.183977 13.94165 17.27805
##   2:   2 1  8.643123 18.82474 22.37659
##   3:   3 1 10.324793 19.35620 25.71761
##   4:   4 0 10.282520 16.10805 20.92872
##   5:   5 1  9.657632 20.49713 22.13235
##  ---                                  
## 496: 496 0 10.430134 15.00519 20.56333
## 497: 497 0  9.801622 17.45522 19.28969
## 498: 498 1 12.034422 21.22105 28.24692
## 499: 499 1  9.359974 18.83581 25.33157
## 500: 500 0  8.817763 14.18292 20.04614</code></pre>
<p>The data in longitudinal form is created with a call to <strong><code>addPeriods</code></strong>. If the cross-sectional data includes time dependent data, then the number of periods <code>nPeriods</code> must be the same as the number of time dependent columns. If a variable is not declared as one of the <code>timevars</code>, it will be repeated each time period. In this example, the treatment indicator <code>T</code> is not specified as a time dependent variable. (Note: if there are two time-dependent variables, it is best to create two data sets and merge them. This will be shown later in the vignette).</p>
<pre class="r"><code>dtTime &lt;- addPeriods(dtTrial, nPeriods = 3, idvars = &quot;id&quot;, timevars = c(&quot;Y0&quot;, 
    &quot;Y1&quot;, &quot;Y2&quot;), timevarName = &quot;Y&quot;)
dtTime</code></pre>
<p>This is what the longitudinal data look like:</p>
<p><img src="/page/simstudy_files/figure-html/unnamed-chunk-21-1.png" width="576" /></p>
<div id="longitudinal-data-with-varying-observation-and-interval-times" class="section level3">
<h3>Longitudinal data with varying observation and interval times</h3>
<p>It is also possible to generate longitudinal data with varying numbers of measurement periods as well as varying time intervals between each measurement period. This is done by defining specific variables in the data set that define the number of observations per subject and the average interval time between each observation. <code>nCount</code> defines the number of measurements for an individual; <code>mInterval</code> specifies the average time between intervals for an subject; and <code>vInterval</code> specifies the variance of those interval times. If <code>vInterval</code> is set to 0 or is not defined, the interval for a subject is deterimined entirely by the mean interval. If <code>vInterval</code> is greater than 0, time intervals are generated using a gamma distribution with mean and dispersion specified.</p>
<p>In this simple example, the cross-sectional data generates individuals with a different number of measurement observations and different times between each observation. Data for two of these individuals is printed:</p>
<pre class="r"><code>def &lt;- defData(varname = &quot;xbase&quot;, dist = &quot;normal&quot;, formula = 20, variance = 3)
def &lt;- defData(def, varname = &quot;nCount&quot;, dist = &quot;noZeroPoisson&quot;, formula = 6)
def &lt;- defData(def, varname = &quot;mInterval&quot;, dist = &quot;gamma&quot;, formula = 30, variance = 0.01)
def &lt;- defData(def, varname = &quot;vInterval&quot;, dist = &quot;nonrandom&quot;, formula = 0.07)

dt &lt;- genData(200, def)
dt[id %in% c(8, 121)]  # View individuals 8 and 121</code></pre>
<pre><code>##     id    xbase nCount mInterval vInterval
## 1:   8 18.24515      5  33.84171      0.07
## 2: 121 17.33932      5  27.60829      0.07</code></pre>
<p>The resulting longitudinal data for these two subjects can be inspected after a call to <code>addPeriods</code>. Notice that no parameters need to be set since all information resides in the data set itself:</p>
<pre class="r"><code>dtPeriod &lt;- addPeriods(dt)
dtPeriod[id %in% c(8, 121)]  # View individuals 8 and 121 only</code></pre>
<pre><code>##      id period    xbase time timeID
##  1:   8      0 18.24515    0     49
##  2:   8      1 18.24515   56     50
##  3:   8      2 18.24515  107     51
##  4:   8      3 18.24515  151     52
##  5:   8      4 18.24515  180     53
##  6: 121      0 17.33932    0    753
##  7: 121      1 17.33932   14    754
##  8: 121      2 17.33932   37    755
##  9: 121      3 17.33932   66    756
## 10: 121      4 17.33932   94    757</code></pre>
<p>If a time sensitive measurement is added to the data set …</p>
<pre class="r"><code>def2 &lt;- defDataAdd(varname = &quot;Y&quot;, dist = &quot;normal&quot;, formula = &quot;15 + .1 * time&quot;, 
    variance = 5)
dtPeriod &lt;- addColumns(def2, dtPeriod)</code></pre>
<p>… a plot of a five randomly selected individuals looks like this:</p>
<p><img src="/page/simstudy_files/figure-html/unnamed-chunk-25-1.png" width="576" /></p>
</div>
</div>
<div id="clustered-data" class="section level2">
<h2>Clustered data</h2>
<p>The function <code>genCluster</code> generates multilevel or clustered data based on a previously generated data set that is one “level” up from the clustered data. For example, if there is a data set that contains school level (considered here to be level 2), classrooms (level 1) can be generated. And then, students (now level 1) can be generated within classrooms (now level 2)</p>
<p>In the example here, we do in fact generate school, class, and student level data. There are eight schools, four of which are randomized to receive an intervention. The number of classes per school varies, as does the number of students per class. (It is straightforward to generate fully balanced data by using constant values.) The outcome of interest is a test score, which is influenced by gender and the intervention. In addition, test scores vary by schools, and by classrooms, so the simulation provides <em>random effects</em> at each of these levels.</p>
<p>We start by definining the school level data:</p>
<pre class="r"><code>gen.school &lt;- defData(varname = &quot;s0&quot;, dist = &quot;normal&quot;, formula = 0, variance = 3, 
    id = &quot;idSchool&quot;)
gen.school &lt;- defData(gen.school, varname = &quot;nClasses&quot;, dist = &quot;noZeroPoisson&quot;, 
    formula = 3)

dtSchool &lt;- genData(8, gen.school)
dtSchool &lt;- trtAssign(dtSchool, n = 2)

dtSchool</code></pre>
<p>The classroom level data are generated with a call to <code>genCluster</code>, and then school level data is added by a call to <code>addColumns</code>:</p>
<pre class="r"><code>gen.class &lt;- defDataAdd(varname = &quot;c0&quot;, dist = &quot;normal&quot;, formula = 0, variance = 2)
gen.class &lt;- defDataAdd(gen.class, varname = &quot;nStudents&quot;, dist = &quot;noZeroPoisson&quot;, 
    formula = 20)

dtClass &lt;- genCluster(dtSchool, &quot;idSchool&quot;, numIndsVar = &quot;nClasses&quot;, level1ID = &quot;idClass&quot;)
dtClass &lt;- addColumns(gen.class, dtClass)

head(dtClass, 10)</code></pre>
<pre><code>##     idSchool trtGrp        s0 nClasses idClass         c0 nStudents
##  1:        1      0  4.507355        3       1 -1.7030717        19
##  2:        1      0  4.507355        3       2  0.9972415        19
##  3:        1      0  4.507355        3       3  0.6907191        19
##  4:        2      1 -1.774387        2       4  1.2638098        17
##  5:        2      1 -1.774387        2       5 -0.2549515        27
##  6:        3      1 -2.245730        5       6 -0.1392407        16
##  7:        3      1 -2.245730        5       7  0.9852097        17
##  8:        3      1 -2.245730        5       8  0.0693371        20
##  9:        3      1 -2.245730        5       9 -0.6584024        17
## 10:        3      1 -2.245730        5      10 -1.1545564         8</code></pre>
<p>Finally, the student level data are added using the same process:</p>
<pre class="r"><code>gen.student &lt;- defDataAdd(varname = &quot;Male&quot;, dist = &quot;binary&quot;, 
    formula = 0.5)
gen.student &lt;- defDataAdd(gen.student, varname = &quot;age&quot;, dist = &quot;uniform&quot;, 
    formula = &quot;9.5; 10.5&quot;)
gen.student &lt;- defDataAdd(gen.student, varname = &quot;test&quot;, dist = &quot;normal&quot;, 
    formula = &quot;50 - 5*Male + s0 + c0 + 8 * trtGrp&quot;, variance = 2)
dtStudent &lt;- genCluster(dtClass, cLevelVar = &quot;idClass&quot;, numIndsVar = &quot;nStudents&quot;, 
    level1ID = &quot;idChild&quot;)

dtStudent &lt;- addColumns(gen.student, dtStudent)</code></pre>
<p>This is what the clustered data look like. Each classroom is represented by a box, and each school is represented by a color. The intervention group is highlighted by dark outlines:</p>
<p><img src="/page/simstudy_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
</div>
<div id="correlated-data" class="section level2">
<h2>Correlated data</h2>
<p>Sometimes it is desireable to simulate correlated data from a correlation matrix directly. For example, a simulation might require two random effects (e.g. a random intercept and a random slope). Correlated data like this could be generated using the <code>defData</code> functionality, but it may be more natural to do this with <code>genCorData</code> or <code>addCorData</code>. Currently, simstudy can only generate multivariate normal using these functions. (In the future, additional distributions will be available.)</p>
<p><code>genCorData</code> requires the user to specify a mean vector <code>mu</code>, a single standard deviation or a vector of standard deviations <code>sigma</code>, and either a correlation matrix <code>corMatrix</code> or a correlation coeficient <code>rho</code> and a correlation structure <code>corsrt</code>. It is easy to see how this can be used from a few different examples.</p>
<pre class="r"><code># specifying a specific correlation matrix C
C &lt;- matrix(c(1, 0.7, 0.2, 0.7, 1, 0.8, 0.2, 0.8, 1), nrow = 3)
C</code></pre>
<pre><code>##      [,1] [,2] [,3]
## [1,]  1.0  0.7  0.2
## [2,]  0.7  1.0  0.8
## [3,]  0.2  0.8  1.0</code></pre>
<pre class="r"><code># generate 3 correlated variables with different location and scale for each
# field
dt &lt;- genCorData(1000, mu = c(4, 12, 3), sigma = c(1, 2, 3), corMatrix = C)
dt</code></pre>
<pre><code>##         id       V1       V2       V3
##    1:    1 4.961148 13.26393 2.840141
##    2:    2 4.423707 11.26632 0.585865
##    3:    3 4.505243 15.10431 7.953057
##    4:    4 5.912019 15.65229 7.284611
##    5:    5 3.803263 12.48040 5.799542
##   ---                                
##  996:  996 3.961720 11.35413 2.382481
##  997:  997 4.916326 14.18447 1.361384
##  998:  998 4.382995 10.68920 1.229472
##  999:  999 2.720188 10.76636 3.706888
## 1000: 1000 6.244197 13.89845 2.818528</code></pre>
<pre class="r"><code># estimate correlation matrix
dt[, round(cor(cbind(V1, V2, V3)), 1)]</code></pre>
<pre><code>##     V1  V2  V3
## V1 1.0 0.7 0.2
## V2 0.7 1.0 0.8
## V3 0.2 0.8 1.0</code></pre>
<pre class="r"><code># estimate standard deviation
dt[, round(sqrt(diag(var(cbind(V1, V2, V3)))), 1)]</code></pre>
<pre><code>##  V1  V2  V3 
## 1.0 2.0 3.1</code></pre>
<pre class="r"><code># generate 3 correlated variables with different location but same standard
# deviation and compound symmetry (cs) correlation matrix with correlation
# coefficient = 0.4.  Other correlation matrix structures are &#39;independent&#39;
# (&#39;ind&#39;) and &#39;auto-regressive&#39; (&#39;ar1&#39;).

dt &lt;- genCorData(1000, mu = c(4, 12, 3), sigma = 3, rho = 0.4, corstr = &quot;cs&quot;, 
    cnames = c(&quot;x0&quot;, &quot;x1&quot;, &quot;x2&quot;))
dt</code></pre>
<pre><code>##         id        x0        x1        x2
##    1:    1  4.016802 10.988722  4.660781
##    2:    2  3.898407  8.077716 -2.126860
##    3:    3  4.747463 12.954511  5.061043
##    4:    4  2.726645  9.057147  1.780203
##    5:    5  5.116028  8.996474  3.785076
##   ---                                   
##  996:  996  5.771868  8.964060  8.938245
##  997:  997 -2.699944  7.022556  6.008857
##  998:  998  5.018185 14.742628  7.820435
##  999:  999  5.706364  5.822701 -1.792551
## 1000: 1000  2.198054 12.991581  3.983375</code></pre>
<pre class="r"><code># estimate correlation matrix
dt[, round(cor(cbind(x0, x1, x2)), 1)]</code></pre>
<pre><code>##     x0  x1  x2
## x0 1.0 0.4 0.4
## x1 0.4 1.0 0.4
## x2 0.4 0.4 1.0</code></pre>
<pre class="r"><code># estimate standard deviation
dt[, round(sqrt(diag(var(cbind(x0, x1, x2)))), 1)]</code></pre>
<pre><code>##  x0  x1  x2 
## 2.9 3.0 3.0</code></pre>
<p>The new data generated by <code>genCorData</code> can be merged with an existing data set. Alternatively, <code>addCorData</code> will do this directly:</p>
<pre class="r"><code># define and generate the original data set
def &lt;- defData(varname = &quot;x&quot;, dist = &quot;normal&quot;, formula = 0, variance = 1, id = &quot;cid&quot;)
dt &lt;- genData(1000, def)

# add new correlate fields a0 and a1 to &#39;dt&#39;
dt &lt;- addCorData(dt, idname = &quot;cid&quot;, mu = c(0, 0), sigma = c(2, 0.2), rho = -0.2, 
    corstr = &quot;cs&quot;, cnames = c(&quot;a0&quot;, &quot;a1&quot;))

dt</code></pre>
<pre><code>##        cid          x         a0           a1
##    1:    1 -2.0674678  1.4789095  0.017142855
##    2:    2 -0.1657663  0.2225743 -0.283654340
##    3:    3 -0.6312775 -2.0066948  0.307710348
##    4:    4 -0.2731647 -0.2291039 -0.008029806
##    5:    5  0.6503149  0.7722605  0.051692272
##   ---                                        
##  996:  996 -1.6173502 -1.0966838  0.180594864
##  997:  997  0.5800576  3.0324297  0.240195201
##  998:  998 -0.8780534 -1.3032857 -0.089815024
##  999:  999  0.6098744  1.8513187 -0.064456111
## 1000: 1000  0.2650545 -2.0742645  0.108673017</code></pre>
<pre class="r"><code># estimate correlation matrix
dt[, round(cor(cbind(a0, a1)), 1)]</code></pre>
<pre><code>##      a0   a1
## a0  1.0 -0.2
## a1 -0.2  1.0</code></pre>
<pre class="r"><code># estimate standard deviation
dt[, round(sqrt(diag(var(cbind(a0, a1)))), 1)]</code></pre>
<pre><code>##  a0  a1 
## 1.9 0.2</code></pre>
<div id="correlated-data-additional-distributions" class="section level3">
<h3>Correlated data: additional distributions</h3>
<p>Two additional functions facilitiate the generation of correlated data from <em>binomial</em>, <em>poisson</em>, <em>gamma</em>, and <em>uniform</em> distributions: <code>genCorGen</code> and <code>addCorGen</code>.</p>
<p><code>genCorGen</code> is an extension of <code>genCorData</code>. In the first example, we are generating data from a multivariate Poisson distribution. We start by specifying the mean of the Poisson distribution for each new variable, and then we specify the correlation structure, just as we did with the normal distribution.</p>
<pre class="r"><code>l &lt;- c(8, 10, 12) # lambda for each new variable

dx &lt;- genCorGen(1000, nvars = 3, params1 = l, dist = &quot;poisson&quot;, rho = .3, corstr = &quot;cs&quot;, wide = TRUE)
dx</code></pre>
<pre><code>##         id V1 V2 V3
##    1:    1  8 13  8
##    2:    2 12 13  9
##    3:    3 12 17 12
##    4:    4 11 15  9
##    5:    5  7 13 17
##   ---              
##  996:  996  9 11 12
##  997:  997  8 10 10
##  998:  998  6  6 12
##  999:  999  7  8 13
## 1000: 1000  9 10 13</code></pre>
<pre class="r"><code>round(cor(as.matrix(dx[, .(V1, V2, V3)])), 2)</code></pre>
<pre><code>##      V1   V2   V3
## V1 1.00 0.32 0.32
## V2 0.32 1.00 0.29
## V3 0.32 0.29 1.00</code></pre>
<p>We can also generate correlated binary data by specifying the probabilities:</p>
<pre class="r"><code>genCorGen(1000, nvars = 3, params1 = c(.3, .5, .7), dist = &quot;binary&quot;, rho = .8, corstr = &quot;cs&quot;, wide = TRUE)</code></pre>
<pre><code>##         id V1 V2 V3
##    1:    1  1  1  1
##    2:    2  0  1  1
##    3:    3  0  1  1
##    4:    4  0  0  0
##    5:    5  0  0  1
##   ---              
##  996:  996  0  0  0
##  997:  997  1  1  1
##  998:  998  1  1  1
##  999:  999  0  0  0
## 1000: 1000  1  1  1</code></pre>
<p>The gamma distribution requires two parameters - the mean and dispersion. (These are converted into shape and rate parameters more commonly used.)</p>
<pre class="r"><code>dx &lt;- genCorGen(1000, nvars = 3, params1 = l, params2 = c(1,1,1), dist = &quot;gamma&quot;, rho = .7, corstr = &quot;cs&quot;, wide = TRUE, cnames=&quot;a, b, c&quot;)
dx</code></pre>
<pre><code>##         id          a          b          c
##    1:    1  2.2147914  5.7828970 12.4494947
##    2:    2  1.3062344  6.1613218  3.1724069
##    3:    3  4.8616340 29.6643309  6.4130084
##    4:    4  0.5403350  0.6539857  0.2711737
##    5:    5 12.4790275  3.3807058 14.2851746
##   ---                                      
##  996:  996  3.9052560  9.5434050  8.9738441
##  997:  997  9.0188944  9.5958862  6.9818731
##  998:  998  1.0142999  2.5976399 13.4244831
##  999:  999  0.3335885  5.6766551  3.0571633
## 1000: 1000  3.4507202  2.6912672 16.6274046</code></pre>
<pre class="r"><code>round(cor(as.matrix(dx[, .(a, b, c)])), 2)</code></pre>
<pre><code>##      a    b    c
## a 1.00 0.64 0.67
## b 0.64 1.00 0.66
## c 0.67 0.66 1.00</code></pre>
<p>These data sets can be generated in either <em>wide</em> or <em>long</em> form. So far, we have generated <em>wide</em> form data, where there is one row per unique id. Now, we will generate data using the <em>long</em> form, where the correlated data are on different rows, so that there are repeated measurements for each id. An id will have multiple records (i.e. one id will appear on multiple rows):</p>
<pre class="r"><code>dx &lt;- genCorGen(1000, nvars = 3, params1 = l, params2 = c(1,1,1), dist = &quot;gamma&quot;, rho = .7, corstr = &quot;cs&quot;, wide = FALSE, cnames=&quot;NewCol&quot;)
dx</code></pre>
<pre><code>##         id period     NewCol
##    1:    1      0  4.6181941
##    2:    1      1  6.3649410
##    3:    1      2  4.9943912
##    4:    2      0  1.6169833
##    5:    2      1  2.6281985
##   ---                       
## 2996:  999      1 13.0572778
## 2997:  999      2 13.9987895
## 2998: 1000      0  0.6222378
## 2999: 1000      1  4.1499146
## 3000: 1000      2  0.3371689</code></pre>
<p><code>addCorGen</code> allows us to create correlated data from an existing data set, as one can already do using <code>addCorData</code>. In the case of <code>addCorGen</code>, the parameter(s) used to define the distribution are created as a field (or fields) in the dataset. The correlated data are added to the existing data set. In the example below, we are going to generate three sets (poisson, binary, and gamma) of correlated data with means that are a function of the variable <code>xbase</code>, which varies by id.</p>
<p>First we define the data and generate a data set:</p>
<pre class="r"><code>def &lt;- defData(varname = &quot;xbase&quot;, formula = 5, variance = .2, dist = &quot;gamma&quot;, id = &quot;cid&quot;)
def &lt;- defData(def, varname = &quot;lambda&quot;, formula = &quot;.5 + .1*xbase&quot;, dist=&quot;nonrandom&quot;, link = &quot;log&quot;)
def &lt;- defData(def, varname = &quot;p&quot;, formula = &quot;-2 + .3*xbase&quot;, dist=&quot;nonrandom&quot;, link = &quot;logit&quot;)
def &lt;- defData(def, varname = &quot;gammaMu&quot;, formula = &quot;.5 + .2*xbase&quot;, dist=&quot;nonrandom&quot;, link = &quot;log&quot;)
def &lt;- defData(def, varname = &quot;gammaDis&quot;, formula = 1, dist=&quot;nonrandom&quot;)

dt &lt;- genData(10000, def)
dt</code></pre>
<pre><code>##          cid    xbase   lambda         p  gammaMu gammaDis
##     1:     1 5.698630 2.914980 0.4279032 5.153757        1
##     2:     2 3.564564 2.354802 0.2827968 3.363267        1
##     3:     3 2.664886 2.152196 0.2313802 2.809418        1
##     4:     4 5.678577 2.909141 0.4264312 5.133129        1
##     5:     5 5.369445 2.820585 0.4039179 4.825377        1
##    ---                                                    
##  9996:  9996 8.325959 3.790871 0.6219393 8.716273        1
##  9997:  9997 2.559089 2.129546 0.2257838 2.750596        1
##  9998:  9998 3.525356 2.345587 0.2804172 3.336997        1
##  9999:  9999 2.417845 2.099679 0.2184629 2.673982        1
## 10000: 10000 3.060428 2.239030 0.2531520 3.040694        1</code></pre>
<p>The Poisson distribution has a single paramter, lambda:</p>
<pre class="r"><code>dtX1 &lt;- addCorGen(dtOld = dt, idvar = &quot;cid&quot;, nvars = 3, rho = .1, corstr = &quot;cs&quot;,
                    dist = &quot;poisson&quot;, param1 = &quot;lambda&quot;, cnames = &quot;a, b, c&quot;)
dtX1</code></pre>
<pre><code>##          cid    xbase   lambda         p  gammaMu gammaDis a b c
##     1:     1 5.698630 2.914980 0.4279032 5.153757        1 6 1 2
##     2:     2 3.564564 2.354802 0.2827968 3.363267        1 3 3 3
##     3:     3 2.664886 2.152196 0.2313802 2.809418        1 2 1 3
##     4:     4 5.678577 2.909141 0.4264312 5.133129        1 3 1 4
##     5:     5 5.369445 2.820585 0.4039179 4.825377        1 2 2 3
##    ---                                                          
##  9996:  9996 8.325959 3.790871 0.6219393 8.716273        1 3 4 5
##  9997:  9997 2.559089 2.129546 0.2257838 2.750596        1 1 2 0
##  9998:  9998 3.525356 2.345587 0.2804172 3.336997        1 2 2 1
##  9999:  9999 2.417845 2.099679 0.2184629 2.673982        1 1 3 5
## 10000: 10000 3.060428 2.239030 0.2531520 3.040694        1 3 0 1</code></pre>
<p>The Bernouilli (binary) distribution has a single parameter, p:</p>
<pre class="r"><code>dtX2 &lt;- addCorGen(dtOld = dt, idvar = &quot;cid&quot;, nvars = 4, rho = .4, corstr = &quot;ar1&quot;,
                    dist = &quot;binary&quot;, param1 = &quot;p&quot;)
dtX2</code></pre>
<pre><code>##          cid    xbase   lambda         p  gammaMu gammaDis V1 V2 V3 V4
##     1:     1 5.698630 2.914980 0.4279032 5.153757        1  0  0  1  0
##     2:     2 3.564564 2.354802 0.2827968 3.363267        1  1  1  0  1
##     3:     3 2.664886 2.152196 0.2313802 2.809418        1  0  0  0  0
##     4:     4 5.678577 2.909141 0.4264312 5.133129        1  1  0  0  0
##     5:     5 5.369445 2.820585 0.4039179 4.825377        1  1  1  1  1
##    ---                                                                
##  9996:  9996 8.325959 3.790871 0.6219393 8.716273        1  0  0  1  1
##  9997:  9997 2.559089 2.129546 0.2257838 2.750596        1  1  0  0  0
##  9998:  9998 3.525356 2.345587 0.2804172 3.336997        1  0  0  0  0
##  9999:  9999 2.417845 2.099679 0.2184629 2.673982        1  1  0  0  1
## 10000: 10000 3.060428 2.239030 0.2531520 3.040694        1  1  1  1  0</code></pre>
<p>The Gamma distribution has two parameters - in <code>simstudy</code> the mean and dispersion are specified:</p>
<pre class="r"><code>dtX3 &lt;- addCorGen(dtOld = dt, idvar = &quot;cid&quot;, nvars = 4, rho = .4, corstr = &quot;cs&quot;,
                  dist = &quot;gamma&quot;, param1 = &quot;gammaMu&quot;, param2 = &quot;gammaDis&quot;)
dtX3</code></pre>
<pre><code>##          cid    xbase   lambda         p  gammaMu gammaDis         V1
##     1:     1 5.698630 2.914980 0.4279032 5.153757        1  2.1924081
##     2:     2 3.564564 2.354802 0.2827968 3.363267        1  8.7328677
##     3:     3 2.664886 2.152196 0.2313802 2.809418        1  2.7422032
##     4:     4 5.678577 2.909141 0.4264312 5.133129        1  4.3125713
##     5:     5 5.369445 2.820585 0.4039179 4.825377        1  4.6422097
##    ---                                                               
##  9996:  9996 8.325959 3.790871 0.6219393 8.716273        1 12.1051327
##  9997:  9997 2.559089 2.129546 0.2257838 2.750596        1  6.2771513
##  9998:  9998 3.525356 2.345587 0.2804172 3.336997        1  7.7878250
##  9999:  9999 2.417845 2.099679 0.2184629 2.673982        1  0.4166578
## 10000: 10000 3.060428 2.239030 0.2531520 3.040694        1  9.5893322
##                V2         V3        V4
##     1:  3.1822804 11.8429426  3.503066
##     2:  0.8551908  8.4568344  3.702797
##     3:  1.4664891  9.1577855  3.277641
##     4:  2.5736640  1.9366756  1.689787
##     5:  2.9348884  1.7149849  2.021616
##    ---                                
##  9996: 12.9311557 21.6100941 29.083559
##  9997:  7.9767125  7.4557215  1.103534
##  9998:  2.5641834  0.4541554  6.861430
##  9999:  2.3301697  1.3183229  3.994858
## 10000:  3.3786109  1.8709750  7.501375</code></pre>
<p>If we have data in <em>long</em> form (e.g. longitudinal data), the function will recognize the structure:</p>
<pre class="r"><code>def &lt;- defData(varname = &quot;xbase&quot;, formula = 5, variance = .4, dist = &quot;gamma&quot;, id = &quot;cid&quot;)
def &lt;- defData(def, &quot;nperiods&quot;, formula = 3, dist = &quot;noZeroPoisson&quot;)

def2 &lt;- defDataAdd(varname = &quot;lambda&quot;, formula = &quot;.5+.5*period + .1*xbase&quot;, dist=&quot;nonrandom&quot;, link = &quot;log&quot;)

dt &lt;- genData(1000, def)

dtLong &lt;- addPeriods(dt, idvars = &quot;cid&quot;, nPeriods = 3)
dtLong &lt;- addColumns(def2, dtLong)

dtLong</code></pre>
<pre><code>##        cid period    xbase nperiods timeID   lambda
##    1:    1      0 4.419360        1      1 2.564942
##    2:    1      1 4.419360        1      2 4.228875
##    3:    1      2 4.419360        1      3 6.972236
##    4:    2      0 5.941155        2      4 2.986540
##    5:    2      1 5.941155        2      5 4.923972
##   ---                                              
## 2996:  999      1 3.365393        3   2996 3.805850
## 2997:  999      2 3.365393        3   2997 6.274785
## 2998: 1000      0 4.490924        5   2998 2.583364
## 2999: 1000      1 4.490924        5   2999 4.259247
## 3000: 1000      2 4.490924        5   3000 7.022311</code></pre>
<pre class="r"><code>### Generate the data 

dtX3 &lt;- addCorGen(dtOld = dtLong, idvar = &quot;cid&quot;, nvars = 3, rho = .6, corstr = &quot;cs&quot;,
                  dist = &quot;poisson&quot;, param1 = &quot;lambda&quot;, cnames = &quot;NewPois&quot;)
dtX3</code></pre>
<pre><code>##        cid period    xbase nperiods timeID   lambda NewPois
##    1:    1      0 4.419360        1      1 2.564942       0
##    2:    1      1 4.419360        1      2 4.228875       3
##    3:    1      2 4.419360        1      3 6.972236       4
##    4:    2      0 5.941155        2      4 2.986540       3
##    5:    2      1 5.941155        2      5 4.923972       4
##   ---                                                      
## 2996:  999      1 3.365393        3   2996 3.805850       5
## 2997:  999      2 3.365393        3   2997 6.274785       8
## 2998: 1000      0 4.490924        5   2998 2.583364       3
## 2999: 1000      1 4.490924        5   2999 4.259247       4
## 3000: 1000      2 4.490924        5   3000 7.022311       9</code></pre>
<p>We can fit a generalized estimating equation (GEE) model and examine the coefficients and the working correlation matrix. They match closely to the data generating parameters:</p>
<pre class="r"><code>geefit &lt;- gee(NewPois ~ period + xbase, data = dtX3, id = cid, family = poisson, corstr = &quot;exchangeable&quot;)</code></pre>
<pre><code>## Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27</code></pre>
<pre><code>## running glm to get initial regression estimate</code></pre>
<pre><code>## (Intercept)      period       xbase 
##  0.49861593  0.50642513  0.09885127</code></pre>
<pre class="r"><code>round(summary(geefit)$working.correlation, 2)</code></pre>
<pre><code>##      [,1] [,2] [,3]
## [1,] 1.00 0.57 0.57
## [2,] 0.57 1.00 0.57
## [3,] 0.57 0.57 1.00</code></pre>
</div>
</div>
<div id="missing-data" class="section level2">
<h2>Missing data</h2>
<p>After generating a complete data set, it is possible to generate missing data. <code>defMiss</code> defines the parameters of missingness. <code>genMiss</code> generates a missing data matrix of indicators for each field. Indicators are set to 1 if the data are missing for a subject, 0 otherwise. <code>genObs</code> creates a data set that reflects what would have been observed had data been missing; this is a replicate of the orginal data set with “NAs” replacing values where missing data has been generated.</p>
<p>By controlling the parameters of missingness, it is possible to represent different missing data mechanisms: (1) <em>missing completely at random</em> (MCAR), where the probability missing data is independent of any covariates, measured or unmeasured, that are associated with the measure, (2) <em>missing at random</em> (MAR), where the probability of subject missing data is a function only of observed covariates that are associated with the measure, and (3) <em>not missing at random</em> (NMAR), where the probability of missing data is related to unmeasured covariates that are associated with measure.</p>
<p>These possibilities are illustrated with an example. A data set of 1000 observations with three “outcome” measures&quot; <code>x1</code>, <code>x2</code>, and <code>x3</code> is defined. This data set also includes two independent predictors, <code>m</code> and <code>u</code> that largely determine the value of each outcome (subject to random noise).</p>
<pre class="r"><code>def1 &lt;- defData(varname = &quot;m&quot;, dist = &quot;binary&quot;, formula = 0.5)
def1 &lt;- defData(def1, &quot;u&quot;, dist = &quot;binary&quot;, formula = 0.5)
def1 &lt;- defData(def1, &quot;x1&quot;, dist = &quot;normal&quot;, formula = &quot;20*m + 20*u&quot;, variance = 2)
def1 &lt;- defData(def1, &quot;x2&quot;, dist = &quot;normal&quot;, formula = &quot;20*m + 20*u&quot;, variance = 2)
def1 &lt;- defData(def1, &quot;x3&quot;, dist = &quot;normal&quot;, formula = &quot;20*m + 20*u&quot;, variance = 2)

dtAct &lt;- genData(1000, def1)</code></pre>
<p>In this example, the missing data mechanism is different for each outcome. As defined below, missingness for <code>x1</code> is MCAR, since the probability of missing is fixed. Missingness for <code>x2</code> is MAR, since missingness is a function of <code>m</code>, a measured predictor of <code>x2</code>. And missingness for <code>x3</code> is NMAR, since the probability of missing is dependent on <code>u</code>, an unmeasured predictor of <code>x3</code>:</p>
<pre class="r"><code>defM &lt;- defMiss(varname = &quot;x1&quot;, formula = 0.15, logit.link = FALSE)
defM &lt;- defMiss(defM, varname = &quot;x2&quot;, formula = &quot;.05 + m * 0.25&quot;, logit.link = FALSE)
defM &lt;- defMiss(defM, varname = &quot;x3&quot;, formula = &quot;.05 + u * 0.25&quot;, logit.link = FALSE)
defM &lt;- defMiss(defM, varname = &quot;u&quot;, formula = 1, logit.link = FALSE)  # not observed

missMat &lt;- genMiss(dtAct, defM, idvars = &quot;id&quot;)
dtObs &lt;- genObs(dtAct, missMat, idvars = &quot;id&quot;)</code></pre>
<pre class="r"><code>missMat</code></pre>
<pre><code>##         id x1 x2 x3 u m
##    1:    1  0  1  0 1 0
##    2:    2  0  0  0 1 0
##    3:    3  0  0  0 1 0
##    4:    4  0  0  0 1 0
##    5:    5  0  0  0 1 0
##   ---                  
##  996:  996  0  0  0 1 0
##  997:  997  0  0  0 1 0
##  998:  998  0  0  0 1 0
##  999:  999  0  0  0 1 0
## 1000: 1000  0  0  0 1 0</code></pre>
<pre class="r"><code>dtObs</code></pre>
<pre><code>##         id m  u         x1          x2          x3
##    1:    1 0 NA  0.4897648          NA -0.41784137
##    2:    2 0 NA  0.7115354  0.44336010  0.09161338
##    3:    3 0 NA -2.0015986  1.14532572  2.27791736
##    4:    4 1 NA 17.6922028 18.87469486 18.56019618
##    5:    5 1 NA 20.3853462 19.39040578 19.32114600
##   ---                                             
##  996:  996 0 NA -2.1475359 -0.16479811  0.31246825
##  997:  997 0 NA  1.1448311  0.08416758 -1.09136051
##  998:  998 1 NA 41.3487531 39.62171697 38.85677524
##  999:  999 0 NA -1.1410528 -0.37949988  0.79642002
## 1000: 1000 0 NA -0.4259718 -0.74783361 -0.63368629</code></pre>
<p>The impacts of the various data mechanisms on estimation can be seen with a simple calculation of means using both the “true” data set without missing data as a comparison for the “observed” data set. Since <code>x1</code> is MCAR, the averages for both data sets are roughly equivalent. However, we can see below that estimates for <code>x2</code> and <code>x3</code> are biased, as the difference between observed and actual is not close to 0:</p>
<pre class="r"><code># Two functions to calculate means and compare them

rmean &lt;- function(var, digits = 1) {
    round(mean(var, na.rm = TRUE), digits)
}

showDif &lt;- function(dt1, dt2, rowName = c(&quot;Actual&quot;, &quot;Observed&quot;, &quot;Difference&quot;)) {
    dt &lt;- data.frame(rbind(dt1, dt2, dt1 - dt2))
    rownames(dt) &lt;- rowName
    return(dt)
}

# data.table functionality to estimate means for each data set

meanAct &lt;- dtAct[, .(x1 = rmean(x1), x2 = rmean(x2), x3 = rmean(x3))]
meanObs &lt;- dtObs[, .(x1 = rmean(x1), x2 = rmean(x2), x3 = rmean(x3))]

showDif(meanAct, meanObs)</code></pre>
<pre><code>##              x1   x2   x3
## Actual     20.1 20.1 20.1
## Observed   20.2 18.3 18.5
## Difference -0.1  1.8  1.6</code></pre>
<p>After adjusting for the measured covariate <code>m</code>, the bias for the estimate of the mean of <code>x2</code> is mitigated, but not for <code>x3</code>, since <code>u</code> is not observed:</p>
<pre class="r"><code>meanActm &lt;- dtAct[, .(x1 = rmean(x1), x2 = rmean(x2), x3 = rmean(x3)), keyby = m]
meanObsm &lt;- dtObs[, .(x1 = rmean(x1), x2 = rmean(x2), x3 = rmean(x3)), keyby = m]</code></pre>
<pre class="r"><code># compare observed and actual when m = 0

showDif(meanActm[m == 0, .(x1, x2, x3)], meanObsm[m == 0, .(x1, x2, x3)])</code></pre>
<pre><code>##              x1   x2   x3
## Actual     10.3 10.2 10.3
## Observed   10.3 10.2  8.8
## Difference  0.0  0.0  1.5</code></pre>
<pre class="r"><code># compare observed and actual when m = 1

showDif(meanActm[m == 1, .(x1, x2, x3)], meanObsm[m == 1, .(x1, x2, x3)])</code></pre>
<pre><code>##              x1   x2   x3
## Actual     29.9 29.9 29.8
## Observed   30.1 29.3 28.2
## Difference -0.2  0.6  1.6</code></pre>
</div>
<div id="longitudinal-data-with-missingness" class="section level2">
<h2>Longitudinal data with missingness</h2>
<p>Missingness can occur, of course, in the context of longitudinal data. <code>missDef</code> provides two additional arguments that are relevant for these types of datas: <code>baseline</code> and <code>monotonic</code>. In the case of variables that are measured at baseline only, a missing value would be reflected throughout the course of the study. In the case where a variable is time-dependent (i.e it is measured at each time point), it is possible to declare missingness to be <em>monotonic</em>. This means that if a value for this field is missing at time <code>t</code>, then values will also be missing at all times <code>T &gt; t</code> as well. The call to <code>genMiss</code> must set <code>repeated</code> to TRUE.</p>
<p>The following two examples describe an outcome variable <code>y</code> that is measured over time, whose value is a function of time and an observed exposure:</p>
<pre class="r"><code># use baseline definitions from previous example

dtAct &lt;- genData(120, def1)
dtAct &lt;- trtObserve(dtAct, formulas = 0.5, logit.link = FALSE, grpName = &quot;rx&quot;)

# add longitudinal data

defLong &lt;- defDataAdd(varname = &quot;y&quot;, dist = &quot;normal&quot;, formula = &quot;10 + period*2 + 2 * rx&quot;, 
    variance = 2)

dtTime &lt;- addPeriods(dtAct, nPeriods = 4)
dtTime &lt;- addColumns(defLong, dtTime)</code></pre>
<p>In the first case, missingness is not monotonic; a subject might miss a measurement but returns for subsequent measurements:</p>
<pre class="r"><code># missingness for y is not monotonic

defMlong &lt;- defMiss(varname = &quot;x1&quot;, formula = 0.2, baseline = TRUE)
defMlong &lt;- defMiss(defMlong, varname = &quot;y&quot;, formula = &quot;-1.5 - 1.5 * rx + .25*period&quot;, 
    logit.link = TRUE, baseline = FALSE, monotonic = FALSE)

missMatLong &lt;- genMiss(dtTime, defMlong, idvars = c(&quot;id&quot;, &quot;rx&quot;), repeated = TRUE, 
    periodvar = &quot;period&quot;)</code></pre>
<p>Here is a conceptual plot that shows the pattern of missingness. Each row represents an individual, and each box represents a time period. A box that is colored reflects missing data; a box colored grey reflects observed. The missingness pattern is shown for two variables <code>x1</code> and <code>y</code>:</p>
<p><img src="/page/simstudy_files/figure-html/unnamed-chunk-51-1.png" width="672" /></p>
<p>In the second case, missingness is monotonic; once a subject misses a measurement for <code>y</code>, there are no subsequent measurements:</p>
<pre class="r"><code># missingness for y is not monotonic

defMlong &lt;- defMiss(varname = &quot;x1&quot;, formula = 0.2, baseline = TRUE)
defMlong &lt;- defMiss(defMlong, varname = &quot;y&quot;, formula = &quot;-1.8 - 1.5 * rx + .25*period&quot;, 
    logit.link = TRUE, baseline = FALSE, monotonic = TRUE)

missMatLong &lt;- genMiss(dtTime, defMlong, idvars = c(&quot;id&quot;, &quot;rx&quot;), repeated = TRUE, 
    periodvar = &quot;period&quot;)</code></pre>
<p><img src="/page/simstudy_files/figure-html/unnamed-chunk-53-1.png" width="672" /></p>
</div>
